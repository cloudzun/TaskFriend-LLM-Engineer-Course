{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "030dace5-6096-4fc3-a6a4-eea583c224e1",
   "metadata": {},
   "source": [
    "# è¯„ä¼° RAG æ€§èƒ½\n",
    "\n",
    "---\n",
    "\n",
    "ç¥è´ºä½ æ„å»ºäº†ç¬¬ä¸€ä¸ª RAGï¼RAGï¼ˆRetrieval-Augmented Generationï¼Œæ£€ç´¢å¢å¼ºç”Ÿæˆï¼‰æ˜¯æ‰“é€ å®ç”¨å‹ LLM åº”ç”¨æœ€å¸¸è§çš„æ–¹å¼ä¹‹ä¸€ã€‚å®ƒè®©ä½ èƒ½å¤Ÿå¼•å…¥å¤–éƒ¨çŸ¥è¯†ï¼Œä½¿ä½ çš„ AI åŠ©æ‰‹æˆ–èŠå¤©æœºå™¨äººä¸å†å±€é™äºæ¨¡å‹åœ¨è®­ç»ƒé˜¶æ®µè®°ä½çš„å†…å®¹ã€‚\n",
    "\n",
    "ä½†åŠ å…¥æ£€ç´¢åŠŸèƒ½ä¹Ÿè®©æ•´ä½“å¤æ‚åº¦æ˜¾è‘—æå‡ã€‚\n",
    "\n",
    "æ­¤æ—¶ä½ ä¸å†åªæ˜¯ç»™ LLM å†™æç¤ºè¯â€”â€”ä½ åœ¨æ­å»ºæ•´æ¡ç®¡çº¿ã€‚è¿™é‡Œæ¶‰åŠæ–‡æœ¬åˆ†å—ã€æ£€ç´¢ã€ä¸Šä¸‹æ–‡æ‹¼è£…ä¸ç”Ÿæˆã€‚å½“å‡ºç°é—®é¢˜æ—¶ï¼Œæ ¹æºå¾€å¾€ä¸æ˜ï¼šæ˜¯æ¨¡å‹å¹»è§‰ï¼Ÿè¿˜æ˜¯å‹æ ¹æ²¡æœ‰æ‹¿åˆ°æ­£ç¡®çš„ä¿¡æ¯ï¼Ÿ\n",
    "\n",
    "é‚£ä¹ˆï¼Œåœ¨å‘ç”¨æˆ·å‘å¸ƒä¹‹å‰ï¼Œå¦‚ä½•åˆ¤æ–­ RAG ç³»ç»Ÿçš„è¡¨ç°å¦‚ä½•å‘¢ï¼Ÿè¿™æ­£æ˜¯è¯„ä¼°æœºåˆ¶å‘æŒ¥ä½œç”¨çš„åœ°æ–¹ã€‚\n",
    "\n",
    "## æ•…äº‹å›é¡¾\n",
    "\n",
    "ä½ å·²ç»æˆåŠŸæŠŠ RAG æ•´åˆè¿› **TaskFriend**ï¼Œç°åœ¨å®ƒå¯ä»¥è®¿é—®åº”ç”¨ä¸­å­˜æ”¾çš„å…¶ä»–ä¿¡æ¯ã€‚ç„¶è€Œï¼Œä½ éšçº¦è§‰å¾—æŸå¤„å‡ºäº†é—®é¢˜ï¼Œäºæ˜¯å¯¹æ¯”äº†åº”ç”¨æ•°æ®ä¸ **TaskFriend** çš„å›ç­”ã€‚æœä¸å…¶ç„¶â€”â€”**TaskFriend** ä¼šæŠŠéƒ¨åˆ†ä¿¡æ¯å¼„é”™ã€‚ä½ æ‹…å¿ƒè¿™å¯èƒ½åªæ˜¯å†°å±±ä¸€è§’ï¼Œå¯æ˜¯å®Œå…¨é äººå·¥æ’æŸ¥æ˜¾ç„¶ä¸å¯è¡Œã€‚\n",
    "\n",
    "å› æ­¤ï¼Œä½ å†³å®šæ„å»ºä¸€ä¸ªè¯„ä¼°æœºåˆ¶ï¼Œå¸®åŠ©ä½ è‡ªåŠ¨åŒ–è¡¡é‡ **TaskFriend** çš„ RAG åŠŸèƒ½è¡¨ç°å¦‚ä½•ã€‚\n",
    "\n",
    "## ç›®æ ‡\n",
    "\n",
    "* äº†è§£ä¸ºä»€ä¹ˆäººå·¥è¯„ä¼°é€‚åˆè°ƒè¯•ï¼Œå´æ— æ³•åœ¨è§„æ¨¡åŒ–åœºæ™¯ä¸‹ç‹¬ç«‹æ”¯æ’‘ã€‚\n",
    "* å­¦ä¼šé€æ­¥æ£€æŸ¥ RAG ç®¡çº¿ï¼Œä»¥å®šä½æ•…éšœç‚¹ã€‚\n",
    "* æŒæ¡ RAG è¯„ä¼°çš„æ ¸å¿ƒç»´åº¦ï¼šä¸Šä¸‹æ–‡å¬å›ã€ä¸Šä¸‹æ–‡ç²¾åº¦ã€äº‹å®å¯ä¿¡åº¦ä¸ç­”æ¡ˆæ­£ç¡®æ€§ã€‚\n",
    "* æ­å»ºå¹¶ä½¿ç”¨ Ragas æ¥è‡ªåŠ¨è¯„ä¼° RAG ç³»ç»Ÿã€‚\n",
    "* è§£è¯»è¯„ä¼°æŒ‡æ ‡ï¼Œæç‚¼å¯æ‰§è¡Œæ´è§ï¼Œä»è€Œæ”¹è¿› RAG ç®¡çº¿ã€‚\n",
    "* æ¯”è¾ƒå¸¸è§çš„ RAG è¯„ä¼°æ¡†æ¶ï¼Œç†è§£å„è‡ªçš„é€‚ç”¨åœºæ™¯ã€‚\n",
    "* å»ºç«‹å¯æŒç»­ã€ä¸“å®¶å‚ä¸çš„è¯„ä¼°æœ€ä½³å®è·µæµç¨‹ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4293289-3769-44ea-afef-78fcb20a7af0",
   "metadata": {},
   "source": [
    "## åˆå§‹åŒ–ç¯å¢ƒ\n",
    "\n",
    "### è®¾ç½® API å¯†é’¥\n",
    "\n",
    "åœ¨å¼€å§‹ä»»ä½•ç¬”è®°æœ¬çš„å·¥ä½œä¹‹å‰ï¼Œæˆ‘ä»¬éœ€è¦åŠ è½½ [Model Studio çš„ API å¯†é’¥](https://modelstudio.console.alibabacloud.com/?tab=globalset#/efm/api_key)ã€‚è¿™æ ·æ‰èƒ½è°ƒç”¨æˆ‘ä»¬åœ¨æ•´ä¸ªè¯¾ç¨‹ä¸­ä½¿ç”¨çš„ Qwen æ¨¡å‹æ¥å£ã€‚\n",
    "\n",
    "> å¦‚æœä½ ä¸ç¡®å®šå¦‚ä½•æ‰¾åˆ° **Model Studio** çš„ API å¯†é’¥ï¼Œè¯·å‚è€ƒ `00 Setting Up the Environment` æ–‡ä»¶ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f10a24-a058-4759-8bc0-69a6d59e02f0",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load Model Studio API key\n",
    "import os\n",
    "from config.load_key import load_key\n",
    "load_key(\n",
    "    confirmation=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f0b040-078c-4f02-8827-6176ad2d8aaa",
   "metadata": {},
   "source": [
    "### é…ç½® LLM ä¸åµŒå…¥æ¨¡å‹\n",
    "\n",
    "ä¸ä¸Šä¸€è¯¾ç›¸åŒï¼Œæˆ‘ä»¬å°†ä½¿ç”¨é˜¿é‡Œäº‘çš„ `qwen-plus` ä½œä¸º LLMï¼Œå¹¶ä½¿ç”¨ DashScope çš„ `text-embedding-v3` ä½œä¸ºåµŒå…¥æ¨¡å‹ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bda9fb2-bdb2-4ad0-94a1-f340c394609d",
   "metadata": {
    "ExecutionIndicator": {
     "show": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set global settings\n",
    "import time\n",
    "import logging\n",
    "import dashscope\n",
    "from llama_index.core import Settings, VectorStoreIndex, SimpleDirectoryReader\n",
    "from llama_index.embeddings.dashscope import DashScopeEmbedding\n",
    "from llama_index.llms.openai_like import OpenAILike\n",
    "from pathlib import Path\n",
    "\n",
    "logging.getLogger().setLevel(logging.ERROR)\n",
    "\n",
    "# Dashscope uses https://dashscope-intl.aliyuncs.com/api/v1 \n",
    "# instead of https://dashscope-intl.aliyuncs.com/compatible-mode/v1\n",
    "dashscope.base_http_api_url =\"https://dashscope-intl.aliyuncs.com/api/v1\"\n",
    "\n",
    "Settings.llm=OpenAILike(\n",
    "    model=\"qwen-plus\",\n",
    "    api_base=\"https://dashscope-intl.aliyuncs.com/compatible-mode/v1\",\n",
    "    api_key=os.getenv(\"DASHSCOPE_API_KEY\"),\n",
    "    is_chat_model=True\n",
    ")\n",
    "\n",
    "Settings.embed_model = DashScopeEmbedding(\n",
    "    model_name=\"text-embedding-v3\",\n",
    "    api_key=os.getenv(\"DASHSCOPE_API_KEY\"),\n",
    "    encoding_format=\"float\"\n",
    ")\n",
    "\n",
    "print(\"âœ… Global parameters set!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6db2223-83ea-46c1-8942-489f43722c6e",
   "metadata": {},
   "source": [
    "# RAG è¯„ä¼°æµç¨‹\n",
    "\n",
    "--- \n",
    "\n",
    "```mermaid\n",
    "graph LR\n",
    "    A[æ‰‹åŠ¨è¯„ä¼°] --> B[æ‰‹åŠ¨æ’éšœ] --> C[è‡ªåŠ¨åŒ–è¯„ä¼°]\n",
    "```\n",
    "\n",
    "åœ¨çœŸå®ç”Ÿäº§ç¯å¢ƒä¸­ï¼Œç”±äºéœ€è¦å¤„ç†çš„æ•°æ®é‡å·¨å¤§ï¼Œè¯„ä¼° RAG ç³»ç»Ÿé€šå¸¸æœ€å¥½äº¤ç»™**è‡ªåŠ¨åŒ–è¯„ä¼°**æ–¹æ³•ã€‚ä¸è¿‡ï¼Œä»Šå¤©æˆ‘ä»¬èšç„¦åœ¨è¾ƒå°çš„èŒƒå›´â€”â€”æˆ‘ä»¬æ–°æ­å»ºçš„ **TaskFriend** åº”ç”¨ã€‚\n",
    "\n",
    "## æ‰‹åŠ¨è¯„ä¼°ï¼šæ‰¾å‡ºé—®é¢˜\n",
    "\n",
    "åœ¨å…ˆå‰çš„ç¤ºä¾‹ä¸­ï¼Œä½ æˆ–è®¸è®°å¾—å‡ºç°è¿‡ç±»ä¼¼çš„å¯¹è¯ï¼š\n",
    "\n",
    "```\n",
    "ğŸš€ TaskFriend Conversation\n",
    "------------------------------------------------------------\n",
    "ğŸ‘¤ You: How many tasks do I need to complete today?\n",
    "\n",
    "ğŸ¤– TaskFriend is thinking...\n",
    "ğŸ¤– TaskFriend: You have one task that is due today.\n",
    "\n",
    "------------------------------------------------------------\n",
    "```\n",
    "\n",
    "ç„¶è€Œï¼Œå½“æˆ‘ä»¬æŸ¥çœ‹ `tasks.pdf` æ—¶ï¼Œå´å‘ç°äº‹å®å¹¶éå¦‚æ­¤ï¼š\n",
    "\n",
    "\n",
    "| ID | Task | Type | Due | Status | Notes |\n",
    "|----|------|------|-----|--------|-------|\n",
    "| 01 | Finalize Q3 OKRs by 3pm | One-off | â­Today | Pending | Collaborate with department heads to align on measurable objectives, lay out solid plan to achieve objectives and assign responsibility to team members. |\n",
    "| 03 | Onboard new team member | One-off | â­Today | Done | Schedule intro meetings with team members, send welcome email with onboarding checklist, assign mentor for first 30 days.<br>Karen was assigned to be the mentor for the new team member. |\n",
    "| 05 | Update Project Phoenix roadmap | One-off | â­Today | Pending | Sync with project leads to reflect latest timelines, milestones, and resource allocations, taking into account the latest changes to supply-chain disruptions. |\n",
    "| 10 | Write thank-you letter to penpal in Korea | One-off | â­Today | Started | Thank penpal in Korea for the help they provided when you needed advice on planning a trip to Norway, and remember to ask them about their newborn son, Edwin. |\n",
    "\n",
    "\n",
    "é‚£ä¹ˆå‘ç”Ÿäº†ä»€ä¹ˆï¼Ÿè¿™ä¸ªé—®é¢˜çš„æ ¹æºæ˜¯ä»€ä¹ˆï¼Ÿ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675e1437-3e9f-437e-ad88-d47c3c7311c4",
   "metadata": {
    "tags": []
   },
   "source": [
    "## æ’æŸ¥ä½ çš„ RAGï¼šä¸Šæ‰‹å®è·µ\n",
    "\n",
    "è®©æˆ‘ä»¬å†è¿è¡Œä¸€æ¬¡ç”± RAG é©±åŠ¨çš„ **TaskFriend**ã€‚ä½†è¿™æ¬¡ï¼Œæˆ‘ä»¬ä¼šåŒæ—¶**æ‰“å° RAG ä»ç´¢å¼•ä¸­æ£€ç´¢åˆ°çš„æ–‡æœ¬å—ï¼ˆæˆ–èŠ‚ç‚¹ï¼‰**ã€‚\n",
    "\n",
    "å¦å¤–ï¼Œæˆ‘ä»¬è¿˜ä¼šæ·»åŠ ä¸€ä¸ªè‡ªå®šä¹‰çš„ `highlight_words` å‡½æ•°ï¼Œä»¥ä¾¿æ›´æ¸…æ™°åœ°è§‚å¯Ÿè¾“å‡ºã€‚ç¨åä½ å°±ä¼šæ˜ç™½å®ƒçš„ä½œç”¨ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104a42ec-710c-4e6a-81b2-5bc06a0228d1",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def highlight_words(text, words_to_highlight, emoji=\"â­\"):\n",
    "    for word in words_to_highlight:\n",
    "        if word in text:\n",
    "            text = text.replace(word, f\"{emoji}{word}{emoji}\")\n",
    "    return text\n",
    "\n",
    "\n",
    "def get_rag_response_with_info(query, query_engine, highlight=None):\n",
    "    print(\"ğŸš€ TaskFriend Conversation (single-round)\")\n",
    "    print(\"-\" * 50)\n",
    "    print(f'ğŸ‘¤ You: {query}')\n",
    "    \n",
    "    try:\n",
    "        # ğŸ” Query the RAG engine\n",
    "        response = query_engine.query(query)\n",
    "\n",
    "        # ğŸ§  Extract the answer\n",
    "        if hasattr(response, 'response'):\n",
    "            answer = response.response\n",
    "        else:\n",
    "            answer = str(response)\n",
    "\n",
    "        # ğŸ“š Show source references AFTER the answer\n",
    "        print(\"ğŸ¤– TaskFriend:\", answer)\n",
    "        print('\\n\\n' + '=' * 50)\n",
    "        print('ğŸ“š References\\n')\n",
    "        \n",
    "        highlight = highlight or []\n",
    "        for i, source_node in enumerate(response.source_nodes, start=1):\n",
    "            print(f'Chunk {i}:')\n",
    "            \n",
    "            # Highlight words in chunk\n",
    "            highlighted_text = highlight_words(source_node.text, highlight)\n",
    "            print(highlighted_text)\n",
    "            print()\n",
    "        print('=' * 50)\n",
    "\n",
    "        return answer\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[RAG Error] {e}\")\n",
    "        return \"[Error retrieving response]\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06f4246-8b9c-4daf-a75f-bc321c1d9986",
   "metadata": {},
   "source": [
    "ç”±äºæˆ‘ä»¬åœ¨ä¸Šä¸€ç« èŠ‚å·²ç»æ„å»ºå¹¶ä¿å­˜äº†ç´¢å¼•ï¼Œå› æ­¤ç°åœ¨åªéœ€è¦ä»ä¿å­˜çš„ä½ç½®ï¼ˆ`./knowledge_base/taskfriend`ï¼‰åŠ è½½å³å¯ã€‚\n",
    "\n",
    "è¿™é‡Œæˆ‘ä»¬ä¼šç”¨åˆ° `llama_index` ä¸­çš„ä¸€äº›å‡½æ•°ï¼š\n",
    "\n",
    "* `StorageContext:` å­˜å‚¨ä¸Šä¸€ç« ä¿å­˜çš„èŠ‚ç‚¹ã€åµŒå…¥ä¸å‘é‡åº“ï¼Œä½¿ä½ çš„ä»£ç èƒ½å¤Ÿå®šä½å¹¶è¿æ¥è¿™äº›æ•°æ®ï¼Œè¿™æ ·å°±æ— éœ€é‡æ–°å¤„ç†æ‰€æœ‰æ–‡æ¡£ï¼Œå°±èƒ½é‡æ–°åŠ è½½æ•´ä¸ªçŸ¥è¯†åº“ã€‚\n",
    "* `load_index_from_storage:` æ ¹æ®ä¿å­˜åœ¨ `StorageContext` ä¸­çš„æ–‡ä»¶é‡å»º RAG ç´¢å¼•ã€‚è¿™æ˜¯è®© RAG ç³»ç»Ÿå¿«é€Ÿå†æ¬¡è¿è¡Œçš„æœ€é«˜æ•ˆæ–¹å¼ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782736b2-6306-4109-9271-43a3c86d190a",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index.core import StorageContext, load_index_from_storage\n",
    "\n",
    "persist_path=\"./knowledge_base/taskfriend\"\n",
    "\n",
    "# Import index (\"knowledgebase\") we built last chapter,\n",
    "storage_context = StorageContext.from_defaults(\n",
    "    persist_dir=persist_path,\n",
    ")\n",
    "\n",
    "index = load_index_from_storage(\n",
    "    storage_context,\n",
    "    embed_model=Settings.embed_model\n",
    ")\n",
    "print(f\"âœ… Index loaded from `{persist_path}`!\")\n",
    "\n",
    "# Build the query engine (used to implement RAG)\n",
    "query_engine = index.as_query_engine(\n",
    "    streaming=False,\n",
    "    llm=Settings.llm,\n",
    ")\n",
    "print(\"âœ… Query engine built!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4484f35-73c4-48c2-8476-488dd6de0937",
   "metadata": {},
   "source": [
    "ç°åœ¨æˆ‘ä»¬å°±å¯ä»¥å†æ¬¡è¿è¡ŒåŒæ ·çš„æŸ¥è¯¢ï¼Œåªä¸è¿‡è¿™ä¸€æ¬¡ä¼šåŒæ—¶æŸ¥çœ‹ **TaskFriend** è·å–ä¿¡æ¯çš„æ¥æºã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56694613-71e5-4c58-8aa7-6a72078053fc",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# User query\n",
    "query = \"How many tasks do I need to complete today?\"\n",
    "\n",
    "# Choose words to highlight\n",
    "highlight = [\"Today\"]\n",
    "\n",
    "response = get_rag_response_with_info(query, query_engine=query_engine, highlight=highlight)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2050137-82b7-4672-804a-a840a62478b0",
   "metadata": {},
   "source": [
    "ç°åœ¨æˆ‘ä»¬ä¼šçœ‹åˆ°ç±»ä¼¼è¿™æ ·çš„è¾“å‡ºï¼š\n",
    "\n",
    "```\n",
    "ğŸš€ TaskFriend Conversation (single-round)\n",
    "--------------------------------------------------\n",
    "ğŸ‘¤ You: How many tasks do I need to complete today?\n",
    "ğŸ¤– TaskFriend: You need to complete two tasks today. One is to finalize Q3 OKRs by 3 pm, and the other is to onboard a new team member, which has already been marked as done.\n",
    "\n",
    "\n",
    "==================================================\n",
    "ğŸ“š References\n",
    "\n",
    "Chunk 1:\n",
    "Tasks   ID Task Type Due Status Notes \n",
    "01 Finalize Q3 OKRs by 3pm One-oï¬€ â­Todayâ­ Pending  Collaborate with department heads to align on measurable objecDves, lay out solid plan to achieve objecDves and assign responsibility to team members.   \n",
    "02 Prepare presentaDon for client review One-oï¬€ This Week Pending  Focus on deliverables from Q2, highlight success metrics, and outline next steps. Obtain client feedback on presentaDon and tweak direcDon based on\n",
    "\n",
    "Chunk 2:\n",
    "client preferences.   \n",
    "03 Onboard new team member One-oï¬€ â­Todayâ­ Done  Schedule intro meeDngs with team members, send welcome email with onboarding checklist, assign mentor for ï¬rst 30 days.  Karen was assigned to be the mentor for the new team member.   04 Review team feedback survey results One-oï¬€ This Week Pending  Analyze anonymous feedback from recent engagement survey and idenDfy top 3 pain points and 2 strengths.\n",
    "\n",
    "==================================================\n",
    "```\n",
    "\n",
    "å‡ ä»¶äº‹æƒ…ä¼šæ ¼å¤–æ˜¾çœ¼ï¼š\n",
    "\n",
    "* å•è¯ `Today` åªå‡ºç°äº†ä¸¤æ¬¡ã€‚ï¼ˆæ„Ÿè°¢ `highlight_words` å¸®æˆ‘ä»¬çªæ˜¾ï¼ï¼‰\n",
    "* RAG åªæ£€ç´¢äº† *2 ä¸ªæ–‡æœ¬å—*ã€‚\n",
    "* è§£æå™¨ä¼¼ä¹å‡ºç°äº†é—®é¢˜ï¼Œç‰¹åˆ«æ˜¯ä¸€äº›æ‹¼å†™ï¼š\n",
    "    * Executive â†’ ExecuHve\n",
    "    * meeDngs â†’ meetings\n",
    "    \n",
    "åŸºäºè¿™äº›çº¿ç´¢ï¼Œä½ å·²ç»æˆåŠŸç¡®å®šäº† RAG ç³»ç»Ÿé—®é¢˜çš„æ ¹æºã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d918713-212f-4734-bb6c-0ab05536869b",
   "metadata": {},
   "source": [
    "# è‡ªåŠ¨åŒ–è¯„ä¼°\n",
    "\n",
    "---\n",
    "\n",
    "å¯¹äºä¸€æ¬¡æ€§åœºæ™¯æˆ–åƒ TaskFriend è¿™ç§æ—©æœŸå¼€å‘é˜¶æ®µçš„åº”ç”¨æ¥è¯´ï¼Œæ‰‹åŠ¨è¯„ä¼°ä¸æ’éšœå®Œå…¨æ²¡æœ‰é—®é¢˜â€”â€”æ·±å…¥æ¢ç©¶å¼€å‘ç»†èŠ‚ä¹Ÿèƒ½å¸®åŠ©ä½ å¿«é€Ÿæˆé•¿ã€‚ä½†ä¸€æ—¦è§„æ¨¡ä¸Šæ¥ï¼Œé äººå·¥é€æ¡æ’æŸ¥é—®é¢˜å°±è¶Šæ¥è¶Šä¸å¯è¡Œäº†ã€‚\n",
    "\n",
    "æ¥ä¸‹æ¥æˆ‘ä»¬çœ‹çœ‹å¦‚ä½•è®©è¿™ä¸ªæµç¨‹å®ç°è‡ªåŠ¨åŒ–ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324412bd-ce78-4fac-ba92-73ba40c2641f",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_dashscope import DashScopeEmbeddings \n",
    "import os\n",
    "import time\n",
    "\n",
    "dashscope.base_http_api_url =\"https://dashscope-intl.aliyuncs.com/api/v1\"\n",
    "\n",
    "# LangChain LLM for Ragas\n",
    "ragas_llm = ChatOpenAI(\n",
    "    model=\"qwen-plus\",\n",
    "    base_url=\"https://dashscope-intl.aliyuncs.com/compatible-mode/v1\",\n",
    "    api_key=os.getenv(\"DASHSCOPE_API_KEY\"),\n",
    "    timeout=60,\n",
    "    max_retries=3\n",
    ")\n",
    "\n",
    "# LangChain Embeddings for Ragas\n",
    "ragas_embeddings = DashScopeEmbeddings(\n",
    "    model=\"text-embedding-v3\",\n",
    "    api_key=os.getenv(\"DASHSCOPE_API_KEY\")\n",
    ")\n",
    "\n",
    "print(\"âœ… LLM and Embeddings pipeline for Ragas successfully built!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465479c0-5e3a-471d-ae71-a78ced56eeca",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a new query engine for evaluation\n",
    "query_engine = index.as_query_engine(\n",
    "    llm=ragas_llm,\n",
    "    embeddings=ragas_embeddings,\n",
    "    streaming=False  # Disable streaming for evaluation\n",
    ")\n",
    "\n",
    "print(\"âœ… Query engine built!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6314e789-7cd1-420c-9ff6-e889a713906d",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define test cases\n",
    "test_cases = [\n",
    "    {\n",
    "        \"question\": \"How many tasks do I need to complete today?\",\n",
    "        \"ground_truth\": (\n",
    "            \"You have 3 tasks to complete today: Finalize Q3 OKRs, \"\n",
    "            \"Update Project Phoenix roadmap, and Write thank-you letter to penpal.\"\n",
    "        )\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Am I planning a trip somewhere?\",\n",
    "        \"ground_truth\": \"You are planning a trip to Norway.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"When is the 'Develop 3-year plan' task due?\",\n",
    "        \"ground_truth\": \"This year\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What are the one-time and recurring tasks for 'Project Phoenix'? Be brief.\",\n",
    "        \"ground_truth\": (\n",
    "            \"One-time tasks: Updating the project roadmap; \"\n",
    "            \"Recurring tasks: Generating weekly reports.\"\n",
    "        )       \n",
    "    },    \n",
    "]\n",
    "\n",
    "print(\"âœ… Test cases defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504ea654-b380-43c2-bfbd-fc4092cfc8a8",
   "metadata": {
    "ExecutionIndicator": {
     "show": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from functions.html_table import create_html_table\n",
    "\n",
    "# Define function to run test cases with evaluator LLM\n",
    "def run_test_cases(query_engine, test_cases):\n",
    "    results = {\n",
    "        \"question\": [],\n",
    "        \"answer\": [],\n",
    "        \"contexts\": [],  # Store raw contexts for Dataset\n",
    "        \"contexts_display\": [],  # Store formatted contexts for display\n",
    "        \"ground_truth\": []\n",
    "    }\n",
    "    \n",
    "    print(\"Generating answers based on test cases...\", end=\"\", flush=True)\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for case in test_cases:\n",
    "        # Get response\n",
    "        response = query_engine.query(case[\"question\"])\n",
    "        \n",
    "        # Extract answer and context\n",
    "        answer = str(response).strip()\n",
    "        # Ensure contexts is a list of strings\n",
    "        contexts = [node.get_content().strip() for node in response.source_nodes]\n",
    "        \n",
    "        # Format contexts for display with [] and line breaks\n",
    "        contexts_display = [f\"[{ctx}]\" for ctx in contexts]\n",
    "        \n",
    "        # Store results\n",
    "        results[\"question\"].append(case[\"question\"])\n",
    "        results[\"answer\"].append(answer)\n",
    "        results[\"contexts\"].append(contexts)\n",
    "        results[\"contexts_display\"].append(\"â­\".join(contexts_display)) # Use this to better visualize breaks between contexts\n",
    "        results[\"ground_truth\"].append(case[\"ground_truth\"])\n",
    "    \n",
    "    load_time = time.time() - start_time\n",
    "    print(f\" âœ… Done ({load_time:.1f} seconds)\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Run the test\n",
    "test_results = run_test_cases(query_engine, test_cases)\n",
    "\n",
    "table_data = {\n",
    "    \"question\": test_results[\"question\"],\n",
    "    \"answer\": test_results[\"answer\"],\n",
    "    \"ground_truth\": test_results[\"ground_truth\"],\n",
    "    \"contexts\": test_results[\"contexts_display\"],\n",
    "}\n",
    "\n",
    "# Use 5:15:15:15:50 percentage distribution (index + 4 columns)\n",
    "create_html_table(\n",
    "    table_data, \n",
    "    title=\"RAG Evaluation Results\", \n",
    "    column_widths=[5, 15, 15, 15, 50]  # index:question:contexts:ground_truth:answer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa3628f-88bb-4d80-a11c-33a0fb8e5cd7",
   "metadata": {
    "ExecutionIndicator": {
     "show": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "# Convert to Dataset\n",
    "eval_dataset = Dataset.from_dict({\n",
    "    \"question\": test_results[\"question\"],\n",
    "    \"answer\": test_results[\"answer\"],\n",
    "    \"contexts\": test_results[\"contexts\"],\n",
    "    \"ground_truth\": test_results[\"ground_truth\"]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6b3c4d-f120-40e7-9b49-6a4809737cf0",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ragas import evaluate\n",
    "from ragas.metrics import (\n",
    "    context_recall,\n",
    "    context_precision,\n",
    "    answer_correctness,\n",
    "    faithfulness\n",
    ")\n",
    "from functions.rag_eval_table import create_rag_evaluation_table\n",
    "\n",
    "# Use the LangChain-compatible LLM for Ragas\n",
    "results = evaluate(\n",
    "    dataset=eval_dataset,\n",
    "    metrics=[\n",
    "        context_recall,\n",
    "        context_precision,\n",
    "        answer_correctness,\n",
    "        faithfulness\n",
    "    ],\n",
    "    llm=ragas_llm,\n",
    "    embeddings=ragas_embeddings\n",
    ")\n",
    "\n",
    "# Convert results to pandas DataFrame\n",
    "results_df = results.to_pandas()\n",
    "\n",
    "# Extract the input fields from the dataset to add context\n",
    "results_df[\"question\"] = eval_dataset[\"question\"]\n",
    "results_df[\"ground_truth\"] = eval_dataset[\"ground_truth\"]\n",
    "results_df[\"answer\"] = eval_dataset[\"answer\"]\n",
    "\n",
    "# Reorder columns for better readability\n",
    "results_df = results_df[[\n",
    "    \"question\", \n",
    "    \"answer\", \n",
    "    \"ground_truth\", \n",
    "    \"answer_correctness\",\n",
    "    \"context_recall\", \n",
    "    \"context_precision\",\n",
    "    \"faithfulness\"\n",
    "]]\n",
    "\n",
    "# print(\"\\nğŸ“ˆ Evaluation Results:\")\n",
    "# print(results_df)\n",
    "create_rag_evaluation_table(results_df, show_contexts=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fdbe5e4-f430-4169-beb8-10cc9d73e55b",
   "metadata": {},
   "source": [
    "# å‰–æ Ragas è¯„ä¼°æŒ‡æ ‡\n",
    "\n",
    "---\n",
    "\n",
    "æˆ‘ä»¬å·²ç»è·‘è¿‡è¯„ä¼°å¹¶å¾—åˆ°äº†åˆ†æ•°ã€‚ç°åœ¨è¯¥æ€å¼€å¼•æ“ç›–ï¼Œå¼„æ¸…æ¥šæ¯ä¸ªæŒ‡æ ‡åˆ°åº•æ„å‘³ç€ä»€ä¹ˆã€‚å°±åƒåŒ»ç”Ÿä¼šé€šè¿‡ä¸åŒçš„è¡€æ¶²æ£€æµ‹æ¥è¯Šæ–­ç—…ç—‡ä¸€æ ·ï¼Œæˆ‘ä»¬ä½¿ç”¨è¿™äº›æŒ‡æ ‡æ¥è¯Šæ–­ RAG ç®¡çº¿çš„å¥åº·çŠ¶å†µã€‚\n",
    "\n",
    "è®°ä½ï¼Œè¿™äº›åˆ†æ•°ä¸åªæ˜¯æ€»æˆç»©â€”â€”å®ƒä»¬æ˜¯ä¸€ä»½è¯Šæ–­æŠ¥å‘Šã€‚`answer_correctness` å¾—åˆ†åä½è¯´æ˜â€œæ‚£è€…ç”Ÿç—…äº†â€ï¼Œè€Œå…¶ä»–æŒ‡æ ‡åˆ™å‘Šè¯‰æˆ‘ä»¬â€œç—…å› ä½•åœ¨â€ã€‚\n",
    "\n",
    "> **æ³¨æ„ï¼š**  \n",
    "> æ¯ä¸ª Ragas è¯„ä¼°æŒ‡æ ‡éƒ½æœ‰ LLM ç‰ˆå’Œé LLM ç‰ˆä¸¤ç§ã€‚Ragas é»˜è®¤é‡‡ç”¨ LLM é©±åŠ¨çš„è¯„ä¼°æŒ‡æ ‡ï¼Œæœ¬èŠ‚ä¹Ÿå°†å›´ç»•è¿™ä¸€å¥—å±•å¼€ã€‚  \n",
    "> è¯¦æƒ…å¯å‚è§ [Ragas æ–‡æ¡£](https://docs.ragas.io/en/stable/concepts/metrics/available_metrics/)ã€‚\n",
    "\n",
    "ä¸‹é¢æˆ‘ä»¬é€ä¸€æ·±å…¥äº†è§£æ‰€ä½¿ç”¨çš„å››ä¸ªæ ¸å¿ƒæŒ‡æ ‡ã€‚\n",
    "\n",
    "## ä¸Šä¸‹æ–‡å¬å›ç‡ï¼ˆContext Recallï¼‰\n",
    "\n",
    "> æˆ‘ä»¬æ˜¯å¦æ‰¾åˆ°äº†æ­£ç¡®çš„ä¿¡æ¯ï¼Ÿ\n",
    "\n",
    "**è¡¡é‡å†…å®¹ï¼š**  \n",
    "ä¸Šä¸‹æ–‡å¬å›ç‡ç”¨äºå›ç­”ä¸€ä¸ªå…³é”®é—®é¢˜ï¼šæˆ‘ä»¬çš„æ£€ç´¢å™¨æ˜¯å¦æ‰¾åˆ°äº†å›ç­”é—®é¢˜æ‰€éœ€çš„å…¨éƒ¨ä¿¡æ¯ï¼Ÿå®ƒè¡¡é‡çš„æ˜¯â€œå‚è€ƒç­”æ¡ˆä¸­çš„ç›¸å…³äº‹å®ï¼Œæœ‰å¤šå°‘æ¯”ä¾‹å‡ºç°åœ¨æ£€ç´¢åˆ°çš„ä¸Šä¸‹æ–‡ä¸­â€ã€‚\n",
    "\n",
    "**é‡è¦æ€§ï¼š**  \n",
    "è¿™æ˜¯æ„å»ºå¯é  RAG ç³»ç»Ÿçš„åœ°åŸºã€‚å¦‚æœæ£€ç´¢ä¸åˆ°æ­£ç¡®çš„ä¿¡æ¯ï¼ŒLLM å°±åƒåœ¨æ‘¸é»‘å·¥ä½œâ€”â€”å³ä¾¿æ¨¡å‹å†å¼ºï¼Œä¹Ÿæ— æ³•å‡­ç©ºç”Ÿæˆç¼ºå¤±çš„äº‹å®ã€‚å¬å›å¾—åˆ†é«˜ï¼Œè¯´æ˜æ£€ç´¢é˜¶æ®µå®Œæˆå¾—å¾ˆåˆ°ä½ã€‚\n",
    "\n",
    "Ragas çš„åšæ³•æ˜¯æŠŠ `ground_truth` æ‹†æˆä¸€ä¸ªä¸ªæœ€å°â€œé™ˆè¿°â€ï¼Œå†æ£€æŸ¥æ¯æ¡é™ˆè¿°æ˜¯å¦èƒ½åœ¨ `retrieved_contexts` ä¸­æ‰¾åˆ°ä¾æ®ã€‚å…¬å¼å¦‚ä¸‹ï¼š\n",
    "\n",
    "$$\n",
    "    \\text{Context Recall} = \\frac{\\text{å‚è€ƒç­”æ¡ˆä¸­è¢«æ£€ç´¢ä¸Šä¸‹æ–‡æ”¯æŒçš„é™ˆè¿°æ•°é‡}}{\\text{å‚è€ƒç­”æ¡ˆä¸­çš„é™ˆè¿°æ€»æ•°}}\n",
    "$$\n",
    "\n",
    "### ç›´è§‚ç¤ºä¾‹\n",
    "\n",
    "æˆ‘ä»¬æ¥æ„é€ ä¸€ä¸ªç®€å•çš„æµ‹è¯•ç”¨ä¾‹ï¼Œçœ‹çœ‹æ£€ç´¢åˆ°çš„ä¸Šä¸‹æ–‡å¦‚ä½•ç›´æ¥å½±å“å¬å›å¾—åˆ†ã€‚è¿™é‡Œç»§ç»­æ²¿ç”¨ä¹‹å‰è®¾ç½®å¥½çš„ `ragas_llm` ä¸ `ragas_embeddings`ã€‚\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b33ca2-7d5a-48b3-85fd-e2a000cd145a",
   "metadata": {
    "ExecutionIndicator": {
     "show": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from functions.metric_barchart import plot_metric_comparison\n",
    "\n",
    "# Define the test scenario\n",
    "question = \"How many tasks are due today?\"\n",
    "\n",
    "# The ground truth contains 4 distinct claims\n",
    "ground_truth = (\n",
    "    \"1. Finalize Q3 OKRs is due today, \"\n",
    "    \"2. Onboard new team member is due today, \"\n",
    "    \"3. Update project roadmap is due today, \"\n",
    "    \"4. Write thank-you letter is due today.\"\n",
    ")\n",
    "\n",
    "# Test Case 1: Perfect Retrieval - All 4 claims are present\n",
    "contexts_perfect = [\n",
    "    [\n",
    "        \"ID 01: Finalize Q3 OKRs - Due: Today\",\n",
    "        \"ID 03: Onboard new team member - Due: Today\",\n",
    "        \"ID 05: Update project roadmap - Due: Today\",\n",
    "        \"ID 14: Write thank-you letter - Due: Today\"\n",
    "    ]\n",
    "]\n",
    "\n",
    "# Test Case 2: Partial Retrieval - Only 2 claims are present\n",
    "contexts_partial = [\n",
    "    [\n",
    "        \"ID 01: Finalize Q3 OKRs - Due: Today\",\n",
    "        \"ID 05: Update project roadmap - Due: Today\",\n",
    "    ]\n",
    "]\n",
    "\n",
    "# Test Case 3: No Retrieval - 0 claims are present\n",
    "contexts_none = [\n",
    "    [\n",
    "        \"ID 02: Prepare presentation - Due: This Week\",\n",
    "        \"ID 08: Clean up email - Due: This Year\"\n",
    "    ]\n",
    "]\n",
    "\n",
    "# Create datasets\n",
    "data_perfect = {\"question\": [question], \"ground_truth\": [ground_truth], \"contexts\": contexts_perfect}\n",
    "data_partial = {\"question\": [question], \"ground_truth\": [ground_truth], \"contexts\": contexts_partial}\n",
    "data_none = {\"question\": [question], \"ground_truth\": [ground_truth], \"contexts\": contexts_none}\n",
    "\n",
    "dataset_perfect = Dataset.from_dict(data_perfect)\n",
    "dataset_partial = Dataset.from_dict(data_partial)\n",
    "dataset_none = Dataset.from_dict(data_none)\n",
    "\n",
    "# Evaluate all three cases\n",
    "result_perfect = evaluate(dataset_perfect, metrics=[context_recall], llm=ragas_llm, embeddings=ragas_embeddings)\n",
    "result_partial = evaluate(dataset_partial, metrics=[context_recall], llm=ragas_llm, embeddings=ragas_embeddings)\n",
    "result_none = evaluate(dataset_none, metrics=[context_recall], llm=ragas_llm, embeddings=ragas_embeddings)\n",
    "\n",
    "# Extract scores\n",
    "scores = {\n",
    "    \"Perfect Retrieval\\n(4/4 claims)\": result_perfect[\"context_recall\"],\n",
    "    \"Partial Retrieval\\n(2/4 claims)\": result_partial[\"context_recall\"],\n",
    "    \"No Relevant Retrieval\\n(0/4 claims)\": result_none[\"context_recall\"]\n",
    "}\n",
    "\n",
    "# Generate comparison chart\n",
    "plot_metric_comparison(\n",
    "    scores_dict=scores,\n",
    "    title=\"Context Recall Score vs. Retrieved Information Quality\",\n",
    "    ylabel=\"Context Recall Score\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7eab11-cdb4-4e9f-bcc1-256fb2df8e35",
   "metadata": {},
   "source": [
    "**å›¾è¡¨è§£è¯»ï¼š**  \n",
    "å¬å›åˆ†æ•°ä¼šéšç€æ£€ç´¢åˆ°çš„ç›¸å…³ä¿¡æ¯é‡çº¿æ€§ä¸‹é™ã€‚è¿™è¯æ˜å¬å›æœ¬è´¨ä¸Šåæ˜ çš„æ˜¯æ£€ç´¢çš„å®Œæ•´æ€§ã€‚\n",
    "\n",
    "### æå‡ä¸Šä¸‹æ–‡å¬å›ç‡\n",
    "\n",
    "* **è°ƒæ•´å—å¤§å°ï¼ˆChunk Sizeï¼‰ï¼š** å¦‚æœæ–‡æœ¬å—å¤ªå°ï¼Œå•æ¡äº‹å®å¯èƒ½è¢«æ‹†æ•£åˆ°å¤šä¸ªå—é‡Œã€‚å°è¯•å°† `chunk_size` ä» 128 å¢å¤§åˆ° 512ã€‚\n",
    "* **ä½¿ç”¨å—é‡å ï¼ˆChunk Overlapï¼‰ï¼š** åœ¨æ–‡æœ¬åˆ‡åˆ†å™¨ä¸­åŠ å…¥ `chunk_overlap=100`ï¼Œä»¥ä¿ç•™è¾¹ç•Œå¤„çš„ä¸Šä¸‹æ–‡ã€‚\n",
    "* **ä¼˜åŒ–åµŒå…¥æ¨¡å‹ï¼š** è¯•è¯•ä¸åŒçš„åµŒå…¥æ¨¡å‹ã€‚æ›´ç¬¦åˆä½ é¢†åŸŸæ•°æ®çš„æ¨¡å‹ä¼šç”Ÿæˆæ›´æœ‰æ„ä¹‰çš„å‘é‡è¡¨ç¤ºã€‚\n",
    "* **å®æ–½é‡æ’åºï¼ˆRe-rankingï¼‰ï¼š** ä½¿ç”¨äº¤å‰ç¼–ç å™¨æ¨¡å‹å¯¹åˆæ¬¡æ£€ç´¢ç»“æœè¿›è¡Œé‡æ’ï¼ŒæŠŠæœ€ç›¸å…³çš„æ–‡æœ¬å—æå‡åˆ°å‰é¢ã€‚\n",
    "* **é‡‡ç”¨æ··åˆæ£€ç´¢ï¼š** å°†å‘é‡æ£€ç´¢ä¸å…³é”®è¯æ£€ç´¢ï¼ˆå¦‚ BM25ï¼‰ç»“åˆï¼Œæ•æ‰ä»…é åµŒå…¥å¯èƒ½é—æ¼çš„æ–‡æ¡£ã€‚\n",
    "\n",
    "\n",
    "## ä¸Šä¸‹æ–‡ç²¾åº¦ï¼ˆContext Precisionï¼‰\n",
    "\n",
    "> æˆ‘ä»¬æ£€ç´¢æ¥äº†å¤šå°‘å™ªå£°ï¼Ÿ\n",
    "\n",
    "**è¡¡é‡å†…å®¹ï¼š**  \n",
    "ä¸Šä¸‹æ–‡ç²¾åº¦èšç„¦äºä¸€ä¸ªå…³é”®é—®é¢˜ï¼š**æˆ‘ä»¬æ£€ç´¢åˆ°çš„æ‰€æœ‰æ–‡æœ¬å—ä¸­ï¼Œæœ‰å¤šå°‘çœŸæ­£ä¸æŸ¥è¯¢ç›¸å…³ï¼Ÿ**  \n",
    "å®ƒè¡¡é‡çš„æ˜¯æ£€ç´¢é˜¶æ®µçš„ä¿¡å™ªæ¯”ã€‚\n",
    "\n",
    "**é‡è¦æ€§ï¼š**  \n",
    "å¦‚æœç²¾åº¦å¾—åˆ†å¾ˆä½ï¼Œè¯´æ˜ LLM æ­£åœ¨è¢«å¤§é‡æ— å…³ä¿¡æ¯â€œæŠ•å–‚â€ã€‚è¿™ä¸ä»…ä¼šåˆ†æ•£æ¨¡å‹æ³¨æ„åŠ›ã€æ¨é«˜å¤„ç†æˆæœ¬ï¼Œè¿˜å¯èƒ½è®©æ¨¡å‹è¢«â€œä¼ªçº¿ç´¢â€è¯¯å¯¼è€Œç»™å‡ºé”™è¯¯ç­”æ¡ˆã€‚\n",
    "\n",
    "Ragas é€šè¿‡â€œLLM è£åˆ¤â€æ¥è®¡ç®—è¯¥æŒ‡æ ‡ã€‚å®ƒä¸æ˜¯ç®€å•çš„ç®—æœ¯è¿ç®—ï¼Œè€Œæ˜¯è°ƒç”¨ä¸€ä¸ªç‹¬ç«‹çš„â€œè¯„ä¼°å™¨â€LLMï¼Œç»¼åˆåˆ†æ `question`ã€`ground_truth` ä¸ `retrieved_contexts`ï¼Œè¯„ä¼°æ£€ç´¢åˆ°çš„æ–‡æœ¬å—å¯¹é—®é¢˜çš„ç›¸å…³ç¨‹åº¦ï¼Œä»¥åŠæœ€æœ‰ç”¨çš„ä¿¡æ¯æ˜¯å¦æ’åœ¨åˆ—è¡¨å‰åˆ—ã€‚\n",
    "\n",
    "å› æ­¤ï¼Œè¿™ä¸ªåˆ†æ•°åæ˜ çš„æ˜¯å¯¹æ£€ç´¢è´¨é‡çš„ç»†è‡´åˆ¤æ–­ï¼ŒåŒæ—¶è€ƒè™‘äº†æ–‡æœ¬å—çš„ç›¸å…³æ€§ä¸æ’åºã€‚\n",
    "\n",
    "$$\n",
    "    \\text{Precision@k} = {\\text{true positives@k} \\over  (\\text{true positives@k} + \\text{false positives@k})}\n",
    "$$\n",
    "\n",
    "\n",
    "### ç›´è§‚ç¤ºä¾‹\n",
    "\n",
    "æˆ‘ä»¬æ¥çœ‹çœ‹æ–‡æœ¬å—çš„æ’åˆ—é¡ºåºå¦‚ä½•å½±å“ `context_precision` åˆ†æ•°ã€‚è¿™é‡Œä½¿ç”¨ä¸€ä¸ªç®€å•çš„æŸ¥è¯¢å’Œä¸‰ç»„ä¸åŒçš„æ£€ç´¢ç»“æœã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc887b4-6ed2-4df2-8026-3a9a868163f8",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the test scenario\n",
    "question = \"When is the project roadmap due?\"\n",
    "\n",
    "# Ground truth (based on your data, it's \"Project Leads\")\n",
    "ground_truth = \"The project roadmap is due today.\"\n",
    "\n",
    "# Test Case 1: High Precision\n",
    "contexts_high = [\n",
    "    [\n",
    "        \"Update project roadmap is due today\"\n",
    "    ]\n",
    "]\n",
    "\n",
    "# Test Case 2: Med Precision\n",
    "contexts_med = [\n",
    "    [\n",
    "        \"Trip to Norway is in November\",\n",
    "        \"Update project roadmap is due today\",                   # Correct answer is preceded by one false answer\n",
    "        \"Write to penpal needs to be completed within 24 hours\"\n",
    "    ]\n",
    "]\n",
    "\n",
    "# Test Case 3: Low Precision\n",
    "contexts_low = [\n",
    "    [\n",
    "        \"Trip to Norway is in November\",\n",
    "        \"Write to penpal needs to be completed within 24 hours\",\n",
    "        \"Update project roadmap is due today\"                    # Correct answer is preceded by two false answers\n",
    "    ]\n",
    "]\n",
    "\n",
    "\n",
    "# Create and evaluate datasets\n",
    "def create_and_evaluate(contexts_list, question, ground_truth):\n",
    "    dataset = Dataset.from_dict({\n",
    "        \"question\": [question],\n",
    "        \"ground_truth\": [ground_truth],\n",
    "        \"contexts\": contexts_list\n",
    "    })\n",
    "    result = evaluate(dataset, metrics=[context_precision], llm=ragas_llm, embeddings=ragas_embeddings)\n",
    "    return result[\"context_precision\"]\n",
    "\n",
    "scores = {\n",
    "    \"High Precision\\n(Correct answer at top)\": create_and_evaluate(contexts_high, question, ground_truth),\n",
    "    \"Med Precision\\n(Correct answer buried once)\": create_and_evaluate(contexts_med, question, ground_truth),\n",
    "    \"Low Precision\\n(Correct answer buried twice)\": create_and_evaluate(contexts_low, question, ground_truth)\n",
    "}\n",
    "\n",
    "# Generate comparison chart\n",
    "plot_metric_comparison(\n",
    "    scores_dict=scores,\n",
    "    title=\"Context Precision Score: When Answers are Buried\",\n",
    "    ylabel=\"Context Precision Score\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d2b424-b0a4-434b-8299-634a8f668454",
   "metadata": {},
   "source": [
    "**å›¾è¡¨è§£è¯»ï¼š**  \n",
    "\n",
    "* **é«˜åˆ†ï¼ˆ1.000ï¼‰ï¼š** è¯„ä¼°å™¨ LLM è®¤ä¸ºç»“æœå®Œç¾ã€‚å”¯ä¸€æ£€ç´¢åˆ°çš„å—é«˜åº¦ç›¸å…³ï¼Œè€Œä¸”æ’åœ¨æœ€å‰ã€‚\n",
    "* **ä¸­ç­‰ï¼ˆ0.500ï¼‰ï¼š** è¯„ä¼°å™¨ LLM å‘ç°æ­£ç¡®ä¿¡æ¯è™½ç„¶å­˜åœ¨ï¼Œä½†å‰é¢å¤¹ç€ä¸€ä¸ªæ— å…³å—ã€‚è¿™ç±»â€œå™ªå£°â€ä¼šè¢«æƒ©ç½šï¼Œä»è€Œæ˜¾è‘—æ‹‰ä½å¾—åˆ†ã€‚\n",
    "* **ä½åˆ†ï¼ˆ0.333ï¼‰ï¼š** è¯„ä¼°å™¨ LLM çœ‹åˆ°æ­£ç¡®ä¿¡æ¯è¢«ä¸¤ä¸ªæ— å…³å—æ©ç›–ã€‚æ’åºè´¨é‡ä½ï¼Œè¯´æ˜å™ªå£°å¾ˆå¤šã€‚\n",
    "\n",
    "è¿™ä¸ªå®éªŒè¯æ˜ `context_precision` ä¸ä»…å…³ä¹â€œæ£€ç´¢åˆ°ä»€ä¹ˆâ€ï¼Œä¹Ÿå…³ä¹â€œå¦‚ä½•æ’åºâ€ã€‚é«˜ç²¾åº¦å¾—åˆ†æ„å‘³ç€æ£€ç´¢ç³»ç»Ÿæ—¢èƒ½æ‰¾åˆ°æ­£ç¡®ä¿¡æ¯ï¼Œä¹Ÿèƒ½ä»¥ LLM æ˜“äºåˆ©ç”¨çš„é¡ºåºå‘ˆç°ã€‚\n",
    "\n",
    "### æå‡ä¸Šä¸‹æ–‡ç²¾åº¦\n",
    "\n",
    "* **è°ƒæ•´ç›¸ä¼¼åº¦é˜ˆå€¼ï¼š** ç­›æ‰ç›¸ä¼¼åº¦ä½äºæŸé˜ˆå€¼çš„æ–‡æœ¬å—ã€‚\n",
    "* **ä½¿ç”¨æŸ¥è¯¢é‡å†™ï¼š** ä¾‹å¦‚é‡‡ç”¨ HyDEï¼ˆå‡æƒ³æ–‡æ¡£åµŒå…¥ï¼‰ç­‰æ–¹æ³•ï¼Œåœ¨æ£€ç´¢å‰ç”Ÿæˆæ›´ä¼˜çš„æŸ¥è¯¢ã€‚\n",
    "* **åˆ©ç”¨å…ƒæ•°æ®è¿‡æ»¤ï¼š** å¦‚æœæ•°æ®é™„å¸¦å…ƒæ•°æ®ï¼ˆå¦‚ task_typeã€priorityï¼‰ï¼Œå¯åœ¨å‘é‡æ£€ç´¢å‰æ®æ­¤ç¼©å°æœç´¢èŒƒå›´ã€‚\n",
    "* **å®ç°é‡æ’åºï¼š** å€ŸåŠ©é‡æ’åºå™¨ï¼ˆre-rankerï¼‰ï¼ŒæŠŠå‘é‡ä¸Šæ¥è¿‘ä½†æ— å…³çš„æ–‡æœ¬å—å‹åˆ°åé¢ã€‚\n",
    "\n",
    "ä¼˜åŒ–ä¸Šä¸‹æ–‡ç²¾åº¦ï¼Œèƒ½è®© LLM é¢å¯¹çš„æ˜¯ä¸€ç»„å¹²å‡€ã€èšç„¦ä¸”æ’åºåˆç†çš„ä¿¡æ¯ï¼Œä»è€Œæœ€å¤§åŒ–äº§å‡ºå‡†ç¡®ä¸”æœ‰ç”¨å›ç­”çš„æ¦‚ç‡ã€‚\n",
    "\n",
    "\n",
    "## å¿ å®åº¦ï¼ˆFaithfulnessï¼‰\n",
    "\n",
    "**è¡¡é‡å†…å®¹ï¼š**  \n",
    "å¿ å®åº¦å…³æ³¨çš„é—®é¢˜æ˜¯ï¼š*LLM æ˜¯å¦å‡ºç°å¹»è§‰ï¼Ÿå›ç­”æ˜¯å¦ä¸¥æ ¼ä¾æ®æä¾›çš„ä¸Šä¸‹æ–‡ï¼Ÿ*  \n",
    "å®ƒè¡¡é‡çš„æ˜¯ç”Ÿæˆç­”æ¡ˆä¸­æœ‰å¤šå°‘é™ˆè¿°èƒ½å¤Ÿè¢«æ£€ç´¢åˆ°çš„ä¸Šä¸‹æ–‡ç›´æ¥æ”¯æŒã€‚\n",
    "\n",
    "**é‡è¦æ€§ï¼š**  \n",
    "è¿™æ˜¯æ„å»ºå¯ä¿¡ AI çš„å…³é”®ã€‚å¿ å®åº¦é«˜æ„å‘³ç€ LLM ä¸åœ¨å‡­ç©ºæé€ å†…å®¹ï¼Œè€Œæ˜¯åŸºäºè¯æ®ç»™å‡ºå›ç­”ã€‚\n",
    "\n",
    "è®¡ç®—æ–¹æ³•ä¸å¬å›ç±»ä¼¼ï¼Œä½†æ–¹å‘ç›¸åï¼š\n",
    "\n",
    "$$\n",
    "    \\text{Faithfulness Score} = \\frac{\\text{å›ç­”ä¸­å¾—åˆ°æ£€ç´¢ä¸Šä¸‹æ–‡æ”¯æŒçš„é™ˆè¿°æ•°é‡}}{\\text{å›ç­”ä¸­çš„é™ˆè¿°æ€»æ•°}}\n",
    "$$\n",
    "\n",
    "### ç›´è§‚ç¤ºä¾‹\n",
    "æˆ‘ä»¬æ¥æ„é€ ä¸€ä¸ªåŒ…å«å¹»è§‰çš„å›ç­”ã€‚\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ccc290e-3524-4de2-a1c1-bc537c081666",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the test case\n",
    "question = \"When is the 'Develop 3-year plan' task due?\"\n",
    "\n",
    "# The ground truth\n",
    "ground_truth = \"This Year\"\n",
    "\n",
    "# The retrieved context (our source of truth)\n",
    "contexts = [\n",
    "    [\n",
    "        \"The 'Develop 3-year plan' task is due 'This Year'.\",\n",
    "        \"The 'Finalize Q3 OKRs' task is due 'Today'.\"\n",
    "    ]\n",
    "]\n",
    "\n",
    "# Test Case 1: Faithful Answer\n",
    "answer_faithful = \"The 'Develop 3-year plan' task is due 'This Year.'\"\n",
    "\n",
    "# Test Case 2: Hallucinated Answer\n",
    "answer_hallucinated = \"The 'Develop 3-year plan' task is due 'This Year,' and it must be approved by the CFO before submission.\"\n",
    "\n",
    "# Create datasets\n",
    "dataset_faithful = Dataset.from_dict({\n",
    "    \"question\": [question],\n",
    "    \"answer\": [answer_faithful],\n",
    "    \"contexts\": contexts\n",
    "})\n",
    "\n",
    "dataset_hallucinated = Dataset.from_dict({\n",
    "    \"question\": [question],\n",
    "    \"answer\": [answer_hallucinated],\n",
    "    \"contexts\": contexts\n",
    "})\n",
    "\n",
    "# Evaluate\n",
    "result_faithful = evaluate(dataset_faithful, metrics=[faithfulness], llm=ragas_llm, embeddings=ragas_embeddings)\n",
    "result_hallucinated = evaluate(dataset_hallucinated, metrics=[faithfulness], llm=ragas_llm, embeddings=ragas_embeddings)\n",
    "\n",
    "# Prepare data for comparison\n",
    "scores = {\n",
    "    \"Faithful Answer\\n(Claims supported by context)\": result_faithful[\"faithfulness\"],\n",
    "    \"Hallucinated Answer\\n(Claim about 'CFO approval' unsupported)\": result_hallucinated[\"faithfulness\"]\n",
    "}\n",
    "\n",
    "# Generate comparison chart\n",
    "plot_metric_comparison(\n",
    "    scores_dict=scores,\n",
    "    title='Faithfulness Score: Accurate vs. Hallucinated Answer',\n",
    "    ylabel='Faithfulness Score'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a62210-07d1-4fc7-84e9-5dd7505c151f",
   "metadata": {},
   "source": [
    "**å›¾è¡¨è§£è¯»ï¼š**  \n",
    "å¸¦æœ‰å¹»è§‰çš„å›ç­”è·å¾—äº†æ›´ä½çš„å¿ å®åº¦å¾—åˆ†ã€‚å…³äºâ€œéœ€è¦ CFO æ‰¹å‡†â€çš„é™ˆè¿°æ²¡æœ‰ä»»ä½•ä¸Šä¸‹æ–‡æ”¯æ’‘ï¼Œå› è€Œæ‹‰ä½äº†æ•´ä½“å¾—åˆ†ã€‚\n",
    "\n",
    "### æå‡å¿ å®åº¦\n",
    "\n",
    "* **å¼ºåŒ–æç¤ºè¯ï¼š** æ˜ç¡®å†™å‡ºâ€œè¯·ä»…æ ¹æ®ä¸‹æ–¹ä¸Šä¸‹æ–‡ä½œç­”ï¼›è‹¥ä¸Šä¸‹æ–‡æœªåŒ…å«ç­”æ¡ˆï¼Œè¯·å›ç­”â€˜I don't know.â€™â€ç­‰æŒ‡ä»¤ã€‚\n",
    "* **æ›´æ¢ LLMï¼š** ä¸åŒ LLM çš„å¹»è§‰å€¾å‘å·®å¼‚å¾ˆå¤§ï¼Œå¯è€ƒè™‘é€‰æ‹©æ›´æ³¨é‡æ‰æ ¹äº‹å®çš„æ¨¡å‹ã€‚\n",
    "* **å¯¹ç­”æ¡ˆåšåå¤„ç†ï¼š** åŠ ä¸€é“éªŒè¯æµç¨‹ï¼Œç”±å¦ä¸€æ¨¡å‹æ£€æŸ¥å›ç­”æ˜¯å¦å¾—åˆ°ä¸Šä¸‹æ–‡æ”¯æŒã€‚\n",
    "\n",
    "## ç­”æ¡ˆæ­£ç¡®åº¦ï¼ˆAnswer Correctnessï¼‰\n",
    "\n",
    "**è¡¡é‡å†…å®¹ï¼š**   \n",
    "ç­”æ¡ˆæ­£ç¡®åº¦æ˜¯é¢å‘ç”¨æˆ·çš„â€œç»ˆææŒ‡æ ‡â€ã€‚  \n",
    "å®ƒå›ç­”çš„é—®é¢˜æ˜¯ï¼š*æœ€ç»ˆç­”æ¡ˆä¸å‚è€ƒç­”æ¡ˆç›¸æ¯”ï¼Œæ˜¯å¦æ­£ç¡®ä¸”å®Œæ•´ï¼Ÿ*\n",
    "\n",
    "**é‡è¦æ€§ï¼š**\n",
    "è¿™æ˜¯ç”¨æˆ·çœŸæ­£çœ‹åˆ°çš„éƒ¨åˆ†ã€‚é«˜æ­£ç¡®åº¦æ„å‘³ç€ç³»ç»Ÿæ­£åœ¨è¾“å‡ºæœ‰ä»·å€¼çš„ç»“æœã€‚\n",
    "\n",
    "Ragas å°†è¯­ä¹‰ç›¸ä¼¼åº¦ï¼ˆå›ç­”æ˜¯å¦è¡¨è¾¾ç›¸åŒå«ä¹‰ï¼‰ä¸äº‹å®å‡†ç¡®æ€§ï¼ˆå…·ä½“äº‹å®æ˜¯å¦æ­£ç¡®ï¼‰èåˆä¸ºä¸€ä¸ªåˆ†æ•°ï¼Œä½¿ç”¨ç±»ä¼¼ F1 çš„æ–¹å¼è®¡ç®—äº‹å®é‡å åº¦ã€‚äº‹å®å‡†ç¡®æ€§ä¼šåº¦é‡ç”Ÿæˆç­”æ¡ˆä¸å‚è€ƒç­”æ¡ˆä¹‹é—´äº‹å®çš„é‡åˆæƒ…å†µï¼Œå¯¹åº”ä»¥ä¸‹æ¦‚å¿µï¼š\n",
    "\n",
    "ç­”æ¡ˆæ­£ç¡®åº¦çš„è®¡ç®—å…¬å¼å¦‚ä¸‹ï¼š\n",
    "\n",
    "$$\n",
    "    \\text{F1 Score} = {|\\text{TP}| \\over {(|\\text{TP}| + 0.5 \\times (|\\text{FP}| + |\\text{FN}|))}}\n",
    "$$\n",
    "\n",
    "å…¶ä¸­ï¼š\n",
    "\n",
    "* **TPï¼ˆçœŸæ­£ï¼‰ï¼š** åŒæ—¶å‡ºç°åœ¨å‚è€ƒç­”æ¡ˆå’Œç”Ÿæˆç­”æ¡ˆä¸­çš„äº‹å®æˆ–é™ˆè¿°ã€‚\n",
    "* **FPï¼ˆå‡æ­£ï¼‰ï¼š** ä»…å‡ºç°åœ¨ç”Ÿæˆç­”æ¡ˆè€Œä¸åœ¨å‚è€ƒç­”æ¡ˆä¸­çš„äº‹å®æˆ–é™ˆè¿°ã€‚\n",
    "* **FNï¼ˆå‡è´Ÿï¼‰ï¼š** ä»…å‡ºç°åœ¨å‚è€ƒç­”æ¡ˆè€Œä¸åœ¨ç”Ÿæˆç­”æ¡ˆä¸­çš„äº‹å®æˆ–é™ˆè¿°ã€‚\n",
    "\n",
    "\n",
    "### ç›´è§‚ç¤ºä¾‹\n",
    "\n",
    "æˆ‘ä»¬æ¥æ¯”è¾ƒä¸€ä¸ªå®Œç¾ç­”æ¡ˆã€ä¸€ä¸ªéƒ¨åˆ†æ­£ç¡®çš„ç­”æ¡ˆï¼Œä»¥åŠä¸€ä¸ªé”™è¯¯ç­”æ¡ˆã€‚\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97282658-df6b-42fe-bc9a-cbaa83a688d8",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Ground truth\n",
    "ground_truth = \"4 tasks are due today: Finalize Q3 OKRs, Onboard new team member, Update project roadmap, Write thank-you letter to penpal.\"\n",
    "\n",
    "# Define test cases\n",
    "test_cases = [\n",
    "    {\n",
    "        \"answer\": \"There are 4 tasks due today: Finalize Q3 OKRs, Onboard new team member, Update project roadmap, and Write thank-you letter to penpal.\",\n",
    "        \"label\": \"Perfect Answer\\n(All facts correct)\"\n",
    "    },\n",
    "    {\n",
    "        \"answer\": \"One task is due today: Finalize Q3 OKRs.\",\n",
    "        \"label\": \"Partially Correct\\n(1 fact correct, 3 missing)\"\n",
    "    },\n",
    "    {\n",
    "        \"answer\": \"No tasks are due today.\",\n",
    "        \"label\": \"Wrong Answer\\n(0 facts correct)\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Evaluate each case\n",
    "scores = {}\n",
    "for case in test_cases:\n",
    "    dataset = Dataset.from_dict({\n",
    "        \"question\": [question],\n",
    "        \"answer\": [case[\"answer\"]],\n",
    "        \"ground_truth\": [ground_truth]\n",
    "    })\n",
    "    result = evaluate(dataset, metrics=[answer_correctness], llm=ragas_llm, embeddings=ragas_embeddings)\n",
    "    scores[case[\"label\"]] = result[\"answer_correctness\"]\n",
    "\n",
    "# Generate the chart using our reusable function\n",
    "plot_metric_comparison(\n",
    "    scores_dict=scores,\n",
    "    title='Answer Correctness Score for Different Answer Qualities',\n",
    "    ylabel='Answer Correctness Score'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925c1f1b-57fe-4828-9f0b-14178ca3aa12",
   "metadata": {},
   "source": [
    "**å›¾è¡¨è§£è¯»ï¼š**  \n",
    "å¾—åˆ†ç›´æ¥åæ˜ æœ€ç»ˆè¾“å‡ºçš„è´¨é‡â€”â€”å®Œæ•´æ€§è¶Šé«˜ã€é”™è¯¯è¶Šå°‘ï¼Œå¾—åˆ†è¶Šé«˜ã€‚\n",
    "\n",
    "### æå‡ç­”æ¡ˆæ­£ç¡®åº¦\n",
    "\n",
    "* **å…ˆè§£å†³ä¸Šæ¸¸é—®é¢˜ï¼š** ç­”æ¡ˆæ­£ç¡®åº¦å¾€å¾€åªæ˜¯ç—‡çŠ¶ã€‚åˆ©ç”¨å…¶ä»–æŒ‡æ ‡ï¼ˆä¾‹å¦‚ä½å¬å›ï¼‰æ¥å®šä½æ ¹å› ã€‚\n",
    "* **ä¼˜åŒ–æç¤ºè¯ï¼š** ä½¿ç”¨é¼“åŠ±ç»“æ„åŒ–ã€å®Œæ•´å›ç­”çš„æç¤ºï¼Œä¾‹å¦‚â€œåˆ—å‡ºä»Šå¤©åˆ°æœŸçš„æ‰€æœ‰ä»»åŠ¡â€ã€‚\n",
    "* **å¯ç”¨å¤šæ­¥æ¨ç†ï¼š** æ¢ç”¨æ›´å¼ºå¤§çš„ LLMï¼Œæˆ–æç¤ºå®ƒâ€œé€æ­¥æ€è€ƒâ€ï¼Œé¿å…é—æ¼ç»†èŠ‚ã€‚\n",
    "\n",
    "\n",
    "## ä»æŒ‡æ ‡ä¸­æç‚¼å¯æ‰§è¡Œæ´è§\n",
    "\n",
    "è¯„ä¼°çš„çœŸæ­£ä»·å€¼åœ¨äºç»„åˆè¿™äº›æŒ‡æ ‡ã€‚å¦‚æœå•ç‹¬çœ‹æŸä¸€ä¸ªï¼Œå¾ˆå®¹æ˜“äº§ç”Ÿè¯¯å¯¼ã€‚è¯Šæ–­çš„é­”åŠ›åœ¨äºç»¼åˆåˆ†æã€‚\n",
    "\n",
    "```mermaid\n",
    "graph TD\n",
    "    classDef frameworkStyle fill:#ffffff,stroke:#1f77b4,stroke-width:2px;\n",
    "\n",
    "    subgraph flowchat [Diagnosis Flowchart]\n",
    "        A[Low Answer Correctness] --> C{Low Context Recall}\n",
    "        C -->|Yes| D[Retrieval Problem: <br>Critical info missing.<br>Fix chunking/embeddings.]\n",
    "        C -->|No| E{Low Context Precision}\n",
    "        E -->|Yes| F[Distracted LLM: <br>Too much noise in context.<br>Improve retrieval filtering/re-ranking.]\n",
    "        E -->|No| G{Low Faithfulness}\n",
    "        G -->|Yes| H[Generation Problem: <br>LLM is hallucinating.<br>Fix prompt or LLM.]\n",
    "        G -->|No| I[Answer Formatting/Completeness Issue: <br>Answer is correct but incomplete or poorly structured.]\n",
    "    end\n",
    "\n",
    "    class flowchat frameworkStyle;\n",
    "```\n",
    "\n",
    "æ€»ä¹‹ï¼Œæˆ‘ä»¬å¯ä»¥æŠŠå·²æŒæ¡çš„å†…å®¹æµ“ç¼©æˆä¸€å¼ ç®€å•çš„è¡¨æ ¼ã€‚\n",
    "\n",
    "<table class='diagnostic-table'>\n",
    "    <tr>\n",
    "        <th>æŒ‡æ ‡</th>\n",
    "        <th>é«˜å€¼ (â‰¥0.8)</th>\n",
    "        <th>ä¸­å€¼ (0.5â€“0.8)</th>\n",
    "        <th>ä½å€¼ (<0.5)</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><strong>Context Recall</strong></td>\n",
    "        <td class='high'>æ£€ç´¢å™¨æ‰¾åˆ°äº†å¤§éƒ¨åˆ†ç›¸å…³ä¿¡æ¯</td>\n",
    "        <td class='medium'>é”™è¿‡äº†ä¸€äº›å…³é”®ä¿¡æ¯</td>\n",
    "        <td class='low'>ç¼ºå°‘å…³é”®ä¿¡æ¯â€”â€”éœ€è¦ä¿®å¤æ£€ç´¢</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><strong>Context Precision</strong></td>\n",
    "        <td class='high'>æ£€ç´¢åˆ°çš„æ–‡æœ¬å—é«˜åº¦ç›¸å…³</td>\n",
    "        <td class='medium'>æ£€ç´¢ä¸Šä¸‹æ–‡ç•¥æœ‰å™ªå£°</td>\n",
    "        <td class='low'>æ— å…³ä¿¡æ¯è¿‡å¤šâ€”â€”LLM å®¹æ˜“è¢«å¹²æ‰°</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><strong>Faithfulness</strong></td>\n",
    "        <td class='high'>å›ç­”ç´§è´´æ£€ç´¢ä¸Šä¸‹æ–‡</td>\n",
    "        <td class='medium'>å­˜åœ¨è½»å¾®å¹»è§‰æˆ–é—æ¼</td>\n",
    "        <td class='low'>ä¸¥é‡å¹»è§‰â€”â€”éœ€è¦ä¿®æç¤ºæˆ–æ›´æ¢æ¨¡å‹</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><strong>Answer Correctness</strong></td>\n",
    "        <td class='high'>ç­”æ¡ˆäº‹å®å‡†ç¡®ä¸”å®Œæ•´</td>\n",
    "        <td class='medium'>éƒ¨åˆ†æ­£ç¡®æˆ–ä¸å¤Ÿå®Œæ•´</td>\n",
    "        <td class='low'>ç­”æ¡ˆé”™è¯¯â€”â€”åº”æ£€æŸ¥æ•´æ¡ç®¡çº¿</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td colspan=\"4\" class='insight'>\n",
    "            <strong>æ ¸å¿ƒæ´è§ï¼š</strong> \n",
    "            å¦‚æœ <strong>Context Recall</strong> ä½ä½† <strong>Faithfulness</strong> é«˜ï¼Œè¯´æ˜ LLM æ²¡æ’’è°â€”â€”å®ƒåªæ˜¯æ‹¿åˆ°é”™è¯¯ä¿¡æ¯ã€‚ \n",
    "            è¿™æ—¶åº”è¯¥ä¿®æ£€ç´¢ï¼ˆå—åˆ’åˆ†ã€åµŒå…¥ï¼‰ï¼Œè€Œä¸æ˜¯æ€ªç”Ÿæˆã€‚\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0cb6ee7-f003-4573-bba2-d1933d0540fb",
   "metadata": {},
   "source": [
    "# å…¶ä»–è¯„ä¼°æ¡†æ¶\n",
    "\n",
    "è™½ç„¶ Ragas åœ¨è‡ªåŠ¨åŒ–ã€LLM é©±åŠ¨çš„è¯„ä¼°æ–¹é¢è¡¨ç°ä¼˜å¼‚ï¼Œä½†å®ƒå¹¶éå”¯ä¸€çš„é€‰æ‹©ã€‚ä¸‹é¢æˆ‘ä»¬æ¥çœ‹çœ‹å…¶ä»–å‡ ç§å¸¸ç”¨æ¡†æ¶â€”â€”å®ƒä»¬å„æœ‰åƒç§‹ã€‚\n",
    "\n",
    "## Ragasï¼ˆæˆ‘ä»¬çš„é¦–é€‰ï¼‰\n",
    "\n",
    "```mermaid\n",
    "graph TD\n",
    "    classDef frameworkStyle fill:#ffffff,stroke:#1f77b4,stroke-width:2px;\n",
    "\n",
    "    subgraph Ragas_Framework [Ragas Framework]\n",
    "        direction TB\n",
    "        \n",
    "        subgraph Ragas_Evaluator [Ragas Evaluator]\n",
    "            direction LR\n",
    "            Judge[LLM Judge] -->|Scores| CR[Context Recall]\n",
    "            Judge -->|Scores| CP[Context Precision]\n",
    "            Judge -->|Scores| F[Faithfulness]\n",
    "            Judge -->|Scores| AC[Answer Correctness]\n",
    "        end\n",
    "\n",
    "        Q[User Question] --> Ragas\n",
    "        A[Generated Answer] --> Ragas\n",
    "        C[Retrieved Context] --> Ragas\n",
    "        GT[Ground Truth] --> Ragas\n",
    "        Ragas --> Judge\n",
    "        \n",
    "    end\n",
    "    \n",
    "    class Ragas_Framework frameworkStyle;\n",
    "    \n",
    "    style Judge fill:#e1f5fe,stroke:#1f77b4\n",
    "    style Ragas stroke:#1f77b4,stroke-width:2px\n",
    "```\n",
    "\n",
    "> Ragas ä½¿ç”¨ç‹¬ç«‹çš„ LLM ä½œä¸ºâ€œè£åˆ¤â€ï¼Œè‡ªåŠ¨ä¸º RAG ç³»ç»Ÿçš„è¾“å‡ºæ‰“åˆ†ã€‚å®ƒéœ€è¦å‚è€ƒç­”æ¡ˆè¿›è¡Œå¯¹æ¯”ï¼Œå¯å¿«é€Ÿç»™å‡ºæ•´ä½“æ€§èƒ½è¯„ä¼°ã€‚\n",
    "\n",
    "Ragas æ˜¯ä¸“ä¸º RAG åº”ç”¨æ‰“é€ çš„å¼€æºæ¡†æ¶ï¼Œå…¶ä¼˜åŠ¿åœ¨äºä¸€ç»„é’ˆå¯¹ RAG çš„æŒ‡æ ‡ï¼Œä¾‹å¦‚ä¸Šä¸‹æ–‡å¬å›ã€ä¸Šä¸‹æ–‡ç²¾åº¦ã€å¿ å®åº¦ä¸ç­”æ¡ˆç›¸å…³æ€§ï¼Œå¯ç›´å‡»æ£€ç´¢å¢å¼ºç³»ç»Ÿçš„å¸¸è§è–„å¼±ç‚¹ã€‚å€ŸåŠ©â€œLLM è£åˆ¤â€ï¼ŒRagas èƒ½ä¸ºç”Ÿæˆç­”æ¡ˆçš„è´¨é‡åŠå…¶ä¸æ£€ç´¢ä¸Šä¸‹æ–‡çš„æ‰æ ¹ç¨‹åº¦æä¾›ç»†è…»çš„è¯„åˆ†ï¼Œå› æ­¤éå¸¸é€‚åˆå¿«é€Ÿè·å¾— RAG ç®¡çº¿æ•´ä½“å¥åº·çŠ¶å†µçš„è‡ªåŠ¨åŒ–è¯„ä¼°ã€‚ä¸è¿‡ï¼Œç”±äºå®ƒä¾èµ– LLM è¯„ä¼°å™¨ï¼Œå¾—åˆ†æœ‰æ—¶ä¼šåƒâ€œé»‘ç®±â€ï¼Œè®©äººéš¾ä»¥å¼„æ¸…å…·ä½“æ‰£åˆ†åŸå› ï¼Œä»è€Œå¢åŠ è°ƒè¯•éš¾åº¦ã€‚\n",
    "\n",
    "## TruLens\n",
    "\n",
    "```mermaid\n",
    "graph LR\n",
    "    classDef frameworkStyle fill:#ffffff,stroke:#1f77b4,stroke-width:2px;\n",
    "    \n",
    "    subgraph TruLens_Framework [TruLens Framework]\n",
    "        A[User Query] --> B[TruLens Monitor]\n",
    "        B --> C[Chunking & Retrieval]\n",
    "        B --> D[Prompt Assembly]\n",
    "        B --> E[LLM Generation]\n",
    "        B --> F[Final Answer]\n",
    "\n",
    "        subgraph TruLens Dashboard\n",
    "            G[Log: Query]\n",
    "            H[Log: Retrieved Chunks]\n",
    "            I[Log: Final Prompt]\n",
    "            J[Log: LLM Call]\n",
    "            K[Log: Answer]\n",
    "            G --> H --> I --> J --> K\n",
    "        end\n",
    "\n",
    "        B --> G\n",
    "        B --> H\n",
    "        B --> I\n",
    "        B --> J\n",
    "        B --> K\n",
    "    \n",
    "    end\n",
    "        \n",
    "    class TruLens_Framework frameworkStyle;\n",
    "```\n",
    "\n",
    "> TruLens åƒé£è¡Œè®°å½•ä»ªä¸€æ ·æ•æ‰ RAG ç®¡çº¿çš„æ¯ä¸ªæ­¥éª¤ï¼Œéå¸¸é€‚åˆæ·±å…¥è°ƒè¯•å¹¶å®šä½é—®é¢˜æ‰€åœ¨ã€‚\n",
    "\n",
    "TruLens çš„ç‰¹è‰²åœ¨äºå¯è§‚æµ‹æ€§ä¸å¯è¿½è¸ªæ€§ã€‚å®ƒä¸ä»…æä¾›æœ€ç»ˆå¾—åˆ†ï¼Œæ›´åƒ LLM åº”ç”¨çš„â€œé»‘åŒ£å­â€ï¼Œä»æœ€åˆçš„æŸ¥è¯¢åˆ°æœ€ç»ˆç­”æ¡ˆã€åŒ…æ‹¬ä¸­é—´çš„æç¤ºè¯ã€æ£€ç´¢ä¸Šä¸‹æ–‡ä¸æ¨¡å‹è°ƒç”¨ï¼Œéƒ½ä¼šè¢«è®°å½•ä¸‹æ¥ã€‚è¿™ç§ç»†èŠ‚å¯¹è°ƒè¯•å¤æ‚é—®é¢˜æä¸ºå®è´µã€‚å‡­å€Ÿä¸ LlamaIndex ç­‰æ¡†æ¶çš„é›†æˆï¼Œå¼€å‘è€…å¯ä»¥è®¾ç½®åé¦ˆå‡½æ•°ï¼Œåœ¨ä¸åŒé˜¶æ®µç¨‹åºåŒ–åœ°è¯„ä¼°æ‰æ ¹æ€§ä¸ç›¸å…³æ€§ã€‚è™½ç„¶ TruLens å†…ç½®æŒ‡æ ‡ä¸å¦‚å…¶ä»–æ¡†æ¶ä¸°å¯Œï¼Œä¹Ÿéœ€è¦æ›´å¤šé…ç½®ï¼Œä½†å®ƒä¸ºæ•´ä¸ªç®¡çº¿æä¾›çš„å…¨æ™¯è§†å›¾å¯¹å®šä½é—®é¢˜æå…¶æœ‰ç”¨ã€‚\n",
    "\n",
    "## DeepEval\n",
    "\n",
    "```mermaid\n",
    "graph TD\n",
    "    subgraph DeepEval Framework\n",
    "        T[Define Test Cases] -->|Question, Ground Truth| DE[DeepEval]\n",
    "        DE -->|Run Tests| A1[Test: Answer Correctness]\n",
    "        DE -->|Run Tests| A2[Test: Faithfulness]\n",
    "        DE -->|Run Tests| A3[Test: Context Recall]\n",
    "\n",
    "        A1 -->|Pass/Fail| R[CI/CD Pipeline]\n",
    "        A2 -->|Pass/Fail| R\n",
    "        A3 -->|Pass/Fail| R\n",
    "    end\n",
    "    \n",
    "    style DE fill:#ffecb3,stroke:#f57c00,stroke-width:2px\n",
    "    style R fill:#e8f5e8,stroke:#2e7d32\n",
    "```\n",
    "> DeepEval å°† RAG è¯„ä¼°è§†ä½œè½¯ä»¶æµ‹è¯•ã€‚ä½ å®šä¹‰æ–­è¨€ï¼Œå®ƒæ‰§è¡Œè‡ªåŠ¨åŒ–æµ‹è¯•ï¼Œéå¸¸é€‚åˆåœ¨ç”Ÿäº§ç¯å¢ƒä¸­é˜²æ­¢å›å½’ã€‚ \n",
    "\n",
    "DeepEval é‡‡ç”¨è½¯ä»¶å·¥ç¨‹æ€è·¯ï¼Œè¢«ç§°ä¸ºâ€œé¢å‘ LLM çš„ Pytestâ€ã€‚å®ƒå€¡å¯¼æµ‹è¯•é©±åŠ¨å¼€å‘ï¼ˆTDDï¼‰ï¼Œé¼“åŠ±ä½ åœ¨æ„å»º RAG åº”ç”¨ä¹‹å‰æˆ–åŒæ—¶ç¼–å†™è¯„ä¼°æµ‹è¯•ã€‚è¯¥æ¡†æ¶åœ¨ CI/CD åœºæ™¯ä¸­è¡¨ç°çªå‡ºï¼Œå¯ä»¥è®¾å®šä¸¥æ ¼çš„é€šè¿‡/å¤±è´¥æ ‡å‡†ï¼ˆä¾‹å¦‚â€œfaithfulness > 0.9â€ï¼‰æ¥é˜²æ­¢é€€åŒ–ã€‚DeepEval æ”¯æŒå¤šç§ LLM ä»»åŠ¡çš„æŒ‡æ ‡ï¼Œä¸é™äº RAGï¼Œå› æ­¤å¯¹äºæ„å»ºå¤šç±»å‹ LLM åŠŸèƒ½çš„å›¢é˜Ÿå°¤ä¸ºå®ç”¨ã€‚å…¶ç»“æ„åŒ–ã€æ–­è¨€å¼çš„æµ‹è¯•æ¨¡å‹ä¸ºç”Ÿäº§çº§è´¨é‡æŠŠæ§æä¾›äº†é«˜åº¦çš„è‡ªåŠ¨åŒ–ä¸æŒæ§åŠ›ã€‚\n",
    "\n",
    "## è‡ªå®šä¹‰è¯„ä¼°æ¡†æ¶\n",
    "\n",
    "å½“æ ‡å‡†æŒ‡æ ‡æ— æ³•è¦†ç›–ä½ åº”ç”¨çš„ç‰¹å®šéœ€æ±‚æ—¶ï¼Œè‡ªå®šä¹‰è¯„ä¼°æ¡†æ¶å°±æ˜¾å¾—ä¸å¯æˆ–ç¼ºã€‚ä¾‹å¦‚ï¼Œæ£€æŸ¥å›ç­”ä¸­æ˜¯å¦åŒ…å«æŒ‡å®šé“¾æ¥ã€æ˜¯å¦éµå¾ªæŸä¸ªå·¥ä½œæµç¨‹ï¼Œç”šè‡³æ˜¯å¦ç¬¦åˆé¢„æœŸæƒ…ç»ªè¯­è°ƒã€‚è‡ªå»ºæ–¹æ¡ˆè™½ç„¶æŠ•å…¥æœ€å¤§ï¼Œå´èƒ½è®©è¯„ä¼°ä¸ä¸šåŠ¡ç›®æ ‡å’Œç”¨æˆ·ä½“éªŒç²¾ç¡®å¯¹é½ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œè¿™äº›æ¡†æ¶å¹¶éäº’æ–¥ï¼›æˆç†Ÿçš„è¯„ä¼°ç­–ç•¥é€šå¸¸ç»„åˆä½¿ç”¨ï¼Œä¾‹å¦‚ç”¨ Ragas åšå¹¿è¦†ç›–çš„è‡ªåŠ¨æ‰“åˆ†ã€ç”¨ TruLens æ·±æŒ–å¼‚å¸¸æ¡ˆä¾‹ï¼Œå†ç”¨è‡ªå®šä¹‰è§„åˆ™ä¿éšœå…³é”®ä¸šåŠ¡é€»è¾‘ã€‚\n",
    "\n",
    "\n",
    "## æ¡†æ¶å¯¹æ¯”\n",
    "\n",
    "| åŠŸèƒ½ | **Ragas** | **TruLens** | **DeepEval** | **è‡ªå®šä¹‰æ¡†æ¶** |\n",
    "| :--- | :--- | :--- | :--- | :--- |\n",
    "| **æœ€é€‚ç”¨åœºæ™¯** | ä¸º RAG ç³»ç»Ÿæä¾›ç«¯åˆ°ç«¯çš„è‡ªåŠ¨åŒ–æŒ‡æ ‡è¯„åˆ†ã€‚ | æä¾›å¯è§‚æµ‹æ€§ã€è°ƒè¯•èƒ½åŠ›ï¼Œè¿½è¸ªæ•´æ¡ RAG ç®¡çº¿ã€‚ | æµ‹è¯•é©±åŠ¨å¼€å‘ï¼ˆTDDï¼‰ä¸ CI/CD é›†æˆã€‚ | å¼ºåˆ¶æ‰§è¡Œç‰¹å®šä¸šåŠ¡é€»è¾‘ä¸é¢†åŸŸè§„åˆ™ã€‚ |\n",
    "| **ä¼˜åŠ¿** | è½»é‡ã€æ˜“é›†æˆï¼ŒæŒ‡æ ‡ä¸“ä¸º RAG è®¾è®¡ï¼ˆå¦‚ä¸Šä¸‹æ–‡å¬å›ã€å¿ å®åº¦ï¼‰ï¼Œåˆ©ç”¨ LLM è£åˆ¤è¾“å‡ºç»†è…»è¯„åˆ†ã€‚ | æ‹¥æœ‰å¯è§†åŒ–é¢æ¿ï¼Œè®°å½•ç®¡çº¿æ¯ä¸€æ­¥ï¼Œä¸ LangChainã€LlamaIndex é›†æˆè‰¯å¥½ï¼Œå¯å®æ—¶åé¦ˆã€‚ | è®¾è®¡ç†å¿µç±»ä¼¼è½¯ä»¶æµ‹è¯•æ¡†æ¶ï¼ˆå¦‚ pytestï¼‰ï¼Œæ”¯æŒæ–­è¨€ä¸è‡ªåŠ¨å›å½’æµ‹è¯•ã€‚ | æœ€å¤§çš„çµæ´»æ€§ï¼Œå¯å®šä¹‰ç°æˆå·¥å…·æ— æ³•è¦†ç›–çš„ç‹¬ç‰¹æŒ‡æ ‡ï¼ˆå¦‚æ”¿ç­–åˆè§„ã€æƒ…ç»ªè¯­è°ƒï¼‰ã€‚ |\n",
    "| **åŠ£åŠ¿** | éœ€è¦èƒ½åŠ›è¶³å¤Ÿçš„è¯„ä¼°å‹ LLMï¼›è¯„åˆ†å¯èƒ½â€œé»‘ç®±â€ï¼Œä½åˆ†éš¾ä»¥è§£é‡Šï¼›æŒ‡æ ‡å«ä¹‰ä¸ä¸€å®šç›´è§‚ã€‚ | å†…ç½®æŒ‡æ ‡ç›¸å¯¹è¾ƒå°‘ï¼›ç›¸æ¯”ç®€å•å·¥å…·éœ€è¦æ›´å¤šé…ç½®ã€‚ | å¯¹å¤æ‚è‡ªå®šä¹‰é€»è¾‘å¯èƒ½éœ€è¦æ›´å¤šè®¾ç½®ï¼›ä¾§é‡éªŒè¯è€Œéæ·±åº¦ç®¡çº¿åˆ†æã€‚ | å¼€å‘ä¸ç»´æŠ¤æˆæœ¬é«˜ï¼Œéœ€è¦å¤§é‡å·¥ç¨‹æŠ•å…¥ã€‚ |\n",
    "| **é€‚ç”¨ç”¨ä¾‹** | å¿«é€Ÿè·å– RAG ç®¡çº¿æ€§èƒ½çš„è‡ªåŠ¨åŒ–å¾—åˆ†ï¼Œå®šä½å®è§‚é—®é¢˜ã€‚ | é€šè¿‡æ£€æŸ¥ä¸­é—´æ­¥éª¤ã€æç¤ºè¯å’Œæ£€ç´¢ä¸Šä¸‹æ–‡ï¼Œæ·±å…¥è°ƒè¯•æ•…éšœç®¡çº¿ã€‚ | åœ¨ç”Ÿäº§ç¯å¢ƒä¸­è‡ªåŠ¨åŒ–è´¨é‡æ£€æŸ¥ï¼Œç¡®ä¿æ›´æ–°ä¸ä¼šç ´åæ—¢æœ‰åŠŸèƒ½ã€‚ | éªŒè¯ AI å›ç­”æ˜¯å¦éµå¾ªä¸¥æ ¼ä¸šåŠ¡è§„åˆ™ï¼Œä¾‹å¦‚åŒ…å«æŒ‡å®šé“¾æ¥æˆ–éµå¾ªå®¢æœè¯æœ¯ã€‚ |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886894e0-b23f-4cb7-ab41-adbee01ab099",
   "metadata": {},
   "source": [
    "# å»ºç«‹è¯„ä¼°æ¡†æ¶çš„æœ€ä½³å®è·µ\n",
    "\n",
    "---\n",
    "\n",
    "ä½ å·²ç»æŒæ¡äº†ä¸€å¥—å¼ºå¤§çš„å·¥å…·ï¼šæ‰‹åŠ¨æ£€æŸ¥ç”¨æ¥è¯Šæ–­é—®é¢˜ã€Ragas çš„è‡ªåŠ¨åŒ–æŒ‡æ ‡å¸®åŠ©ä½ åœ¨è§„æ¨¡ä¸Šè¡¡é‡è¡¨ç°ã€è¿˜æœ‰å¯ä»¥é€‰æ‹©çš„å¤šç§æ¡†æ¶ã€‚ä½†çœŸæ­£çš„æŒ‘æˆ˜ä¸æ˜¯â€œä¼šç”¨è¿™äº›å·¥å…·â€ï¼Œè€Œæ˜¯æ‰“é€ ä¸€å¥—å¯æŒç»­ã€æœ‰æ•ˆçš„è¯„ä¼°å®è·µï¼Œæ¨åŠ¨æŒç»­æ”¹è¿›ã€‚\n",
    "\n",
    "æŠŠå®ƒæƒ³è±¡æˆç»´æŠ¤ä¸€å°é«˜æ€§èƒ½å¼•æ“ã€‚å†å…ˆè¿›çš„è¯Šæ–­å·¥å…·ï¼Œå¦‚æœæ²¡æœ‰å®šæœŸä¿å…»ã€ä¸“ä¸šæŠ€å¸ˆå’Œè¯¦å°½è®°å½•ï¼Œå‘åŠ¨æœºæœ€ç»ˆä¹Ÿä¼šå‡ºæ•…éšœã€‚\n",
    "\n",
    "ä»¥ä¸‹æ˜¯ä¸º RAG åº”ç”¨æ„å»ºç¨³å¥è¯„ä¼°ä½“ç³»çš„å…³é”®æ­¥éª¤ã€‚\n",
    "\n",
    "## è®©é¢†åŸŸä¸“å®¶å°½æ—©å‚ä¸\n",
    "\n",
    "æˆåŠŸçš„è¯„ä¼°ç­–ç•¥ï¼Œæœ€é‡è¦çš„å› ç´ æ˜¯äººçš„ä¸“ä¸šåˆ¤æ–­ã€‚å†å¼ºå¤§çš„ LLM åˆ¤æ–­å™¨ï¼Œä¹Ÿæ¯”ä¸è¿‡ç†Ÿæ‚‰ä¸šåŠ¡ç»†èŠ‚çš„ä¸“å®¶ã€‚\n",
    "\n",
    "> **é‡è¦æ€§ï¼š**  \n",
    "> åªæœ‰çœŸæ­£æ·±å…¥ä¸šåŠ¡çš„äººæ‰èƒ½ç•Œå®šä»€ä¹ˆæ‰ç®—â€œæ­£ç¡®â€ã€‚â€œé«˜ä¼˜å…ˆçº§â€çš„ä»»åŠ¡æ˜¯å¦æ¯”â€œä»Šæ—¥æˆªæ­¢â€æ›´ç´§æ€¥ï¼Ÿå›ç­”æ˜¯å¦å¿…é¡»åŒ…å«é“¾æ¥ã€æˆªæ­¢æ—¥æœŸæˆ–å®¡æ‰¹æµç¨‹ï¼Ÿ\n",
    "\n",
    "### å®è·µæ–¹å¼ï¼š\n",
    "\n",
    "* **å…±åŒç¼–å†™ ground truthï¼š** ä¸è¦å•ç‹¬å†™ `ground_truth`ã€‚ä¸ä¸“å®¶ï¼ˆå¦‚ HR ç»ç†ã€é¡¹ç›®è´Ÿè´£äººï¼‰åä¸‹æ¥ä¸€èµ·æ’°å†™ç†æƒ³å›ç­”ã€‚\n",
    "* **è¯†åˆ«è¾¹ç¼˜æƒ…æ™¯ï¼š** ä¸“å®¶æœ€äº†è§£æ£˜æ‰‹åœºæ™¯ã€‚ä¾‹å¦‚â€œä»»åŠ¡å·²è¿‡æœŸä½†çŠ¶æ€ä»æ˜¯ Not Startedï¼Ÿâ€æˆ–â€œåˆšåˆ é™¤çš„ä»»åŠ¡è¢«è¯¢é—®æ€ä¹ˆåŠï¼Ÿâ€\n",
    "* **å®¡æŸ¥æŒ‡æ ‡ï¼š** å®šæœŸè¯·ä¸“å®¶å¤æ ¸ä½åˆ†æ¡ˆä¾‹ï¼Œç¡®è®¤æ˜¯æŒ‡æ ‡åˆ¤æ–­æ­£ç¡®ï¼Œè¿˜æ˜¯åº”è¯¥æ›´æ–°å‚è€ƒç­”æ¡ˆã€‚\n",
    "\n",
    "> **ğŸ’¡ ä¸“å®¶æç¤ºï¼š**  \n",
    "> æŠŠé¢†åŸŸä¸“å®¶å½“æˆå‰¯é©¾é©¶ï¼Œè€Œä¸æ˜¯äº‹åå®¡é˜…è€…ã€‚ä»–ä»¬çš„æ´è§åº”è¯¥ä»ç¬¬ä¸€å¤©å°±èå…¥è¯„ä¼°æ ‡å‡†ã€‚\n",
    "\n",
    "## ç”¨çœŸå®ç”¨æˆ·æŸ¥è¯¢æ„å»ºæµ‹è¯•é›†\n",
    "\n",
    "è¯„ä¼°æ•°æ®é›†æ˜¯è´¨é‡ä¿éšœçš„åŸºçŸ³ã€‚å¦‚æœå®ƒæºäºå‡è®¾é—®é¢˜ï¼Œè¯„ä¼°ç»“æœä¹Ÿéš¾ä»¥åæ˜ çœŸå®è¡¨ç°ã€‚\n",
    "\n",
    "**çœŸå®æŸ¥è¯¢æ¥è‡ªå“ªé‡Œï¼š**\n",
    "\n",
    "* **èŠå¤©è®°å½•ï¼š** æŒ–æ˜å®¢æœæœºå™¨äººã€å†…éƒ¨èŠå¤©å·¥å…·æˆ–æ—©æœŸç”¨æˆ·æµ‹è¯•çš„å¯¹è¯ã€‚\n",
    "* **æœç´¢å†å²ï¼š** æŸ¥çœ‹ç”¨æˆ·åœ¨çŸ¥è¯†åº“æˆ– Wiki ä¸­æœç´¢çš„å†…å®¹ã€‚\n",
    "* **å·¥å•ï¼š** æ”¯æŒå·¥å•æ˜¯ç”¨æˆ·ç—›ç‚¹å’Œæ¨¡ç³Šè¡¨è¾¾çš„å®åº“ã€‚\n",
    "\n",
    "### èšç„¦é«˜ä»·å€¼é—®é¢˜ï¼š\n",
    "\n",
    "**ä¼˜å…ˆå…³æ³¨ï¼š**\n",
    "\n",
    "* **é«˜é¢‘é—®é¢˜ï¼š** ç»å¸¸å‡ºç°çš„æé—®ã€‚\n",
    "* **é«˜é£é™©é—®é¢˜ï¼š** ä¸æˆªæ­¢æ—¶é—´ã€æ”¿ç­–æˆ–è´¢åŠ¡ä¿¡æ¯ç›¸å…³çš„è¯·æ±‚ã€‚\n",
    "* **æ¨¡ç³Šé—®é¢˜ï¼š** å¤šç§è§£é‡Šçš„æé—®ï¼ˆä¾‹å¦‚â€œæœ¬å‘¨æˆªæ­¢çš„æ˜¯ä»€ä¹ˆï¼Ÿâ€ vs.â€œä»Šå¤©æˆªæ­¢çš„æ˜¯ä»€ä¹ˆï¼Ÿâ€ï¼‰ã€‚\n",
    "\n",
    "è¿™æ ·æ‰èƒ½è®©è¯„ä¼°åŠªåŠ›èšç„¦åœ¨å¯¹ç”¨æˆ·æœ€é‡è¦çš„é¢†åŸŸã€‚\n",
    "\n",
    "## æ··åˆä½¿ç”¨å¤šç§è¯„ä¼°æ–¹æ³•\n",
    "\n",
    "æ²¡æœ‰ä»»ä½•å•ä¸€å·¥å…·èƒ½å‘ˆç°å…¨è²Œã€‚æœ€æœ‰æ•ˆçš„å›¢é˜Ÿä¼šé‡‡ç”¨åˆ†å±‚è¯Šæ–­ç»„åˆï¼š\n",
    "\n",
    "| æ–¹æ³• | ç›®çš„ | ä¼˜åŠ¿ | å±€é™æ€§ |\n",
    "|--------|--------|-----------|-------------|\n",
    "| **Manual Inspection** | ç›´è§‚éªŒè¯æ£€ç´¢ä¸è¾“å‡ºè´¨é‡ | å¿«é€Ÿã€ç›´è§‚ï¼Œèƒ½å‘ç°æ ¼å¼é—®é¢˜ | éš¾ä»¥æ‰©å±•ã€ä¸»è§‚æ€§å¼º |\n",
    "| **TruLens** | è¿½è¸ªå¹¶è°ƒè¯•å®Œæ•´ RAG ç®¡çº¿ | å±•ç¤ºæç¤ºè¯ã€ä¸Šä¸‹æ–‡ã€LLM è°ƒç”¨ | ä¸ç›´æ¥ç»™å‡ºè´¨é‡å¾—åˆ† |\n",
    "| **Ragas** | ç”¨æŒ‡æ ‡é‡åŒ–æ€§èƒ½ | æä¾›å®¢è§‚è¯„åˆ†ï¼ˆæ­£ç¡®åº¦ã€å¿ å®åº¦ï¼‰ | éœ€è¦å‚è€ƒç­”æ¡ˆ |\n",
    "| **LLM-as-a-Judge** | è‡ªåŠ¨è¯„ä¼°å›ç­”è´¨é‡ | å¯è¡¡é‡è¯­æ°”ã€ç›¸å…³æ€§ã€å®Œæ•´æ€§ | å¯èƒ½å‡ºç°è¯„ä¼°å¹»è§‰ |\n",
    "| **A/B Testing** | æ¯”è¾ƒæç¤ºæˆ–æ£€ç´¢ç­–ç•¥å˜åŒ– | èƒ½è¡¡é‡çœŸå®ç”¨æˆ·å½±å“ | éœ€è¦çœŸå®æµé‡ä¸æŒ‡æ ‡ |\n",
    "\n",
    "> ğŸ’¡ **æœ€ä½³å®è·µ**ï¼šç»“åˆ **TruLens è°ƒè¯•** + **Ragas æ‰“åˆ†** + **äººå·¥å®¡æŸ¥è¾¹ç¼˜æ¡ˆä¾‹**ã€‚\n",
    "### ç¤ºä¾‹å·¥ä½œæµï¼š\n",
    "\n",
    "1. ä½¿ç”¨ Ragas åšæ—¥å¸¸è‡ªåŠ¨åŒ–è¿è¡Œï¼ŒåŠæ—¶å‘ç°æ€§èƒ½ä¸‹é™ã€‚\n",
    "2. å½“å¾—åˆ†åä½æ—¶ï¼Œå€ŸåŠ© TruLens æ·±å…¥æ—¥å¿—ï¼Œå®šä½å…·ä½“é—®é¢˜ã€‚\n",
    "3. ç¼–å†™ DeepEval æµ‹è¯•ï¼Œç¡®ä¿è¯¥é—®é¢˜ä¸ä¼šå†æ¬¡å‡ºç°ã€‚\n",
    "4. é¢å‘æ–°åŠŸèƒ½ï¼ˆä¾‹å¦‚é€€æ¬¾æ”¿ç­–ï¼‰ï¼Œç¼–å†™è‡ªå®šä¹‰è¯„ä¼°å™¨ï¼Œç¡®ä¿å›ç­”å§‹ç»ˆåŒ…å«æŒ‡å®šé“¾æ¥ã€‚\n",
    "\n",
    "## é—­åˆåé¦ˆå›è·¯\n",
    "\n",
    "è¯„ä¼°ä¸æ˜¯ä¸€æ¬¡æ€§ä»»åŠ¡ï¼Œè€Œæ˜¯æŒç»­æ”¹è¿›çš„å¾ªç¯ã€‚ç›®æ ‡æ˜¯æ„å»ºä¸€ä¸ªé£è½®ï¼Œæ¯è½¬ä¸€åœˆï¼Œç³»ç»Ÿå°±æ›´å¯é ã€‚\n",
    "\n",
    "```mermaid\n",
    "graph LR\n",
    "    subgraph Quality_Flywheel [Quality Flywheel]\n",
    "        A[Collect Bad Cases] --> B[Analyze Metrics]\n",
    "        B --> C[Improve Chunking/Prompting]\n",
    "        C --> D[Re-evaluate]\n",
    "        D --> E[Deploy]\n",
    "        E --> A\n",
    "    end\n",
    "```\n",
    "\n",
    "### å®æ–½è´¨é‡é£è½®\n",
    "\n",
    "* **Collectï¼š** æ±‡é›†å¤±è´¥ç”¨ä¾‹ã€ç”¨æˆ·åé¦ˆä¸ä½åˆ†æŸ¥è¯¢ã€‚\n",
    "* **Analyzeï¼š** åˆ©ç”¨æŒ‡æ ‡è¯Šæ–­æ ¹å› ï¼ˆä¾‹å¦‚å¬å›ä½ â†’ ä¿®æ£€ç´¢ï¼‰ã€‚\n",
    "* **Improveï¼š** æœ‰é’ˆå¯¹æ€§åœ°ä¿®æ”¹ï¼ˆè°ƒæ•´å—å¤§å°ã€é‡å†™æç¤ºç­‰ï¼‰ã€‚\n",
    "* **Re-evaluateï¼š** è¿è¡Œæµ‹è¯•é›†éªŒè¯ä¿®å¤æ•ˆæœã€‚\n",
    "* **Deployï¼š** å‘å¸ƒæ”¹è¿›ç‰ˆæœ¬ã€‚\n",
    "* **Repeatï¼š** ä¸æ–­å¾ªç¯ï¼ŒæŒç»­å¢å¼ºç³»ç»Ÿå¯é æ€§ã€‚\n",
    "\n",
    "## æŠŠè¯„ä¼°å½“æˆäº§å“\n",
    "\n",
    "è¯„ä¼°æ¡†æ¶ä¸åº”ç”¨ä»£ç ä¸€æ ·é‡è¦ï¼Œéœ€è¦åŒæ ·ä¸¥æ ¼å¯¹å¾…ã€‚\n",
    "\n",
    "* **ç‰ˆæœ¬æ§åˆ¶ï¼š** å°†æµ‹è¯•ç”¨ä¾‹ã€å‚è€ƒç­”æ¡ˆä¸è¯„ä¼°è„šæœ¬ä¸ä¸»ä»£ç ä¸€èµ·å­˜å…¥ Gitã€‚\n",
    "* **å®Œæ•´æ–‡æ¡£ï¼š** è¯´æ˜æ¯ä¸ªæµ‹è¯•ç”¨ä¾‹ä¸ºä½•å­˜åœ¨ã€æ—¨åœ¨æ•æ‰ä»€ä¹ˆé—®é¢˜ã€‚\n",
    "* **ç›‘æ§è¶‹åŠ¿ï¼š** æŒç»­è¿½è¸ªå…³é”®æŒ‡æ ‡ï¼ˆå¦‚å¹³å‡ç­”æ¡ˆæ­£ç¡®åº¦ï¼‰ã€‚åˆ†æ•°çªç„¶ä¸‹é™å°±æ˜¯é¢„è­¦ã€‚\n",
    "* **æ¥å…¥ CI/CDï¼š** å°†è¯„ä¼°å¥—ä»¶é›†æˆåˆ°éƒ¨ç½²æµç¨‹ä¸­ã€‚ä¾‹å¦‚ï¼Œå½“å¿ å®åº¦ä½äº 0.8 æ—¶ç›´æ¥é˜»æ­¢æ„å»ºã€‚\n",
    "\n",
    "# æ¥ä¸‹æ¥åšä»€ä¹ˆï¼Ÿ\n",
    "\n",
    "---\n",
    "\n",
    "## ç­”é¢˜è‡ªæµ‹ï¼\n",
    "\n",
    "<details>\n",
    "<summary style=\"cursor: pointer; padding: 12px; border: 1px solid #dee2e6; border-radius: 6px;\">\n",
    "<b>1. ä½ çš„ RAG ç³»ç»Ÿç»™å‡ºäº†æ­£ç¡®ç­”æ¡ˆï¼Œä½† `context_recall` å¾—åˆ†å¾ˆä½ã€‚æœ€å¯èƒ½çš„åŸå› æ˜¯ä»€ä¹ˆï¼Ÿ</b>  \n",
    "\n",
    "<ul>\n",
    "    <li>A) LLM è¢«æ— å…³æ–‡æœ¬å—å¹²æ‰°  </li>\n",
    "    <li>B) å›ç­”ä¸å®Œæ•´  </li>\n",
    "    <li>C) æ£€ç´¢åˆ°çš„ä¸Šä¸‹æ–‡ä¸åŒ…å«å¿…è¦ä¿¡æ¯  </li>\n",
    "    <li>D) LLM åœ¨å¹»è§‰</li>\n",
    "</ul>\n",
    "\n",
    "**æŸ¥çœ‹ç­”æ¡ˆ â†’**\n",
    "</summary>\n",
    "\n",
    "<div style=\"margin-top: 10px; padding: 15px; border: 1px solid #dee2e6; border-radius: 0 0 6px 6px;\">\n",
    "\n",
    "âœ… **æ­£ç¡®ç­”æ¡ˆï¼š** C) æ£€ç´¢åˆ°çš„ä¸Šä¸‹æ–‡ä¸åŒ…å«å¿…è¦ä¿¡æ¯  \n",
    "ğŸ“ **è¯´æ˜**ï¼š\n",
    "* `context_recall` ä½æ„å‘³ç€æ­£ç¡®ä¿¡æ¯æ²¡æœ‰è¢«æ£€ç´¢åˆ°ã€‚å¦‚æœç­”æ¡ˆä¾ç„¶æ­£ç¡®ï¼Œé‚£å°±åªèƒ½æ˜¯æ¨¡å‹â€œå‡­ç©ºè¡¥å……â€äº†äº‹å®â€”â€”è¿™æ˜¯ä¸€ç§å±é™©çš„å¤±è´¥æ¨¡å¼ï¼Œè¯´æ˜æ£€ç´¢å·²å‡ºé—®é¢˜ï¼Œè€Œ LLM åœ¨å¸®å®ƒâ€œæ“¦å±è‚¡â€ã€‚\n",
    "\n",
    "</div>\n",
    "</details>\n",
    "\n",
    "## è¦ç‚¹å›é¡¾\n",
    "\n",
    "* **ä¸ºä»€ä¹ˆè¦è¯„ä¼° RAG ç³»ç»Ÿï¼Ÿ**\n",
    "    * **RAG æ˜¯ä¸€æ¡ç®¡çº¿ï¼Œè€Œéå•ä¸€æ­¥éª¤**â€”â€”æ¶‰åŠåˆ†å—ã€æ£€ç´¢ã€ä¸Šä¸‹æ–‡ç»„è£…ä¸ç”Ÿæˆã€‚\n",
    "    * **å½“äº‹æƒ…å‡ºé”™æ—¶ï¼Œæ ¹å› å¾€å¾€ä¸æ˜**â€”â€”æ˜¯æ¨¡å‹å¹»è§‰ï¼Œè¿˜æ˜¯æ ¹æœ¬æ²¡æ£€ç´¢åˆ°æ­£ç¡®ä¸Šä¸‹æ–‡ï¼Ÿ\n",
    "    * **è¯„ä¼°èƒ½åŒºåˆ†ç—‡çŠ¶ä¸æ ¹å› ï¼š**\n",
    "      - é”™è¯¯ç­”æ¡ˆå¯èƒ½æ¥è‡ªç³Ÿç³•çš„æ£€ç´¢ã€æç¤ºæˆ–æ¨¡å‹é™åˆ¶ã€‚\n",
    "    * **æ²¡æœ‰è¯„ä¼°å°±åƒè’™ç€çœ¼ä¸Šçº¿**â€”â€”çœ‹ä¸åˆ°é—®é¢˜ä¹Ÿå°±æ— æ³•æ”¹è¿›ã€‚\n",
    "    * **è¯„ä¼°å¸¦æ¥ä¿¡ä»»ã€å¯æ‰©å±•æ€§ä¸è¿­ä»£èƒ½åŠ›**â€”â€”è¿™æ˜¯ç”Ÿäº§çº§ AI çš„åŸºç¡€ã€‚\n",
    "\n",
    "<br>\n",
    "\n",
    "* **æ‰‹åŠ¨è¯„ä¼°**\n",
    "    * **è§†è§‰æ£€æŸ¥æ˜¯ç¬¬ä¸€æ­¥**\n",
    "    * **ç•™æ„é¢„è­¦ä¿¡å·ï¼š**\n",
    "      - ç¼ºå°‘å…³é”®å…³é”®è¯\n",
    "      - æ–‡æœ¬å—è¦†ç›–ä¸å…¨\n",
    "      - æ–‡æœ¬è¢«ç ´åæˆ–ä¹±ç \n",
    "    * **æ‰‹åŠ¨è°ƒè¯•èƒ½åŸ¹å…»ç›´è§‰**â€”â€”ç†è§£æ£€ç´¢ä¸ç”Ÿæˆå¦‚ä½•äº’åŠ¨ã€‚\n",
    "    * **å§‹ç»ˆæ£€æŸ¥åŸå§‹èŠ‚ç‚¹**â€”â€”ç¡®è®¤æ¨¡å‹æ˜¯å¦æ‹¿åˆ°äº†æ­£ç¡®ä¿¡æ¯ï¼Œå†å†³å®šæ˜¯å¦æ€ª LLMã€‚\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "* **ä½¿ç”¨ Ragas åšè‡ªåŠ¨åŒ–è¯„ä¼°**\n",
    "    * **Ragas æä¾›é‡åŒ–æŒ‡æ ‡**â€”â€”æŠŠä¸»è§‚è´¨é‡è½¬åŒ–ä¸ºå¯æµ‹åˆ†æ•°ã€‚\n",
    "    * æ ¸å¿ƒæŒ‡æ ‡ï¼š\n",
    "      - **Answer Correctness**ï¼šå›ç­”åœ¨äº‹å®å±‚é¢æœ‰å¤šå‡†ç¡®ã€‚\n",
    "      - **Context Recall**ï¼šæ£€ç´¢ä¸Šä¸‹æ–‡æ˜¯å¦åŒ…å«æ‰€æœ‰ç›¸å…³äº‹å®ã€‚\n",
    "      - **Context Precision**ï¼šæ£€ç´¢æ–‡æœ¬å—æ˜¯å¦ç›¸å…³ï¼Œæ˜¯å¦å­˜åœ¨å¤§é‡å™ªå£°ã€‚\n",
    "      - **Faithfulness**ï¼šå›ç­”æ˜¯å¦æºè‡ªä¸Šä¸‹æ–‡ï¼Œè€Œéå¹»è§‰ã€‚\n",
    "    * **Ragas è®©è¯„ä¼°è¿›å…¥ CI/CD æµç¨‹**â€”â€”æµ‹è¯•ã€æ‰“åˆ†ã€æ”¾å¿ƒä¸Šçº¿ã€‚\n",
    "\n",
    "<br>\n",
    "\n",
    "* **æ„å»ºè´´è¿‘çœŸå®çš„è¯„ä¼°æ•°æ®é›†**\n",
    "    * **ä½¿ç”¨çœŸå®ç”¨æˆ·æé—®**â€”â€”ä¸è¦å‡­ç©ºæœæ’°ï¼š\n",
    "      - èŠå¤©è®°å½•\n",
    "      - æœç´¢å†å²\n",
    "      - æ”¯æŒå·¥å•\n",
    "    * **åŠ å…¥æ¨¡ç³Šã€å«ç³Šæˆ–å¤šé—®ä¸€é¢˜çš„åœºæ™¯**â€”â€”è¿™äº›æœ€éš¾ä¹Ÿæœ€èƒ½æš´éœ²é—®é¢˜ã€‚\n",
    "    * **å®šä¹‰æ¸…æ™°çš„å‚è€ƒç­”æ¡ˆ**â€”â€”æ¯ä¸ªé—®é¢˜çš„â€œæ­£ç¡®ç­”æ¡ˆâ€æ˜¯ä»€ä¹ˆï¼Ÿ\n",
    "    * **æŠŠé¢†åŸŸä¸“å®¶å½“å‰¯é©¾é©¶**â€”â€”ä»–ä»¬çš„è§è§£åº”ä»ç¬¬ä¸€å¤©èµ·å¡‘é€ ä½ çš„è¯„ä¼°æ ‡å‡†ã€‚\n",
    "    * **å°è§„æ¨¡èµ·æ­¥ï¼Œä½†è¦å°½æ—©**â€”â€”å“ªæ€•åªæœ‰ 10 ä¸ªé«˜è´¨é‡ç”¨ä¾‹ï¼Œä¹Ÿèƒ½æ­ç¤ºç³»ç»Ÿæ€§é—®é¢˜ã€‚\n",
    "\n",
    "<br>\n",
    "\n",
    "* **è§£è¯»æŒ‡æ ‡**\n",
    "    * **æŒ‡æ ‡æ˜¯è¯Šæ–­å·¥å…·ï¼Œä¸æ˜¯æˆç»©å•ï¼š**\n",
    "      - `context_recall` ä½ â†’ ä¿®æ£€ç´¢ï¼ˆä¼˜åŒ–åˆ†å—ã€åµŒå…¥æˆ–æœç´¢ï¼‰\n",
    "      - `answer_correctness` ä½ â†’ ä¼˜åŒ–æç¤ºæˆ–æ¢æ›´å¼ºçš„æ¨¡å‹\n",
    "      - `context_precision` é«˜ä½† `answer_correctness` ä½ â†’ æ¨¡å‹åœ¨å¿½ç•¥ä¼˜è´¨ä¸Šä¸‹æ–‡\n",
    "    * **ä¸è¦å­¤ç«‹çœ‹æŒ‡æ ‡**â€”â€”ç»„åˆåˆ†ææ‰èƒ½æ‰¾åˆ°æ ¹å› ã€‚\n",
    "    * **ä¸¾ä¾‹ï¼š** ç­”æ¡ˆæ­£ç¡® + å¬å›ä½ = å¹»è§‰ï¼ˆå±é™©ï¼ï¼‰\n",
    "    * **è¯„ä¼°æ˜¯è¿­ä»£çš„**â€”â€”æµ‹é‡ã€ä¿®å¤ã€å†æµ‹é‡ã€‚\n",
    "\n",
    "<br>\n",
    "\n",
    "* **ä»è¯„ä¼°ä¸­æç‚¼å¯æ‰§è¡Œæ´è§**\n",
    "    * **å…ˆä¿®ä¸Šæ¸¸é—®é¢˜**â€”â€”ç­”æ¡ˆæ­£ç¡®åº¦å¾€å¾€åªæ˜¯ç—‡çŠ¶ã€‚ç»“åˆå…¶ä»–æŒ‡æ ‡å®šä½æ ¹å› ï¼š\n",
    "      - æ£€ç´¢å¤±è´¥ï¼Ÿâ†’ æ”¹è¿›åˆ†å—æˆ–åµŒå…¥\n",
    "      - æç¤ºæ¬ ä½³ï¼Ÿâ†’ åŠ å…¥ç»“æ„ã€ç¤ºä¾‹æˆ–é“¾å¼æ€è€ƒ\n",
    "    * **ä¼˜åŒ–æç¤º**â€”â€”é‡‡ç”¨å¦‚ä¸‹æŒ‡ä»¤ï¼š\n",
    "      - â€œåˆ—å‡ºä»Šå¤©åˆ°æœŸçš„æ‰€æœ‰ä»»åŠ¡ã€‚â€\n",
    "      - â€œè¯·ç”¨é¡¹ç›®ç¬¦å·ä½œç­”ã€‚â€\n",
    "    * **å¯ç”¨å¤šæ­¥æ¨ç†**â€”â€”ä½¿ç”¨å…·å¤‡æ€è€ƒæ¨¡å¼çš„æ¨ç†æ¨¡å‹ï¼ˆå¦‚ Qwen-plusï¼‰ï¼Œå‡å°‘é—æ¼ç»†èŠ‚ã€‚\n",
    "    * **è¯„ä¼°çš„çœŸæ­£ä»·å€¼**ä¸åœ¨åˆ†æ•°ï¼Œè€Œåœ¨äºè¿™äº›åˆ†æ•°æ¿€å‘çš„**æ´è§**ï¼Œå®ƒä»¬èƒ½ä¿ƒæˆæ›´åˆç†çš„ç³»ç»Ÿè®¾è®¡ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4571b6-5dfb-49af-bc7e-2e30462f849e",
   "metadata": {},
   "source": [
    "# ä¸‹ä¸€æ­¥ï¼Ÿ\n",
    "\n",
    "---\n",
    "\n",
    "## è‡ªæµ‹å°ç»ƒï¼\n",
    "\n",
    "<details>\n",
    "<summary style=\"cursor: pointer; padding: 12px; border: 1px solid #dee2e6; border-radius: 6px;\">\n",
    "<b>1. ä½ çš„ RAG ç³»ç»Ÿç»™å‡ºäº†æ­£ç¡®ç­”æ¡ˆï¼Œä½† `context_recall` å¾—åˆ†å¾ˆä½ã€‚æœ€å¯èƒ½çš„åŸå› æ˜¯ä»€ä¹ˆï¼Ÿ</b>  \n",
    "\n",
    "<ul>\n",
    "    <li>A) LLM è¢«æ— å…³æ–‡æœ¬å—å¹²æ‰°  </li>\n",
    "    <li>B) å›ç­”ä¸å®Œæ•´  </li>\n",
    "    <li>C) æ£€ç´¢åˆ°çš„ä¸Šä¸‹æ–‡ä¸åŒ…å«å¿…è¦ä¿¡æ¯  </li>\n",
    "    <li>D) LLM åœ¨å¹»è§‰</li>\n",
    "</ul>\n",
    "\n",
    "**æŸ¥çœ‹ç­”æ¡ˆ â†’**\n",
    "</summary>\n",
    "\n",
    "<div style=\"margin-top: 10px; padding: 15px; border: 1px solid #dee2e6; border-radius: 0 0 6px 6px;\">\n",
    "\n",
    "âœ… **æ­£ç¡®ç­”æ¡ˆï¼š** C) æ£€ç´¢åˆ°çš„ä¸Šä¸‹æ–‡ä¸åŒ…å«å¿…è¦ä¿¡æ¯  \n",
    "ğŸ“ **è¯´æ˜**ï¼š\n",
    "* `context_recall` ä½æ„å‘³ç€æ­£ç¡®ä¿¡æ¯æ²¡æœ‰è¢«æ£€ç´¢åˆ°ã€‚å¦‚æœç­”æ¡ˆä¾ç„¶æ­£ç¡®ï¼Œé‚£åªèƒ½è¯´æ˜æ¨¡å‹â€œå‡­ç©ºè¡¥å……â€äº†äº‹å®â€”â€”è¿™æ˜¯ä¸€ç§å±é™©çš„å¤±è´¥æ¨¡å¼ï¼Œè¡¨ç¤ºæ£€ç´¢é˜¶æ®µå·²ç»å‡ºé—®é¢˜ï¼Œè€Œ LLM åœ¨æ›¿å®ƒâ€œæ“¦å±è‚¡â€ã€‚\n",
    "\n",
    "</div>\n",
    "</details>\n",
    "\n",
    "## è¦ç‚¹å›é¡¾\n",
    "\n",
    "* **ä¸ºä»€ä¹ˆè¦è¯„ä¼° RAG ç³»ç»Ÿï¼Ÿ**\n",
    "    * **RAG æ˜¯ä¸€æ¡ç®¡çº¿ï¼Œè€Œéå•ä¸€æ­¥éª¤**â€”â€”æ¶‰åŠåˆ†å—ã€æ£€ç´¢ã€ä¸Šä¸‹æ–‡ç»„è£…ä¸ç”Ÿæˆã€‚\n",
    "    * **å½“äº‹æƒ…å‡ºé”™æ—¶ï¼Œæ ¹å› å¾€å¾€ä¸æ˜**â€”â€”æ˜¯æ¨¡å‹å¹»è§‰ï¼Œè¿˜æ˜¯å‹æ ¹æ²¡æ£€ç´¢åˆ°æ­£ç¡®ä¸Šä¸‹æ–‡ï¼Ÿ\n",
    "    * **è¯„ä¼°èƒ½åŒºåˆ†ç—‡çŠ¶ä¸æ ¹å› ï¼š**\n",
    "      - é”™è¯¯ç­”æ¡ˆå¯èƒ½æ¥è‡ªç³Ÿç³•çš„æ£€ç´¢ã€æç¤ºæˆ–æ¨¡å‹é™åˆ¶ã€‚\n",
    "    * **æ²¡æœ‰è¯„ä¼°å°±åƒè’™ç€çœ¼ä¸Šçº¿**â€”â€”çœ‹ä¸åˆ°é—®é¢˜ä¹Ÿå°±æ— æ³•æ”¹è¿›ã€‚\n",
    "    * **è¯„ä¼°å¸¦æ¥ä¿¡ä»»ã€å¯æ‰©å±•æ€§ä¸è¿­ä»£èƒ½åŠ›**â€”â€”è¿™æ˜¯ç”Ÿäº§çº§ AI çš„åŸºçŸ³ã€‚\n",
    "\n",
    "<br>\n",
    "\n",
    "* **æ‰‹åŠ¨è¯„ä¼°**\n",
    "    * **è§†è§‰æ£€æŸ¥æ˜¯ç¬¬ä¸€æ­¥**\n",
    "    * **ç•™æ„é¢„è­¦ä¿¡å·ï¼š**\n",
    "      - ç¼ºå°‘å…³é”®å…³é”®è¯\n",
    "      - æ–‡æœ¬å—è¦†ç›–ä¸å…¨\n",
    "      - æ–‡æœ¬è¢«ç ´åæˆ–ä¹±ç \n",
    "    * **æ‰‹åŠ¨è°ƒè¯•èƒ½åŸ¹å…»ç›´è§‰**â€”â€”ç†è§£æ£€ç´¢ä¸ç”Ÿæˆå¦‚ä½•äº’åŠ¨ã€‚\n",
    "    * **å§‹ç»ˆæ£€æŸ¥åŸå§‹èŠ‚ç‚¹**â€”â€”ç¡®è®¤æ¨¡å‹æ˜¯å¦æ‹¿åˆ°äº†æ­£ç¡®ä¿¡æ¯ï¼Œå†å†³å®šæ˜¯å¦æ€ª LLMã€‚\n",
    "\n",
    "<br>\n",
    "\n",
    "* **ä½¿ç”¨ Ragas åšè‡ªåŠ¨åŒ–è¯„ä¼°**\n",
    "    * **Ragas æä¾›é‡åŒ–æŒ‡æ ‡**â€”â€”æŠŠä¸»è§‚è´¨é‡è½¬åŒ–ä¸ºå¯æµ‹åˆ†æ•°ã€‚\n",
    "    * æ ¸å¿ƒæŒ‡æ ‡ï¼š\n",
    "      - **ç­”æ¡ˆæ­£ç¡®åº¦ï¼ˆAnswer Correctnessï¼‰**ï¼šå›ç­”åœ¨äº‹å®å±‚é¢æœ‰å¤šå‡†ç¡®ã€‚\n",
    "      - **ä¸Šä¸‹æ–‡å¬å›ç‡ï¼ˆContext Recallï¼‰**ï¼šæ£€ç´¢ä¸Šä¸‹æ–‡æ˜¯å¦åŒ…å«æ‰€æœ‰ç›¸å…³äº‹å®ã€‚\n",
    "      - **ä¸Šä¸‹æ–‡ç²¾åº¦ï¼ˆContext Precisionï¼‰**ï¼šæ£€ç´¢æ–‡æœ¬å—æ˜¯å¦ç›¸å…³ï¼Œæ˜¯å¦å­˜åœ¨å¤§é‡å™ªå£°ã€‚\n",
    "      - **å¿ å®åº¦ï¼ˆFaithfulnessï¼‰**ï¼šå›ç­”æ˜¯å¦æºè‡ªä¸Šä¸‹æ–‡ï¼Œè€Œéå¹»è§‰ã€‚\n",
    "    * **Ragas è®©è¯„ä¼°è¿›å…¥ CI/CD æµç¨‹**â€”â€”æµ‹è¯•ã€æ‰“åˆ†ã€æ”¾å¿ƒä¸Šçº¿ã€‚\n",
    "\n",
    "<br>\n",
    "\n",
    "* **æ„å»ºè´´è¿‘çœŸå®çš„è¯„ä¼°æ•°æ®é›†**\n",
    "    * **ä½¿ç”¨çœŸå®ç”¨æˆ·æé—®**â€”â€”ä¸è¦å‡­ç©ºæœæ’°ï¼š\n",
    "      - èŠå¤©è®°å½•\n",
    "      - æœç´¢å†å²\n",
    "      - æ”¯æŒå·¥å•\n",
    "    * **åŠ å…¥æ¨¡ç³Šã€å«ç³Šæˆ–å¤šé—®ä¸€é¢˜çš„åœºæ™¯**â€”â€”è¿™äº›æœ€éš¾ä¹Ÿæœ€èƒ½æš´éœ²é—®é¢˜ã€‚\n",
    "    * **å®šä¹‰æ¸…æ™°çš„å‚è€ƒç­”æ¡ˆ**â€”â€”æ¯ä¸ªé—®é¢˜çš„â€œæ­£ç¡®ç­”æ¡ˆâ€æ˜¯ä»€ä¹ˆï¼Ÿ\n",
    "    * **æŠŠé¢†åŸŸä¸“å®¶å½“å‰¯é©¾é©¶**â€”â€”ä»–ä»¬çš„è§è§£åº”ä»ç¬¬ä¸€å¤©èµ·å¡‘é€ ä½ çš„è¯„ä¼°æ ‡å‡†ã€‚\n",
    "    * **å°è§„æ¨¡èµ·æ­¥ï¼Œä½†è¦å°½æ—©**â€”â€”å“ªæ€•åªæœ‰ 10 ä¸ªé«˜è´¨é‡ç”¨ä¾‹ï¼Œä¹Ÿèƒ½æ­ç¤ºç³»ç»Ÿæ€§é—®é¢˜ã€‚\n",
    "\n",
    "<br>\n",
    "\n",
    "* **è§£è¯»æŒ‡æ ‡**\n",
    "    * **æŒ‡æ ‡æ˜¯è¯Šæ–­å·¥å…·ï¼Œä¸æ˜¯æˆç»©å•ï¼š**\n",
    "      - `context_recall` ä½ â†’ ä¿®æ£€ç´¢ï¼ˆä¼˜åŒ–åˆ†å—ã€åµŒå…¥æˆ–æœç´¢ï¼‰\n",
    "      - `answer_correctness` ä½ â†’ ä¼˜åŒ–æç¤ºæˆ–æ¢æ›´å¼ºçš„æ¨¡å‹\n",
    "      - `context_precision` é«˜ä½† `answer_correctness` ä½ â†’ æ¨¡å‹åœ¨å¿½ç•¥ä¼˜è´¨ä¸Šä¸‹æ–‡\n",
    "    * **ä¸è¦å­¤ç«‹çœ‹æŒ‡æ ‡**â€”â€”ç»„åˆåˆ†ææ‰èƒ½æ‰¾åˆ°æ ¹å› ã€‚\n",
    "    * **ä¸¾ä¾‹ï¼š** ç­”æ¡ˆæ­£ç¡® + å¬å›ä½ = å¹»è§‰ï¼ˆå±é™©ï¼ï¼‰\n",
    "    * **è¯„ä¼°æ˜¯è¿­ä»£çš„**â€”â€”æµ‹é‡ã€ä¿®å¤ã€å†æµ‹é‡ã€‚\n",
    "\n",
    "<br>\n",
    "\n",
    "* **ä»è¯„ä¼°ä¸­æç‚¼å¯æ‰§è¡Œæ´è§**\n",
    "    * **å…ˆä¿®ä¸Šæ¸¸é—®é¢˜**â€”â€”ç­”æ¡ˆæ­£ç¡®åº¦å¾€å¾€åªæ˜¯ç—‡çŠ¶ã€‚ç»“åˆå…¶ä»–æŒ‡æ ‡å®šä½æ ¹å› ï¼š\n",
    "      - æ£€ç´¢å¤±è´¥ï¼Ÿâ†’ æ”¹è¿›åˆ†å—æˆ–åµŒå…¥\n",
    "      - æç¤ºæ¬ ä½³ï¼Ÿâ†’ åŠ å…¥ç»“æ„ã€ç¤ºä¾‹æˆ–é“¾å¼æ€è€ƒ\n",
    "    * **ä¼˜åŒ–æç¤º**â€”â€”é‡‡ç”¨å¦‚ä¸‹æŒ‡ä»¤ï¼š\n",
    "      - â€œåˆ—å‡ºä»Šå¤©åˆ°æœŸçš„æ‰€æœ‰ä»»åŠ¡ã€‚â€\n",
    "      - â€œè¯·ç”¨é¡¹ç›®ç¬¦å·ä½œç­”ã€‚â€\n",
    "    * **å¯ç”¨å¤šæ­¥æ¨ç†**â€”â€”ä½¿ç”¨å…·å¤‡æ€è€ƒæ¨¡å¼çš„æ¨ç†æ¨¡å‹ï¼ˆå¦‚ Qwen-plusï¼‰ï¼Œå‡å°‘é—æ¼ç»†èŠ‚ã€‚\n",
    "    * **è¯„ä¼°çš„çœŸæ­£ä»·å€¼**ä¸åœ¨åˆ†æ•°ï¼Œè€Œåœ¨äºè¿™äº›åˆ†æ•°æ¿€å‘çš„**æ´è§**ï¼Œå®ƒä»¬èƒ½ä¿ƒæˆæ›´åˆç†çš„ç³»ç»Ÿè®¾è®¡ã€‚"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM Engineer (Professional)",
   "language": "python",
   "name": "llm_pro"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
