{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98b60110-1258-497c-80f1-98ccaf5b0f04",
   "metadata": {},
   "source": [
    "# RAG ä¼˜åŒ–æŠ€å·§\n",
    "\n",
    "---\n",
    "\n",
    "å½“ä½ å·²ç»æ„å»ºäº†åŸºç¡€çš„ RAG ç³»ç»Ÿï¼Œå¹¶è§è¯å®ƒå¦‚ä½•å€ŸåŠ©ä½ çš„ç§æœ‰æ•°æ®æå‡ LLM çš„è§£ç­”èƒ½åŠ›åï¼Œç°åœ¨æ˜¯è¿›ä¸€æ­¥æå‡çš„æ—¶å€™äº†ã€‚\n",
    "\n",
    "åœ¨æœ¬ç« ä¸­ï¼Œæˆ‘ä»¬å°†æ¢ç´¢è¿›é˜¶çš„ RAG æŠ€æœ¯ï¼Œå¸®åŠ©ä½ ï¼š\n",
    "\n",
    "* æ£€ç´¢æ›´å‡†ç¡®ã€æ›´ç›¸å…³çš„æ–‡æ¡£\n",
    "* å‡å°‘å¹»è§‰\n",
    "* æå‡å›ç­”è´¨é‡\n",
    "* å¤„ç†å¤æ‚æˆ–æ¨¡ç³Šçš„æŸ¥è¯¢\n",
    "\n",
    "## åˆ°ç›®å‰ä¸ºæ­¢çš„æ•…äº‹â€¦â€¦\n",
    "\n",
    "**åœºæ™¯ï¼š**\n",
    "ç”¨æˆ·éå¸¸å–œæ¬¢æ–°ä¸Šçº¿çš„åŠŸèƒ½ï¼Œä»–ä»¬å¯ä»¥ç›´æ¥ä¸ **TaskFriend** èŠå¤©åˆ†äº«è‡ªå·±çš„æ—¥å¸¸ã€‚ç„¶è€Œï¼Œä»–ä»¬ä¹Ÿå‘ç° **TaskFriend** æœ‰æ—¶æ— æ³•æ£€ç´¢åˆ°ä»–ä»¬æƒ³è¦çš„ä¿¡æ¯ã€‚\n",
    "\n",
    "\n",
    "## ç›®æ ‡\n",
    "\n",
    "* æå‡ **TaskFriend** æ£€ç´¢å‡†ç¡®ã€ç›¸å…³ä»»åŠ¡çš„èƒ½åŠ›\n",
    "* å‡å°‘å› ä¸Šä¸‹æ–‡ç¼ºå¤±æˆ–æ— å…³è€Œå¯¼è‡´çš„é”™è¯¯å›ç­”\n",
    "* å¸®åŠ© **TaskFriend** ç†è§£å¤æ‚æˆ–æ¨¡ç³Šçš„æŸ¥è¯¢ï¼Œä¾‹å¦‚ `\"I'm stuck â€” what should I do next?\"`\n",
    "* é€šè¿‡ä¼˜åŒ– RAG æµæ°´çº¿ï¼Œè®© **TaskFriend** æä¾›æ›´æœ‰å¸®åŠ©ã€æ›´æœ‰ä¾æ®çš„å›ç­”\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1afdf00-aee6-4ffd-b947-fa2c0b333a30",
   "metadata": {},
   "source": [
    "## åˆå§‹åŒ–ç¯å¢ƒ\n",
    "\n",
    "### è®¾ç½® API Key\n",
    "\n",
    "åœ¨ä»»ä½•ç¬”è®°æœ¬å¼€å§‹ä¹‹å‰ï¼Œæˆ‘ä»¬éƒ½éœ€è¦åŠ è½½ [Model Studio çš„ API Key](https://modelstudio.console.alibabacloud.com/?tab=globalset#/efm/api_key)ã€‚è¿™èƒ½ç¡®ä¿æˆ‘ä»¬å¯ä»¥è°ƒç”¨æ•´ä¸ªè¯¾ç¨‹ä¸­å°†ä½¿ç”¨åˆ°çš„ Qwen æ¨¡å‹ APIã€‚\n",
    "\n",
    "> å¦‚æœä½ ä¸ç¡®å®šå¦‚ä½•æ‰¾åˆ° **Model Studio** çš„ API Keyï¼Œè¯·å‚é˜… `00 Setting Up the Environment` æ–‡æ¡£ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1e575a-2333-4f9f-95be-1cba64ced07a",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load Model Studio API key\n",
    "import os\n",
    "from config.load_key import load_key\n",
    "load_key(\n",
    "    confirmation=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498147ef-0dcb-4c19-aea0-7789dba0fa58",
   "metadata": {},
   "source": [
    "### é…ç½® LLM å®¢æˆ·ç«¯\n",
    "\n",
    "æˆ‘ä»¬å°†ä½¿ç”¨ DashScope æä¾›çš„ OpenAI å…¼å®¹æ¥å£æ¥ä¸ Qwen æ¨¡å‹ï¼ˆä»¥åŠæœ¬è¯¾ç¨‹ä¸­ä¼šç”¨åˆ°çš„å…¶ä»–æ¨¡å‹ï¼‰äº¤äº’ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854d1b2c-9840-46ae-9e7d-210e3a57e905",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=os.getenv(\"DASHSCOPE_API_KEY\"),\n",
    "    base_url=\"https://dashscope-intl.aliyuncs.com/compatible-mode/v1\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1618ff-6d66-48f5-b2ff-160257ff0e94",
   "metadata": {},
   "source": [
    "## è®¾ç½®å…¨å±€å‚æ•°\n",
    "\n",
    "æˆ‘ä»¬å°†æ²¿ç”¨ä¸Šä¸€ç« ä¸­ä½¿ç”¨çš„å…¨å±€å‚æ•°é…ç½®ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f084310-96c6-4084-9253-fd67b53e175b",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set global settings\n",
    "import dashscope\n",
    "from llama_index.core import Settings, VectorStoreIndex, SimpleDirectoryReader\n",
    "from llama_index.embeddings.dashscope import DashScopeEmbedding\n",
    "from llama_index.llms.openai_like import OpenAILike\n",
    "\n",
    "\n",
    "\n",
    "# Dashscope uses https://dashscope-intl.aliyuncs.com/api/v1 \n",
    "# instead of https://dashscope-intl.aliyuncs.com/compatible-mode/v1\n",
    "dashscope.base_http_api_url =\"https://dashscope-intl.aliyuncs.com/api/v1\"\n",
    "\n",
    "Settings.llm=OpenAILike(\n",
    "    model=\"qwen-plus\",\n",
    "    api_base=\"https://dashscope-intl.aliyuncs.com/compatible-mode/v1\",\n",
    "    api_key=os.getenv(\"DASHSCOPE_API_KEY\"),\n",
    "    is_chat_model=True\n",
    ")\n",
    "\n",
    "Settings.embed_model = DashScopeEmbedding(\n",
    "    model_name=\"text-embedding-v3\",\n",
    "    api_key=os.getenv(\"DASHSCOPE_API_KEY\"),\n",
    "    encoding_format=\"float\"\n",
    ")\n",
    "\n",
    "print(\"âœ… Global parameters set!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02121547-a4b9-47e6-9104-7757ed01739b",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def highlight_words(text, words_to_highlight, emoji=\"â­\"):\n",
    "    for word in words_to_highlight:\n",
    "        if word in text:\n",
    "            text = text.replace(word, f\"{emoji}{word}{emoji}\")\n",
    "    return text\n",
    "\n",
    "\n",
    "def get_rag_response_with_info(query, query_engine, highlight=None):\n",
    "    print(\"ğŸš€ TaskFriend Conversation (single-round)\")\n",
    "    print(\"-\" * 50)\n",
    "    print(f'ğŸ‘¤ You: {query}')\n",
    "    \n",
    "    try:\n",
    "        # ğŸ” Query the RAG engine\n",
    "        response = query_engine.query(query)\n",
    "\n",
    "        # ğŸ§  Extract the answer\n",
    "        if hasattr(response, 'response'):\n",
    "            answer = response.response\n",
    "        else:\n",
    "            answer = str(response)\n",
    "\n",
    "        # ğŸ“š Show source references AFTER the answer\n",
    "        print(\"ğŸ¤– TaskFriend:\", answer)\n",
    "        print('\\n\\n' + '=' * 50)\n",
    "        print('ğŸ“š References\\n')\n",
    "        \n",
    "        highlight = highlight or []\n",
    "        for i, source_node in enumerate(response.source_nodes, start=1):\n",
    "            print(f'Chunk {i}:')\n",
    "            \n",
    "            # Highlight words in chunk\n",
    "            highlighted_text = highlight_words(source_node.text, highlight)\n",
    "            print(highlighted_text)\n",
    "            print()\n",
    "        print('=' * 50)\n",
    "\n",
    "        return answer\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[RAG Error] {e}\")\n",
    "        return \"[Error retrieving response]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05fe6a6-34bf-47a4-8670-f17b205ecb62",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index.core import StorageContext, load_index_from_storage\n",
    "\n",
    "persist_path=\"./knowledge_base/taskfriend\"\n",
    "\n",
    "# Import index (\"knowledgebase\") we built last chapter,\n",
    "storage_context = StorageContext.from_defaults(\n",
    "    persist_dir=persist_path,\n",
    ")\n",
    "\n",
    "index = load_index_from_storage(\n",
    "    storage_context,\n",
    "    embed_model=Settings.embed_model\n",
    ")\n",
    "print(f\"âœ… Index loaded from `{persist_path}`!\")\n",
    "\n",
    "# Build the query engine (used to implement RAG)\n",
    "query_engine = index.as_query_engine(\n",
    "    streaming=False,\n",
    "    llm=Settings.llm,\n",
    "    embeddings=Settings.embed_model,\n",
    ")\n",
    "print(\"âœ… Query engine built!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068b90a4-1ca2-46b8-8110-592443694471",
   "metadata": {},
   "source": [
    "# æå‡ RAG æ€§èƒ½çš„åŸºç¡€ç­–ç•¥\n",
    "\n",
    "---\n",
    "\n",
    "æ—¢ç„¶ä½ å·²ç»å­¦ä¼šå¦‚ä½•è¯„ä¼° RAG ç³»ç»Ÿå¹¶æ‰¾å‡ºè–„å¼±ç¯èŠ‚ï¼Œç°åœ¨å°±è¯¥åŠ¨æ‰‹ä¿®å¤å®ƒä»¬äº†ã€‚ä½ å·²ç»çœ‹åˆ°å„ç§ç—‡çŠ¶â€”â€”å¬å›ç‡ä½ã€å‡†ç¡®ç‡å·®ã€å¹»è§‰é¢‘å‘â€”â€”æ¥ä¸‹æ¥å°±æ˜¯å¼€è¯æ–¹ã€‚\n",
    "\n",
    "ä¼˜åŒ– RAG æµæ°´çº¿å¹¶ä¸æ˜¯é­”æ³•ï¼Œè€Œæ˜¯å›´ç»•å…³é”®ç»„ä»¶åšå‡ºèªæ˜ã€ç²¾å‡†çš„è°ƒæ•´ã€‚ä¸‹å›¾å±•ç¤ºäº†æœ¬ç« å°†ä»‹ç»çš„åŸºç¡€ä¼˜åŒ–ç­–ç•¥æµç¨‹å›¾ã€‚è¿™äº›ä¹Ÿæ˜¯å½“å‰æœ€å€¼å¾—æ‹‰åŠ¨ã€æœ€å…·å½±å“åŠ›çš„è°ƒä¼˜æ æ†ã€‚\n",
    "\n",
    "```mermaid\n",
    "graph TD\n",
    "    classDef frameworkStyle fill:#ffffff,stroke:#1f77b4,stroke-width:2px;\n",
    "    classDef retrieval fill:#e3f2fd,stroke:#1976d2,stroke-width:2px;\n",
    "    classDef embedding fill:#e8f5e8,stroke:#388e3c,stroke-width:2px;\n",
    "    classDef chunking fill:#fff3e0,stroke:#f57c00,stroke-width:2px;\n",
    "\n",
    "    subgraph flowchart [RAG ä¼˜åŒ–æµæ°´çº¿]\n",
    "        A[ç”¨æˆ·æŸ¥è¯¢] --> B[æ£€ç´¢]\n",
    "        subgraph \"ä¼˜åŒ–ï¼šsimilarity_top_k\"\n",
    "            direction TB\n",
    "            B --> C[å‘é‡åº“æœç´¢]\n",
    "            C --> D[æ£€ç´¢ Top-K æ–‡æœ¬å—]\n",
    "            style D fill:#e3f2fd,stroke:#1976d2\n",
    "        end\n",
    "\n",
    "        subgraph \"ä¼˜åŒ–ï¼šåµŒå…¥æ¨¡å‹\"\n",
    "            direction TB\n",
    "            E[åµŒå…¥æ¨¡å‹] --> C\n",
    "            style E fill:#e8f5e8,stroke:#388e3c\n",
    "        end\n",
    "\n",
    "        D --> F[æ‹¼è£…ä¸Šä¸‹æ–‡]\n",
    "        subgraph \"ä¼˜åŒ–ï¼šåˆ†å—ç­–ç•¥\"\n",
    "            direction TB\n",
    "            G[åˆ†å—ç­–ç•¥] --> H[æºæ–‡æ¡£]\n",
    "            style G fill:#fff3e0,stroke:#f57c00\n",
    "        end\n",
    "        H --> I[åˆ›å»ºå‘é‡ç´¢å¼•]\n",
    "        I --> E\n",
    "        I --> C\n",
    "\n",
    "        F --> J[LLM ç”Ÿæˆ]\n",
    "        J --> K[æœ€ç»ˆå›ç­”]\n",
    "    end\n",
    "\n",
    "    class flowchat frameworkStyle\n",
    "\n",
    "    class D retrieval\n",
    "    class E embedding\n",
    "    class G chunking\n",
    "\n",
    "    style A fill:#f3e5f5,stroke:#7b1fa2\n",
    "    style K fill:#f3e5f5,stroke:#7b1fa2\n",
    "```\n",
    "\n",
    "1. é€šè¿‡è°ƒèŠ‚ `similarity_top_k` ç²¾ç»†æ§åˆ¶æ£€ç´¢ç»“æœï¼›\n",
    "2. é€‰æ‹©åˆé€‚çš„åµŒå…¥æ¨¡å‹ä¸ºè¯­ä¹‰æœç´¢æä¾›åŠ¨åŠ›ï¼›\n",
    "3. æŒæ¡åˆ†å—ç­–ç•¥ï¼Œè®©çŸ¥è¯†ç»“æ„æ›´åˆç†ã€‚\n",
    "\n",
    "è¿™äº›ä¸æ˜¯ç®€å•çš„æŠ€æœ¯å¼€å…³ï¼Œè€Œæ˜¯å†³å®š AI â€œæ€è€ƒæ–¹å¼â€å’Œæ£€ç´¢èƒ½åŠ›çš„æ ¸å¿ƒå†³ç­–ã€‚æˆ‘ä»¬ä¼šç”¨å®é™…ç¤ºä¾‹é€ä¸€æ‹†è§£ï¼Œå‘ä½ å±•ç¤ºå¦‚ä½•æŠŠä¸€ä¸ªè¡¨ç°å¹³å¹³çš„ RAG æ‰“é€ æˆé«˜æ•ˆèƒ½ç³»ç»Ÿã€‚\n",
    "\n",
    "\n",
    "\n",
    "è®©æˆ‘ä»¬å¼€å§‹ï¼Œè®© TaskFriend å˜å¾—æ›´èªæ˜ã€‚\n",
    "\n",
    "\n",
    "## `similarity_top_k`ï¼šæ§åˆ¶ RAG èƒ½çœ‹åˆ°ä»€ä¹ˆ\n",
    " \n",
    "è®©æˆ‘ä»¬å›åˆ°ç†Ÿæ‚‰çš„ç¤ºä¾‹â€”â€”ä¸Šä¸€ç« åšè¿‡çš„å†…å®¹ï¼Œæˆ‘ä»¬å†è·‘ä¸€éã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ff9ee1-bb48-482a-a4f1-c558325d7c46",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# User query\n",
    "query = \"How many tasks are due today, and what are they?\"\n",
    "\n",
    "# Choose words to highlight\n",
    "highlight = [\"Today\"]\n",
    "\n",
    "response = get_rag_response_with_info(query, query_engine=query_engine, highlight=highlight)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9628a10c-d6ea-43ca-9f6c-758a598fcd82",
   "metadata": {},
   "source": [
    "ç°åœ¨æˆ‘ä»¬å¯ä»¥çœ‹åˆ° **TaskFriend**ï¼š\n",
    "\n",
    "* åªä»ç´¢å¼•ä¸­å–å›äº†ä¸¤ä¸ªä¸Šä¸‹æ–‡å—\n",
    "* æ¯ä¸ªå—éƒ½åªå‡ºç°äº†ä¸€æ¬¡å•è¯ `today`\n",
    "* æ ¹æ®æ£€ç´¢åˆ°çš„å†…å®¹ï¼Œå¾—å‡ºä»Šå¤©åªæœ‰ä¸¤ä¸ªä»»åŠ¡åˆ°æœŸ\n",
    "\n",
    "é‚£ä¹ˆï¼Œä¸ºä»€ä¹ˆ **TaskFriend** åªèƒ½çœ‹åˆ°ä¸¤ä¸ªæ–‡æœ¬å—ï¼Ÿå…¶ä»–ä¸Šä¸‹æ–‡éƒ½å»å“ªäº†ï¼Ÿ\n",
    "\n",
    "åŸå› åœ¨äº `query_engine` å‡½æ•°çš„å·¥ä½œæ–¹å¼ã€‚\n",
    "\n",
    "```python\n",
    "query_engine = index.as_query_engine(\n",
    "    ...\n",
    "    similarity_top_k=2       # â† é»˜è®¤å€¼æ˜¯ 2\n",
    ")\n",
    "```\n",
    "\n",
    "`query_engine` æ¥æ”¶ `similarity_top_k` å‚æ•°ï¼Œé»˜è®¤å€¼ä¸º `2`ã€‚è¿™æ„å‘³ç€å®ƒä¼šæ ¹æ®è¾“å…¥æŸ¥è¯¢ï¼Œè¿”å›è¯­ä¹‰ä¸Šæœ€ç›¸ä¼¼çš„å‰ä¸¤ä¸ªæ–‡æœ¬å—ã€‚\n",
    "\n",
    "å› æ­¤ï¼Œå³ä½¿ç´¢å¼•ä¸­è¿˜æœ‰æ›´å¤šç›¸å…³çš„å—â€”â€”ä¾‹å¦‚å…¶ä»–ä»Šå¤©åˆ°æœŸçš„ä»»åŠ¡â€”â€”åªè¦æ²¡æœ‰è¿›å…¥å‰ä¸¤åï¼Œå®ƒä»¬å°±ä¸ä¼šè¢«æ£€ç´¢å‡ºæ¥ï¼Œä¹Ÿä¸ä¼šè¢«ä¼ ç»™ LLM å‚ä¸æ¨ç†ã€‚æ‰€æœ‰æ’åœ¨ Top-K ä¹‹å¤–çš„å†…å®¹ï¼Œå¯¹ TaskFriend æ¥è¯´éƒ½æ˜¯â€œä¸å¯è§â€çš„ã€‚\n",
    "\n",
    "è¿™æ­£æ˜¯ RAG ç³»ç»Ÿçš„å…³é”®é™åˆ¶ï¼šæ¨¡å‹åªèƒ½åŸºäºæ£€ç´¢åˆ°çš„ä¸Šä¸‹æ–‡è¿›è¡Œæ¨ç†ï¼Œè€Œä¸æ˜¯æ•´ä¸ªçŸ¥è¯†åº“ã€‚åªè¦ç›¸å…³ä¿¡æ¯æ²¡è¿›å…¥ Top-Kï¼Œå°±ä¸ä¼šè¢«è€ƒè™‘ï¼Œæœ€ç»ˆå¯¼è‡´å›ç­”ä¸å®Œæ•´ç”šè‡³é”™è¯¯ã€‚\n",
    "\n",
    "æ¦‚æ‹¬æ¥è¯´ï¼Œæˆ‘ä»¬ç°åœ¨å¾—åˆ°çš„æ˜¯ï¼š\n",
    "\n",
    "```\n",
    "[ä»»åŠ¡æ–‡æœ¬å—çš„å‘é‡ç´¢å¼•]\n",
    "â”‚\n",
    "â”œâ”€â”€ Chunk 0: \"Finalize Q3 OKRs - today by 3pm\"                     â† âœ… å·²æ£€ç´¢ï¼ˆé«˜ç›¸å…³ï¼‰\n",
    "â”œâ”€â”€ Chunk 1: \"Update Project Phoenix roadmap â€“ due today\"          â† âœ… å·²æ£€ç´¢\n",
    "â”œâ”€â”€ Chunk 2: \"Renew cloud subscription â€“ due today\"  â† âŒ æœªæ£€ç´¢åˆ°\n",
    "â”œâ”€â”€ Chunk 3: \"Update documentation â€“ due tomorrow\"\n",
    "â”œâ”€â”€ Chunk 4: \"Onboard new intern â€“ due next week\"\n",
    "â”‚\n",
    "â†“\n",
    "[LLM è¾“å…¥ä¸Šä¸‹æ–‡]\n",
    "\n",
    "\"\"\"\n",
    "You need to complete one task today:\n",
    "- Submit Q3 report â€“ due today\n",
    "\"\"\"\n",
    "\n",
    "ğŸ§  LLM è¾“å‡ºï¼šâ€œYou have 2 tasks due today.â€\n",
    "âŒ é—æ¼ï¼šâ€œRenew cloud subscriptionâ€\n",
    "```\n",
    "\n",
    "ç°åœ¨ï¼Œè®©æˆ‘ä»¬è¯•ç€è°ƒæ•´ `similarity_top_k` å‚æ•°ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25c7170-1fa2-4b79-abed-197d93023d0b",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Rebuild query engine with custom similarity_top_k argument\n",
    "query_engine = index.as_query_engine(\n",
    "    streaming=True,\n",
    "    llm=Settings.llm,\n",
    "    embeddings=Settings.embed_model,\n",
    "    similarity_top_k=5       # â† The default value is 2\n",
    ")\n",
    "print(\"âœ… Query engine built!\")\n",
    "print(\"\\nUsing existing query settings...\\n\")\n",
    "response = get_rag_response_with_info(query, query_engine=query_engine, highlight=highlight)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3c5931-a596-4816-a0d6-f1f2b2440e59",
   "metadata": {},
   "source": [
    "å¤ªå¥½äº†ï¼é€šè¿‡å¢åŠ æ£€ç´¢çš„æ–‡æœ¬å—æ•°é‡ï¼Œæˆ‘ä»¬æˆåŠŸæ‰¾åˆ°äº†æ›´å¤šä»Šå¤©åˆ°æœŸçš„ä»»åŠ¡ã€‚`similarity_top_k` ç¡®å®ä¸ºæˆ‘ä»¬æä¾›äº†ä¸€ç§å¿«æ·æ–¹å¼æ¥è·å–æ‰€éœ€å†…å®¹â€”â€”ä½†è¿™çœŸçš„æ˜¯æœ€ä½³åšæ³•å—ï¼Ÿ\n",
    "\n",
    "ç…§è¿™ä¸ªé€»è¾‘ï¼Œæˆ‘ä»¬å®Œå…¨å¯ä»¥æŠŠ `similarity_top_k` è®¾æˆæ•´ä¸ªç´¢å¼•çš„å¤§å°ï¼Œæ£€ç´¢æ‰€æœ‰æ–‡æœ¬å—ï¼Œä¿è¯ä¸ä¼šæ¼æ‰ä»»ä½•ä¸œè¥¿ã€‚ç„¶è€Œï¼Œç°å®ä¸­å­˜åœ¨éå¸¸å®é™…çš„é™åˆ¶ï¼Œä½¿å¾—è¿™ç§åšæ³•ä¸åˆ‡å®é™…ï¼š\n",
    "\n",
    "\n",
    "\n",
    "ç»“åˆä¸Šä¸€ç« å­¦åˆ°çš„è¯„ä¼°æŒ‡æ ‡ï¼Œæˆ‘ä»¬ä¹Ÿè®¸èƒ½å¾—åˆ°æ›´å¤šæ´è§ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0573735f-4713-42d1-b4ea-b344d94466f3",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_dashscope import DashScopeEmbeddings\n",
    "from datasets import Dataset\n",
    "import os\n",
    "import time\n",
    "\n",
    "dashscope.base_http_api_url =\"https://dashscope-intl.aliyuncs.com/api/v1\"\n",
    "\n",
    "# LangChain LLM for Ragas\n",
    "ragas_llm = ChatOpenAI(\n",
    "    model=\"qwen-plus\",\n",
    "    base_url=\"https://dashscope-intl.aliyuncs.com/compatible-mode/v1\",\n",
    "    api_key=os.getenv(\"DASHSCOPE_API_KEY\"),\n",
    "    timeout=60,\n",
    "    max_retries=3\n",
    ")\n",
    "\n",
    "# LangChain Embeddings for Ragas\n",
    "ragas_embeddings = DashScopeEmbeddings(\n",
    "    model=\"text-embedding-v3\",\n",
    "    api_key=os.getenv(\"DASHSCOPE_API_KEY\"),\n",
    ")\n",
    "\n",
    "print(\"âœ… LLM and Embeddings pipeline for Ragas successfully built!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9a615e-ba62-419d-843b-7624c12be436",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ragas import evaluate\n",
    "from ragas.metrics import (\n",
    "    context_recall,\n",
    "    context_precision,\n",
    "    answer_correctness,\n",
    "    faithfulness\n",
    ")\n",
    "from functions.rag_eval_table import create_rag_evaluation_table\n",
    "\n",
    "def eval_output(query_engine, question, ground_truth):\n",
    "    print(\"Performing evaluation...\", end=\"\", flush=True)\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Run query\n",
    "    response = query_engine.query(question)\n",
    "\n",
    "    # Extract answer and context\n",
    "    if hasattr(response, 'get_response'):\n",
    "        completed_response = response.get_response()\n",
    "        answer = getattr(completed_response, 'response', str(completed_response))\n",
    "    else:\n",
    "        answer = getattr(response, 'response_txt', str(response))\n",
    "    \n",
    "    # Ensure answer is a proper string\n",
    "    answer = str(answer) if answer is not None else \"No answer generated\"\n",
    "    \n",
    "    # Get retrieved contexts\n",
    "    contexts = []\n",
    "    for node in response.source_nodes:\n",
    "        content = node.get_content()\n",
    "        # Ensure it's a non-empty string\n",
    "        if content is not None:\n",
    "            content_str = str(content).strip()\n",
    "            if content_str:  # only add non-empty strings\n",
    "                contexts.append(content_str)\n",
    "    \n",
    "    # ğŸ›¡ï¸ RAGAS REQUIREMENT: contexts must be a list of strings (never empty list)\n",
    "    if not contexts:\n",
    "        contexts = [\"\"]  # Ragas expects at least one string\n",
    "\n",
    "    # Construct evaluation dataset\n",
    "    data_samples = {\n",
    "        'question': [str(question)],\n",
    "        'answer': [answer],\n",
    "        'ground_truth': [str(ground_truth)],\n",
    "        'contexts': [contexts],\n",
    "    }\n",
    "    dataset = Dataset.from_dict(data_samples)\n",
    "\n",
    "    # Use Ragas for evaluation\n",
    "    score = evaluate(\n",
    "        dataset=dataset,\n",
    "        metrics=[\n",
    "            answer_correctness, \n",
    "            context_recall, \n",
    "            context_precision, \n",
    "            faithfulness\n",
    "        ],\n",
    "        llm=ragas_llm,\n",
    "        embeddings=ragas_embeddings\n",
    "    )\n",
    "    \n",
    "    load_time = time.time() - start_time\n",
    "    print(f\" âœ… Done ({load_time:.1f} seconds)\")\n",
    "\n",
    "    # Get results as DataFrame\n",
    "    results_df = score.to_pandas()\n",
    "    \n",
    "    # Display the styled HTML table\n",
    "    styled_table = create_rag_evaluation_table(results_df, column_widths=[10, 10, 10, 40, 10, 10, 10], show_contexts=False)\n",
    "    return styled_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76eeabba-3f86-46fd-ba8a-df9e8a8b1e22",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set question & ground_truth\n",
    "question = \"How many tasks do I need to complete today? State the task and short description\"\n",
    "ground_truth = \"\"\"\n",
    "    You have 3 tasks due today:\n",
    "    1. Finalize Q3 OKRs by 3pm â€“ collaborate with department heads to align on measurable objectives.\n",
    "    2. Update 'Project Phoenix' roadmap â€“ sync with project leads to reflect latest timelines, \n",
    "    milestones, and resource allocations.\n",
    "    3. Write thank-you letter to penpal in Korea\n",
    "\"\"\"\n",
    "eval_output(query_engine=query_engine, question=question, ground_truth=ground_truth)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad5b7f6-ac95-407d-a301-b37dad4fc43f",
   "metadata": {},
   "source": [
    "åŸºäºç»“æœï¼Œæˆ‘ä»¬å¯ä»¥å¾—å‡ºä¸€äº›æ¨è®ºï¼ˆå…·ä½“æ•°å€¼å¯èƒ½ç•¥æœ‰å·®å¼‚ï¼Œä½†æ•´ä½“è¶‹åŠ¿åº”ç›¸è¿‘ï¼‰ï¼š\n",
    "\n",
    "|  æŒ‡æ ‡                |  å¾—åˆ†          |  è¯´æ˜               |  ç»“è®º    |\n",
    "|------------------------|-----------------|-----------------------------|---------------|\n",
    "|  ç­”æ¡ˆæ­£ç¡®ç‡    | ä¸­ç­‰ (0.54)      | <ul><li>æ¨¡å‹æ­£ç¡®è¯†åˆ«å‡ºä»Šå¤©åˆ°æœŸçš„ **4 ä¸ªä»»åŠ¡ä¸­çš„ 2 ä¸ª**ï¼š`Finalize Q3 OKRs` å’Œ `Update project roadmap`ã€‚</li><li>æ¼æ‰äº†ä¸¤ä¸ªä»»åŠ¡ï¼š`Onboard new team member` å’Œ `Write thank-you letter`ã€‚</li></ul>   |  ç­”æ¡ˆéƒ¨åˆ†æ­£ç¡®ï¼Œä½†ä¸å®Œæ•´ã€‚    |\n",
    "|  ä¸Šä¸‹æ–‡å¬å›ç‡        | é«˜ (0.80)      | <ul><li>åœ¨å®é™…åº”æ£€ç´¢åˆ°çš„ 4 ä¸ªä»»åŠ¡ï¼ˆæ ‡è®°ä¸ºä»Šæ—¥åˆ°æœŸï¼‰ä¸­ï¼Œ**æ‰¾åˆ°äº† 3 ä¸ª**ï¼š`Finalize Q3 OKRs`ã€`Update project roadmap` å’Œ `Onboard new team member`ã€‚</li><li>ä»…ç¼ºå¤± `Write thank-you letter`ã€‚</li></ul>   |  æ£€ç´¢å™¨å¤§è‡´æœ‰æ•ˆï¼Œä½†ä»æ¼æ‰ä¸€ä¸ªç›¸å…³ä¸Šä¸‹æ–‡ã€‚    |\n",
    "|  ä¸Šä¸‹æ–‡ç²¾ç¡®ç‡     | 0 (0.00)     | <ul><li>æ¨¡å‹å…±æ£€ç´¢åˆ° **5 ä¸ªä¸Šä¸‹æ–‡**ï¼Œä½†åªæœ‰ **2 ä¸ª**ï¼ˆ`Finalize Q3 OKRs`ã€`Update project roadmap`ï¼‰æ˜¯çœŸæ­£ä»Šå¤©åˆ°æœŸçš„ä»»åŠ¡ã€‚</li><li>å¦å¤– 3 ä¸ªè¦ä¹ˆæ˜¯æ›´æ™šåˆ°æœŸï¼Œè¦ä¹ˆå®Œå…¨æ— å…³ï¼ˆå¦‚ `Clean up inbox`ã€`Call bank` ç­‰ï¼‰ã€‚</li></ul>    |  æ£€ç´¢å™¨ç¼ºä¹ç²¾ç¡®åº¦â€”â€”æ‹‰æ¥äº†å¤§é‡æ— å…³å†…å®¹ã€‚    |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c647a8-ab13-4a57-a948-dd6bad7a9a71",
   "metadata": {},
   "source": [
    "# RAG æµæ°´çº¿ï¼šä»æ£€ç´¢åˆ°å¢å¼ºå†åˆ°ç”Ÿæˆ\n",
    "\n",
    "---\n",
    "\n",
    "æ—¢ç„¶ä½ å·²ç»äº†è§£è°ƒæ•´ `similarity_top_k` å¦‚ä½•å¸®åŠ© **TaskFriend** çœ‹åˆ°æ›´å¤šä»»åŠ¡ï¼Œæ¥ä¸‹æ¥å°±è¦å­¦ä¹ æå‡ RAG æ€§èƒ½çš„æ•´ä½“ç­–ç•¥ã€‚ä½†åœ¨æ­¤ä¹‹å‰ï¼Œæˆ‘ä»¬éœ€è¦å…ˆç†è§£æ•´æ¡ RAG æµæ°´çº¿ã€‚\n",
    "\n",
    "```mermaid\n",
    "graph LR\n",
    "  subgraph Ingest[\"æ–‡æ¡£å¯¼å…¥ï¼ˆLlamaIndexï¼‰\"]\n",
    "  direction TB\n",
    "    KB[çŸ¥è¯†åº“] --> PreP[\"é¢„å¤„ç†<br>æ–‡æ¡£\"]\n",
    "  end\n",
    "  subgraph RAG[\"RAGï¼ˆLlamaIndex + Langchainï¼‰\"]\n",
    "  direction LR\n",
    "    PreP -- æ–‡æ¡£ --> Emb[åµŒå…¥<br>æ¨¡å‹]\n",
    "    Emb -- æ–‡æ¡£<br>å‘é‡ --> vDB[(å‘é‡æ•°æ®åº“)]\n",
    "      vDB -- \"æç¤ºè¯ + æŸ¥è¯¢<br>+ æ£€ç´¢ä¸Šä¸‹æ–‡\" --> LLM\n",
    "  end\n",
    "  Usr[ç”¨æˆ·] --> Chatbot\n",
    "  Chatbot -- ç”¨æˆ·æŸ¥è¯¢ --> Emb\n",
    "  Emb -- æŸ¥è¯¢å‘é‡ --> vDB\n",
    "  subgraph Input\n",
    "  direction LR\n",
    "      Usr\n",
    "      Chatbot\n",
    "  end\n",
    "  LLM -- ç”Ÿæˆå›ç­” --> Chatbot\n",
    "```\n",
    "\n",
    "**å·¥ä½œåŸç†**\n",
    "1. æ–‡æ¡£å¯¼å…¥\n",
    "    * æµç¨‹ä»ä½ çš„çŸ¥è¯†åº“å¼€å§‹ï¼ˆä¾‹å¦‚ä»»åŠ¡åˆ—è¡¨ã€æ–‡æ¡£ã€FAQ ç­‰ï¼‰ã€‚\n",
    "    * è¿™äº›æ–‡æ¡£ä¼šè¿›å…¥é¢„å¤„ç†é˜¶æ®µï¼Œåœ¨è¿™é‡Œè¿›è¡Œæ¸…æ´—ã€åˆ‡åˆ†å’Œç´¢å¼•å‡†å¤‡ã€‚\n",
    "2. åµŒå…¥ä¸å­˜å‚¨\n",
    "    * æ–‡æœ¬å—ä¼šé€šè¿‡åµŒå…¥æ¨¡å‹è½¬æ¢æˆæ•°å€¼å‘é‡ã€‚\n",
    "    * è¿™äº›å‘é‡å­˜å‚¨åœ¨å‘é‡æ•°æ®åº“ä¸­ï¼Œä¾¿äºé«˜æ•ˆè¯­ä¹‰æ£€ç´¢ã€‚\n",
    "3. ç”¨æˆ·æŸ¥è¯¢æµç¨‹\n",
    "    * å½“ç”¨æˆ·æäº¤é—®é¢˜æ—¶ï¼ŒèŠå¤©æœºå™¨äººä¼šå°†å…¶å‘é€åˆ°åŒä¸€ä¸ªåµŒå…¥æ¨¡å‹ã€‚\n",
    "    * æŸ¥è¯¢è¢«è½¬æ¢æˆæŸ¥è¯¢å‘é‡ï¼Œè½åœ¨ä¸æ–‡æ¡£ç›¸åŒçš„å‘é‡ç©ºé—´ä¸­ã€‚\n",
    "4. æ£€ç´¢\n",
    "    * ç³»ç»Ÿåœ¨å‘é‡æ•°æ®åº“ä¸­æŸ¥æ‰¾æœ€ç›¸å…³çš„æ–‡æœ¬å—ï¼ˆé€šè¿‡ç›¸ä¼¼åº¦æœç´¢ï¼‰ã€‚\n",
    "    * æ£€ç´¢åˆ°çš„ä¸Šä¸‹æ–‡ä¼šä¸åŸå§‹é—®é¢˜å’Œæç¤ºæ¨¡æ¿ç»„åˆã€‚\n",
    "5. ç”Ÿæˆ\n",
    "    * â€œæç¤ºè¯ + æŸ¥è¯¢ + æ£€ç´¢ä¸Šä¸‹æ–‡â€ è¿™ä¸€å¢å¼ºè¾“å…¥ä¼šè¢«å‘é€åˆ° LLMã€‚\n",
    "    * LLM ç”Ÿæˆå¸¦ä¸Šä¸‹æ–‡çš„å›ç­”ï¼Œå†è¿”å›ç»™èŠå¤©æœºå™¨äººä¾›ç”¨æˆ·æŸ¥çœ‹ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a5f6b2-90a4-4f44-a849-681000ce3e55",
   "metadata": {},
   "source": [
    "# é¢„å¤„ç†ï¼šè®© RAG æ‹¥æœ‰â€œçœ‹æ¸…â€æ•°æ®çš„èƒ½åŠ›\n",
    "\n",
    "---\n",
    "\n",
    "é¢„å¤„ç†é˜¶æ®µå†³å®šäº† RAG ç³»ç»Ÿçš„â€œè§†åŠ›â€â€”â€”èƒ½å¦åœ¨åˆé€‚çš„ç²’åº¦è·å–å‡†ç¡®ä¿¡æ¯ã€‚å®ƒåŒ…å«ä¸¤ä¸ªæ ¸å¿ƒç¯èŠ‚ï¼šæ–‡æ¡£å‡†å¤‡ä¸åˆ†å—ç­–ç•¥ã€‚\n",
    "\n",
    "## å°†åˆé€‚çš„çŸ¥è¯†åŒ¹é…ç»™ç”¨æˆ·éœ€æ±‚\n",
    "\n",
    "åœ¨ä¼˜åŒ–æ£€ç´¢æˆ–ç”Ÿæˆä¹‹å‰ï¼Œå…ˆç¡®ä¿ RAG ç³»ç»Ÿæ‹¥æœ‰æ­£ç¡®çš„åŸºçŸ³ï¼šé«˜è´¨é‡çš„çŸ¥è¯†ã€‚\n",
    "\n",
    "æ¢ä¸ªè§’åº¦çœ‹ï¼š\n",
    "\n",
    "* ç”¨æˆ·çš„æé—®åŸºäºä»–ä»¬çš„éœ€æ±‚â€”â€”è¿™æ„æˆäº†**æ„å›¾ç©ºé—´ï¼ˆintent spaceï¼‰**ã€‚\n",
    "* ä½ çš„çŸ¥è¯†åº“ä¿å­˜ç€ç­”æ¡ˆâ€”â€”è¿™æ„æˆäº†**çŸ¥è¯†ç©ºé—´ï¼ˆknowledge spaceï¼‰**ã€‚\n",
    "\n",
    "| ç»´åº¦ | æ„å›¾ç©ºé—´ | çŸ¥è¯†ç©ºé—´ |\n",
    "|-------|----------------|-------------------|\n",
    "| **å®šä¹‰** | ç”¨æˆ·é€šè¿‡æŸ¥è¯¢è¡¨è¾¾çš„æ‰€æœ‰æ½œåœ¨ç›®æ ‡æˆ–éœ€æ±‚ã€‚ | RAG ç³»ç»Ÿå¯è®¿é—®çš„äº‹å®ã€æ–‡æ¡£ä¸ç»“æ„åŒ–ä¿¡æ¯é›†åˆã€‚ |\n",
    "| **å…³æ³¨ç‚¹** | *â€œç”¨æˆ·æƒ³è¦ä»€ä¹ˆï¼Ÿâ€*â€”â€”ç†è§£ç›®çš„ã€è¯­å¢ƒä¸æŸ¥è¯¢ç±»å‹ã€‚ | *â€œç³»ç»ŸçŸ¥é“ä»€ä¹ˆï¼Ÿâ€*â€”â€”æä¾›å¯æ£€ç´¢ã€å¯å¼•ç”¨çš„å†…å®¹ã€‚ |\n",
    "| **ç¤ºä¾‹** | â€œæ¯”è¾ƒä¸¤ä»¶å•†å“â€ã€â€œé‡ç½®å¯†ç â€ã€â€œè§£é‡ŠæŸä¸ªåŸç†â€ | å†…éƒ¨æ–‡æ¡£ã€FAQã€äº§å“è§„æ ¼ã€ç ”ç©¶è®ºæ–‡ã€æ•°æ®åº“ |\n",
    "| **åœ¨ RAG ä¸­çš„è§’è‰²** | é€šè¿‡è¯†åˆ«æŸ¥è¯¢ç±»å‹ï¼ˆå¦‚äº‹å®ã€æ¯”è¾ƒã€æµç¨‹ï¼‰æ¥æŒ‡å¯¼æ£€ç´¢ï¼Œä½¿æŸ¥è¯¢æ›´åŠ æ„å›¾æ„ŸçŸ¥ã€‚ | ä½œä¸ºæ£€ç´¢æ¥æºâ€”â€”ä»ä¸­æå–ä¸Šä¸‹æ–‡ï¼Œå¢å¼º LLM æç¤ºã€‚ |\n",
    "| **å…³é”®æœºåˆ¶** | è‡ªç„¶è¯­è¨€ç†è§£ï¼ˆNLUï¼‰ã€æ„å›¾åˆ†ç±»æ¨¡å‹ | å‘é‡æ•°æ®åº“ã€è¯­ä¹‰æœç´¢ã€çŸ¥è¯†å›¾è°± |\n",
    "| **è‹¥å¤±é…** | ç³»ç»Ÿè¯¯è§£ç”¨æˆ·ç›®æ ‡ â†’ æ£€ç´¢å‡ºé”™è¯¯å†…å®¹ | ç³»ç»Ÿç¼ºä¹å¿…è¦çŸ¥è¯† â†’ å¯èƒ½å¹»è§‰æˆ–æ²¡æœ‰ç»“æœ |\n",
    "| **ä¼˜åŒ–ç­–ç•¥** | ä½¿ç”¨æŸ¥è¯¢æ”¹å†™ã€æ„å›¾æ ‡æ³¨ã€å¤šæŸ¥è¯¢æ£€ç´¢ï¼Œæ›´å¥½æ•è·ç”¨æˆ·æ„å›¾ | æå‡æ–‡æ¡£è¦†ç›–ç‡ã€æ¸…ç†è¿‡æ—¶å†…å®¹ã€ä¼˜åŒ–åˆ†å—ä»¥æå‡å¯æ£€ç´¢æ€§ |\n",
    "\n",
    "è¦è®© RAG åº”ç”¨æ•ˆæœè‰¯å¥½ï¼Œè¿™ä¸¤ä¸ªç©ºé—´å¿…é¡»æœ‰é‡å ã€‚\n",
    "\n",
    "| åœºæ™¯  | å«ä¹‰  | å¦‚ä½•ä¿®å¤  |\n",
    "|-----------|-----------------|-------------|\n",
    "| æœ‰é‡å   | é—®é¢˜åœ¨ä½ çš„æ–‡æ¡£è¦†ç›–èŒƒå›´å†… â†’ RAG èƒ½ç­”å¥½ã€‚  | æå‡å†…å®¹è´¨é‡ä¸æ£€ç´¢å‡†ç¡®åº¦ã€‚  |\n",
    "| ç¼ºçŸ¥è¯†  | ç”¨æˆ·æé—®çš„æ˜¯æ–°å†…å®¹ï¼ˆå¦‚æ–°äº§å“ï¼‰â†’ RAG å¯èƒ½â€œå¹»è§‰â€ã€‚  | æ·»åŠ æ–°æ–‡æ¡£ï¼Œå®šæœŸæ›´æ–°çŸ¥è¯†åº“ã€‚  |\n",
    "| ç»“æœä¸ç›¸å…³  | æ£€ç´¢åˆ°äº†é”™è¯¯æˆ–æ— å…³å†…å®¹ â†’ è®© LLM å›°æƒ‘ã€‚  | æ”¹è¿›åˆ†å—ã€åµŒå…¥æˆ–æ£€ç´¢é€»è¾‘ï¼Œç§»é™¤è¿‡æ—¶å†…å®¹ã€‚  |\n",
    "\n",
    "> **å…³é”®æ´å¯Ÿï¼š**  \n",
    "> **æ„å›¾ç©ºé—´** å‘Šè¯‰ RAG è¦æ‰¾ä»€ä¹ˆã€‚\n",
    "> **çŸ¥è¯†ç©ºé—´** å‘Šè¯‰ RAG å»å“ªé‡Œæ‰¾ã€‚\n",
    "> åªæœ‰å½“äºŒè€…**å¯¹é½**æ—¶ï¼ŒRAG æ‰èƒ½æä¾›å‡†ç¡®ã€ç›¸å…³ã€å€¼å¾—ä¿¡èµ–çš„å›ç­”ã€‚\n",
    "\n",
    "## æ–‡æ¡£å‡†å¤‡ï¼šä»å¹²å‡€ã€ç»“æ„åŒ–çš„è¾“å…¥å¼€å§‹\n",
    "\n",
    "è¾“å‡ºè´¨é‡å–å†³äºè¾“å…¥è´¨é‡ã€‚çœŸå®ä¸–ç•Œä¸­çš„æ–‡æ¡£æ ¼å¼ç¹å¤šâ€”â€”PDFã€Wordã€Keynoteâ€”â€”è¿˜å¸¸æ··æ‚è¡¨æ ¼ã€å›¾ç‰‡ã€å¤æ‚æ’ç‰ˆã€‚\n",
    "\n",
    "**å¸¸è§æŒ‘æˆ˜ä¸è§£å†³æ–¹æ¡ˆ**  \n",
    "\n",
    "| é—®é¢˜  | å½±å“  | è§£å†³æ–¹æ¡ˆ  |\n",
    "|--------|---------|-----------|\n",
    "| ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼ï¼ˆå¦‚ `.key`ã€`.py`ã€`.json` ç­‰ï¼‰   | è§£æå™¨æ— æ³•â€œè¯»å–â€æ–‡ä»¶ï¼Œå¯¼è‡´çŸ¥è¯†ç©ºé—´å‡ºç°ç©ºç™½  | è½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼ï¼Œå¦‚ `.pdf`ã€`.txt`ã€`.md` ç­‰  |\n",
    "| æå–è´¨é‡å·®ï¼ˆå¦‚è¡¨æ ¼ç ´ç¢ã€å›¾ç‰‡ç¼ºå¤±ï¼‰  | å…³é”®ä¿¡æ¯ä¸¢å¤±æˆ–è¢«æ‰­æ›²  | é€‰æ‹©èƒ½ä¿ç•™ç»“æ„çš„è§£æå™¨ï¼Œæˆ–ä½¿ç”¨ LLM è¿›è¡Œåå¤„ç†æ¶¦è‰²  |\n",
    "| å›¾ç‰‡å†…åµŒæ–‡å­—ï¼ˆå¦‚æˆªå›¾ä¸­çš„å‘½ä»¤ï¼‰  | æ ‡å‡† OCR æ— æ³•æ•è·æ–‡å­—  | ä½¿ç”¨è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰è¯†åˆ«å›¾ç‰‡å†…å®¹å¹¶çº³å…¥çŸ¥è¯†åº“  |\n",
    "\n",
    "\n",
    "### å°†è¾“å…¥æ–‡æ¡£è½¬æ¢ä¸º Markdown\n",
    "\n",
    "`.pdf` è¿™ç±»æ ¼å¼å¯¹äººç±»å‹å¥½ï¼Œä½†å¯¹æœºå™¨ç†è§£å¹¶ä¸è½»æ¾ã€‚æŠŠæ–‡æ¡£è½¬æ¢æˆ Markdown (`.md`) å¯ä»¥æå‡åº”ç”¨å¯¹æ–‡æ¡£çš„ç†è§£èƒ½åŠ›ï¼Œå…¶ä¼˜åŠ¿åŒ…æ‹¬ï¼š\n",
    "\n",
    "* æ›´æ˜ç¡®çš„ç»“æ„ä¸å±‚çº§\n",
    "    * Markdown æ”¯æŒæ ‡é¢˜ï¼ˆ`#`ã€`##` ç­‰ï¼‰ã€åˆ—è¡¨ã€ä»£ç å—ã€å¼ºè°ƒã€‚\n",
    "    * æœ‰åŠ©äºåˆ†å—ç­–ç•¥æŒ‰ç« èŠ‚åˆ’åˆ†å†…å®¹ï¼Œä½¿åˆ‡åˆ†æ›´æœ‰è¯­ä¹‰ã€‚\n",
    "    * æ›´å¥½çš„åˆ†å— â†’ æ›´è¿è´¯çš„ä¸Šä¸‹æ–‡ â†’ æ›´ç›¸å…³çš„æ£€ç´¢ç»“æœã€‚\n",
    "\n",
    "* æ›´æ¸…æ™°çš„è¯­ä¹‰\n",
    "    * æ ‡é¢˜å’Œå°èŠ‚æ˜¯å¤©ç„¶çš„å…ƒæ•°æ®ã€‚\n",
    "    * ä¾‹å¦‚æŸ¥è¯¢ â€œExplain the methodologyâ€ æ›´å®¹æ˜“åŒ¹é…åˆ° `## Methodology` å¼€å¤´çš„å—ã€‚\n",
    "    \n",
    "* ä¿ç•™å…³é”®æ ¼å¼\n",
    "    * ä»£ç å—ï¼ˆ```ï¼‰ä¸è¡Œå†…ä»£ç ï¼ˆ`ï¼‰èƒ½åŒºåˆ†æŠ€æœ¯æœ¯è¯­æˆ–å‘½ä»¤ï¼Œå¯¹æŠ€æœ¯æ–‡æ¡£çš„å‡†ç¡®æ£€ç´¢è‡³å…³é‡è¦ã€‚\n",
    "    * æ‰©å±• Markdown æ”¯æŒåˆ—è¡¨ä¸è¡¨æ ¼ï¼Œä¿ç•™æ¡ç›®ä¹‹é—´çš„å…³ç³»ã€‚\n",
    "\n",
    "å½“ç„¶ï¼Œå®ƒä¹Ÿæœ‰ç¼ºç‚¹ï¼š\n",
    "\n",
    "* **æ ¼å¼ç³Ÿç³•çš„ Markdownï¼š** å¦‚æœæ ‡é¢˜ä¹±ç”¨æˆ–ä¸ä¸€è‡´ï¼Œç»“æ„ä¼šè¯¯å¯¼ç³»ç»Ÿã€‚\n",
    "* **è¿‡åº¦åˆ†å—ï¼š** å°èŠ‚æ‹†å¾—å¤ªç»†ä¼šç ´åä¸Šä¸‹æ–‡ï¼Œåè€Œå½±å“æ£€ç´¢è´¨é‡ã€‚\n",
    "* **å…ƒæ•°æ®ä¸¢å¤±ï¼š** Markdown é»˜è®¤ä¸å¸¦å…ƒæ•°æ®ï¼ˆå¦‚ä½œè€…ã€æ—¶é—´ï¼‰ï¼Œéœ€é€šè¿‡å‰ç½® YAMLï¼ˆå¦‚ `title:`ã€`source:`ï¼‰è¡¥å……ã€‚\n",
    "\n",
    "\n",
    "ä¸ºäº†æ–¹ä¾¿ç†è§£ï¼Œä¸‹é¢åˆ—å‡ºå°†æ–‡æ¡£è½¬æ¢ä¸º Markdown çš„åˆ©å¼Šå¯¹ç…§è¡¨ï¼š\n",
    "\n",
    "| ç»´åº¦ | Markdown å¯¹ RAG æ£€ç´¢çš„å½±å“ | å¤‡æ³¨ / æœ€ä½³å®è·µ |\n",
    "|--------|-------------------------------------|----------------------------|\n",
    "| **æ–‡æ¡£ç»“æ„** | âœ… æ”¹å–„ | ä½¿ç”¨æ ‡é¢˜ï¼ˆ`#`ã€`##`ï¼‰æ„å»ºå±‚çº§ï¼Œå¸®åŠ©æ£€ç´¢ç³»ç»Ÿå®šä½ç›¸å…³æ®µè½ã€‚ |\n",
    "| **è¯­ä¹‰æ¸…æ™°åº¦** | âœ… æ”¹å–„ | æ ‡é¢˜æ˜¯å¤©ç„¶çš„æŸ¥è¯¢åŒ¹é…ä¿¡å·ï¼ˆä¾‹å¦‚â€œ## Methodologyâ€å¯¹åº”â€œæ–¹æ³•è®ºâ€ç›¸å…³é—®é¢˜ï¼‰ã€‚ |\n",
    "| **æ–‡æœ¬åˆ†å—** | âœ… æ”¹å–„ | æ”¯æŒæ›´èªæ˜ã€è¯­ä¹‰æ„ŸçŸ¥çš„åˆ†å—ï¼ˆæŒ‰ç« èŠ‚ï¼‰ï¼Œæå‡æ£€ç´¢ç›¸å…³åº¦ã€‚ |\n",
    "| **æ ¼å¼ä¿ç•™** | âœ… æ”¹å–„ | ä¿ç•™ä»£ç å—ã€åˆ—è¡¨ã€å¼ºè°ƒï¼Œå¯¹äºæŠ€æœ¯æˆ–ç»“æ„åŒ–å†…å®¹å°¤ä¸ºå…³é”®ã€‚ |\n",
    "| **å¤„ç†æ•ˆç‡** | âœ… æ”¹å–„ | çº¯æ–‡æœ¬ã€è½»é‡åŒ–ï¼Œç›¸å¯¹ PDF/HTML æ›´æ˜“è§£æã€ç´¢å¼•ã€æ¸…æ´—ã€‚ |\n",
    "| **å…ƒæ•°æ®æ”¯æŒ** | âš ï¸ å—é™ | åŸç”Ÿ Markdown ç¼ºå°‘å…ƒæ•°æ®ï¼Œå¯ç”¨ YAML å‰ç½®è¡¥å……ï¼ˆå¦‚ `title:`ã€`source:`ï¼‰ã€‚ |\n",
    "| **æ ¼å¼è´¨é‡é£é™©** | âŒ å¯èƒ½æœ‰å®³ | æ ‡é¢˜æˆ–åˆ—è¡¨ä¸è§„èŒƒä¼šè¯¯å¯¼æ£€ç´¢ã€‚å†…å®¹è´¨é‡æ¯”æ ¼å¼æ›´é‡è¦ã€‚ |\n",
    "| **è¿‡åº¦åˆ†å—é£é™©** | âš ï¸ å¯èƒ½æœ‰å®³ | è¿‡å°çš„ç‰‡æ®µä¼šç ´åä¸Šä¸‹æ–‡ï¼Œéœ€è¦å¹³è¡¡å—å¤§å°ä¸è¿è´¯æ€§ã€‚ |\n",
    "| **éä¸‡èƒ½è§£** | âš ï¸ ä¸­æ€§ | Markdown ä¸èƒ½å•ç‹¬è§£å†³å†…å®¹è´¨é‡æˆ–åµŒå…¥æ¨¡å‹é—®é¢˜ã€‚éœ€ä¸é«˜è´¨é‡æ–‡æœ¬å’Œæ¨¡å‹é…åˆã€‚ |\n",
    "| **æœ€ä½³å®è·µ** | â€” | â€¢ ä½¿ç”¨è¯­ä¹‰ä¸€è‡´çš„æ ‡é¢˜<br>â€¢ æŒ‰ç« èŠ‚è¾¹ç•Œåˆ†å—<br>â€¢ ä¿ç•™ä»£ç /åˆ—è¡¨/è¡¨æ ¼<br>â€¢ é€šè¿‡å‰ç½®å…ƒæ•°æ®è¡¥å……ä¿¡æ¯<br>â€¢ è½¬æ¢åæµ‹è¯•æ£€ç´¢æ•ˆæœ |\n",
    "\n",
    "ç°åœ¨ï¼Œè®©æˆ‘ä»¬åšä¸ªå°å®éªŒï¼ŒæŠŠ `./docs/taskfriend/tasks.pdf` è½¬æˆ Markdownï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48774629-2221-4542-a676-6fd25365a157",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import pymupdf4llm  # For Markdown conversion\n",
    "\n",
    "# Convert PDF to Markdown\n",
    "def pdf_to_md(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    md_text = pymupdf4llm.to_markdown(doc)\n",
    "    doc.close()\n",
    "    return md_text\n",
    "\n",
    "# Convert your file\n",
    "md_content = pdf_to_md(\"./docs/taskfriend/tasks.pdf\")\n",
    "\n",
    "print(\"ğŸ“„ Raw Markdown Output:\")\n",
    "print(\"-\" * 100)\n",
    "print(md_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6869634-88e1-4a14-be67-2e647e5b05c7",
   "metadata": {},
   "source": [
    "æ­£å¦‚ä½ æ‰€è§ï¼ŒåŸå§‹è¾“å‡ºä¸æˆ‘ä»¬ä¹‹å‰å¾—åˆ°çš„æ–‡æœ¬å—ç›¸å·®æ— å‡ â€”â€”å­˜åœ¨æ‹¼å†™é”™è¯¯ï¼Œè¡¨æ ¼åœ¨åˆ†é¡µæ—¶è¢«â€œæ‹†ç¢â€ã€‚è¿™äº›éƒ½å±äºæˆ‘ä»¬åˆšæåˆ°çš„ Markdown è½¬æ¢ç¼ºç‚¹ã€‚ä¸è¿‡äº‹æƒ…å¹¶æœªç»“æŸï¼Œæˆ‘ä»¬å¯ä»¥å€ŸåŠ© LLMï¼šæŠŠåŸå§‹ `.md` è¾“å‡ºå–‚ç»™æ¨¡å‹ï¼Œè®©å®ƒä¿®å¤å¤§éƒ¨åˆ†é—®é¢˜ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6201ce1b-a020-4047-ab37-2911f3c12b92",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from dashscope import Generation\n",
    "\n",
    "def md_polisher(markdown_text, model=\"qwen-plus\"):\n",
    "    prompt = f\"\"\"\n",
    "The following Markdown text is converted from a PDF. Please fix and polish it:\n",
    "1. Fix heading hierarchy and missing info.\n",
    "2. Correct inconsistent context or tables.\n",
    "3. Ensure lists and code blocks are properly formatted.\n",
    "4. Do NOT invent new content.\n",
    "5. Output only the cleaned Markdown.\n",
    "\n",
    "Content:\n",
    "{markdown_text}\n",
    "\"\"\"\n",
    "    messages = [{'role': 'user', 'content': prompt}]\n",
    "    \n",
    "    response = Generation.call(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        result_format='message',\n",
    "        stream=True,\n",
    "        incremental_output=True  # Good for long responses\n",
    "    )\n",
    "    \n",
    "    result = \"\"\n",
    "    print(\"âœ¨ Polished Markdown:\")\n",
    "    print(\"-\" * 50)\n",
    "    for chunk in response:\n",
    "        content = chunk.output.choices[0].message.content\n",
    "        print(content, end='')\n",
    "        result += content\n",
    "    return result\n",
    "\n",
    "# Polish the output\n",
    "polished_md = md_polisher(md_content)\n",
    "\n",
    "# Optional: Save to file\n",
    "with open(\"./docs/tasks_polished.md\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(polished_md)\n",
    "\n",
    "\n",
    "print(\"\\n\\n\" + \"-\" * 50)\n",
    "print(\"âœ… Saved polished Markdown to ./docs/tasks_polished.md\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b804dc91-8605-45ec-bcc8-4dde3e22b37f",
   "metadata": {},
   "source": [
    "å¦‚æœä½ æ›´å–œæ¬¢ `.md` åˆ—è¡¨æ ¼å¼ï¼Œä¹Ÿå¯ä»¥è°ƒæ•´æç¤ºè¯ï¼Œè®©æ¶¦è‰²ç»“æœç¬¦åˆä½ çš„è¦æ±‚ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdbd4b70-fc14-4645-a3fd-d11b367cdeed",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def md_polisher_to_list(markdown_text, model=\"qwen-plus\"):\n",
    "    prompt = f\"\"\"\n",
    "The following Markdown text is converted from a PDF. Please fix and polish it:\n",
    "1. Fix heading hierarchy and missing info.\n",
    "2. Correct inconsistent context or tables.\n",
    "3. Format as a clean markdown list grouped by due date.\n",
    "4. Summarize notes as a single, concise sentence.\n",
    "5. Output only the cleaned Markdown.\n",
    "\n",
    "[Examples]\n",
    "# Completed\n",
    "ID: <task_id> | <task_name> - <recurring> task due <due>, <summarized notes>.\n",
    "\n",
    "## Due Today\n",
    "ID: <task_id> | <task_name> - <recurring> task due <due>, <summarized notes>.\n",
    "\n",
    "## Due This Week\n",
    "ID: <task_id> | <task_name> - <recurring> task due <due>, <summarized notes>.\n",
    "\n",
    "Content:\n",
    "{markdown_text}\n",
    "\"\"\"\n",
    "    messages = [{'role': 'user', 'content': prompt}]\n",
    "    \n",
    "    response = Generation.call(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        result_format='message',\n",
    "        stream=True,\n",
    "        incremental_output=True  # Good for long responses\n",
    "    )\n",
    "    \n",
    "    result = \"\"\n",
    "    print(\"âœ¨ Polished Markdown:\")\n",
    "    print(\"-\" * 50)\n",
    "    for chunk in response:\n",
    "        content = chunk.output.choices[0].message.content\n",
    "        print(content, end='')\n",
    "        result += content\n",
    "    return result\n",
    "\n",
    "# Polish the output\n",
    "polished_md = md_polisher_to_list(md_content)\n",
    "\n",
    "# Optional: Save to file\n",
    "with open(\"./docs/taskfriend/tasks_list_polished.md\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(polished_md)\n",
    "\n",
    "\n",
    "print(\"\\n\\n\" + \"-\" * 50)\n",
    "print(\"âœ… Saved polished Markdown to ./docs/taskfriend/tasks_list_polished.md\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d313d9-54a5-4c80-9fff-7952f80814b9",
   "metadata": {},
   "source": [
    "è¿™æ˜¯ä¸€ä¸ªç®€å•ä½†é«˜æ•ˆçš„æµç¨‹ï¼šå…ˆæŠŠ `.pdf` è½¬æˆ `.md`ï¼Œå†ä¿®å¤æ½œåœ¨é—®é¢˜ï¼Œä»è€Œå……åˆ†åˆ©ç”¨ç»“æ„åŒ–æ ¼å¼ï¼Œä¸º RAG ç³»ç»Ÿæ‰“å¥½åŸºç¡€ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d1cd86-da71-4fae-b207-ca10846801e5",
   "metadata": {},
   "source": [
    "## åˆ†å—ï¼šåœ¨ä¸Šä¸‹æ–‡ä¸ç²¾åº¦ä¹‹é—´å¯»æ‰¾å¹³è¡¡\n",
    "\n",
    "åˆ†å—å†³å®šäº†æ–‡æ¡£åœ¨è¢«åµŒå…¥å’Œå­˜å‚¨ä¹‹å‰å¦‚ä½•æ‹†åˆ†ã€‚å—å¤ªå°ä¼šä¸¢å¤±ä¸Šä¸‹æ–‡ï¼Œå—å¤ªå¤§åˆä¼šå¼•å…¥å™ªéŸ³ã€‚\n",
    "\n",
    "ä¸å­˜åœ¨â€œä¸€åˆ€åˆ‡â€çš„æ–¹æ³•â€”â€”ä»¥ä¸‹æ˜¯æœ€å¸¸ç”¨çš„ç­–ç•¥ï¼š\n",
    "\n",
    "| æ–¹æ³•  | æœ€é€‚åˆåœºæ™¯  | æ ¸å¿ƒä¼˜åŠ¿  |\n",
    "|---------|-----------|--------------|\n",
    "| å¥å­åˆ‡åˆ†  | é€šç”¨åœºæ™¯  | ä¿ç•™å¥å­è¾¹ç•Œï¼Œç»“æ„æ¸…æ™°å¯æ§  |\n",
    "| Token åˆ‡åˆ†  | æ¨¡å‹ä¸Šä¸‹æ–‡çª—å£ä¸¥æ ¼å—é™æ—¶  | ç²¾ç¡®æ§åˆ¶ Token æ•°  | \n",
    "| å¥çª—æ³•  | å¯¹ä¸Šä¸‹æ–‡è¦æ±‚é«˜çš„æŸ¥è¯¢  | åœ¨æ£€ç´¢æ—¶é™„å¸¦ä¸Šä¸‹æ–‡çª—å£  | \n",
    "| è¯­ä¹‰åˆ‡åˆ†  | æŠ€æœ¯æ–‡æ¡£æˆ–å¤æ‚å†…å®¹  | åŸºäºè¯­ä¹‰è€Œéé•¿åº¦è¿›è¡Œåˆ‡åˆ†  | \n",
    "| Markdown åˆ‡åˆ†  | æ–‡æ¡£ã€READMEã€ç»“æ„åŒ–å†…å®¹  | å°Šé‡æ ‡é¢˜ä¸ç« èŠ‚ç»“æ„ï¼Œé€‚åˆå±‚çº§çŸ¥è¯†  | \n",
    "\n",
    "**å¦‚ä½•é€‰æ‹©ï¼Ÿ**\n",
    "\n",
    "* **åˆšå…¥é—¨ï¼Ÿ** ä½¿ç”¨å¥å­åˆ‡åˆ†ï¼Œé€‚é…å¤§å¤šæ•°åœºæ™¯ã€‚\n",
    "* **é•¿æ–‡æ¡£ï¼Ÿ** å°è¯•å¥çª—æ³•æˆ–è¯­ä¹‰åˆ‡åˆ†ã€‚\n",
    "* **ä½¿ç”¨ Markdown æ–‡æ¡£ï¼Ÿ** ç”¨ MarkdownNodeParser ä¿ç•™ç« èŠ‚è¾¹ç•Œã€‚\n",
    "* **é¢‘ç¹è§¦ç¢°ä¸Šä¸‹æ–‡ä¸Šé™ï¼Ÿ** æ”¹ç”¨å¸¦é‡å çš„ Token åˆ‡åˆ†ã€‚\n",
    "\n",
    "> æ²¡æœ‰ä»»ä½•æ–¹æ³•æ˜¯**å®Œç¾**çš„ã€‚  \n",
    "> ä½¿ç”¨è¯„ä¼°æŒ‡æ ‡ï¼ˆå¦‚æ£€ç´¢å‡†ç¡®åº¦ã€å›ç­”ç›¸å…³åº¦ï¼‰æµ‹è¯•ä¸åŒåˆ†å—æ–¹å¼ï¼Œå¹¶ä¸æ–­è¿­ä»£ã€‚\n",
    "\n",
    "åœ¨ä»‹ç»ä¸åŒåˆ†å—æ–¹æ³•ä¹‹å‰ï¼Œæˆ‘ä»¬å…ˆåŠ è½½ä¾èµ–ï¼Œå¹¶å†™ä¸€ä¸ªæ–¹ä¾¿å¯¹æ¯”åˆ†å—æ•ˆæœçš„å‡½æ•°ï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca6d4f6-7dad-4f83-b91c-d5b3ab6189f9",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index.core.node_parser import (\n",
    "    SentenceSplitter,\n",
    "    SemanticSplitterNodeParser,\n",
    "    SentenceWindowNodeParser,\n",
    "    MarkdownNodeParser,\n",
    "    TokenTextSplitter\n",
    ")\n",
    "from llama_index.core.postprocessor import MetadataReplacementPostProcessor\n",
    "\n",
    "documents = SimpleDirectoryReader(\n",
    "    input_dir=\"./docs/taskfriend\",\n",
    "    required_exts=[\".md\"],\n",
    "    recursive=False\n",
    ").load_data()\n",
    "\n",
    "def eval_splitter(splitter, documents, question, ground_truth, splitter_name):\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"ğŸ” EVALUATING: {splitter_name}\")\n",
    "    print(f\"{'='*50}\\n\")\n",
    "    \n",
    "\n",
    "    print(\"ğŸ§± Parsing documents into chunks...\")\n",
    "    nodes = splitter.get_nodes_from_documents(documents)\n",
    "    print(f\"   â†’ Created {len(nodes)} chunks\")\n",
    "    index = VectorStoreIndex(nodes, embed_model=Settings.embed_model)\n",
    "\n",
    "    query_engine = index.as_query_engine(\n",
    "        similarity_top_k=5,\n",
    "        streaming=True\n",
    "    )\n",
    "\n",
    "    print(f\"\\nğŸ‘¤ You: {question}\")\n",
    "    print(\"\\nğŸ¤– TaskFriend:\")\n",
    "    response = query_engine.query(question)\n",
    "    response.print_response_stream()\n",
    "\n",
    "    # Show retrieved contexts\n",
    "    print(f\"\\n\\nğŸ“Œ Retrieved contexts:\")\n",
    "    print(f\"{'-'*50}\\n\")\n",
    "    source_contexts = [node.get_content() for node in response.source_nodes]\n",
    "    for i, ctx in enumerate(source_contexts):\n",
    "        ctx_len = len(ctx)\n",
    "        print(f\"Chunk {i+1} | {ctx_len} chars:\\n{ctx}\\n\")\n",
    "\n",
    "    # Show evaluation table\n",
    "    print(f\"\\nğŸ“Š {splitter_name} evaluation:\")\n",
    "    print(\"-\" * 50)\n",
    "    display(eval_output(query_engine, question, ground_truth))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20e9a4c-9c57-4776-a683-f9a5e34b28d2",
   "metadata": {},
   "source": [
    "### å¥å­åˆ‡åˆ†\n",
    "\n",
    "**å·¥ä½œåŸç†**ï¼š  \n",
    "æŒ‰ç…§è‡ªç„¶çš„å¥å­è¾¹ç•Œï¼ˆå¦‚ `.`, `!`, `?`ï¼‰ç»“åˆå¯å‘å¼è§„åˆ™åˆ‡åˆ†æ–‡æœ¬ï¼Œç›´åˆ°è¾¾åˆ°è®¾å®šçš„å­—ç¬¦æˆ– Token é™åˆ¶ã€‚\n",
    "\n",
    "\n",
    "```\n",
    "åŸå§‹æ–‡æœ¬ï¼š\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚ Allen loves AI. He reads papers daily. LLMs are amazing!   â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "\n",
    "å¥å­åˆ‡åˆ†åï¼š\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚ Allen loves AI. â”‚ â”‚ He reads papers daily. â”‚ â”‚ LLMs are amazing!   â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "     å— 1                å— 2                         å— 3\n",
    "```\n",
    "\n",
    "**ä¼˜ç‚¹** âœ…\n",
    "* ä¿ç•™è‡ªç„¶è¯­è¨€çš„è¯­åºæµç•…æ€§\n",
    "* è¿è¡Œé€Ÿåº¦å¿«ã€è®¡ç®—æˆæœ¬ä½\n",
    "* æ˜“äºé€šè¿‡ `chunk_size`ï¼ˆæŒ‰å­—ç¬¦æˆ– Tokenï¼‰é…ç½®\n",
    "* é€‚ç”¨äºå¤§å¤šæ•°æ–‡æœ¬ç±»å‹\n",
    "\n",
    "**ç¼ºç‚¹** âŒ\n",
    "* å¯èƒ½äº§ç”Ÿéå¸¸çŸ­çš„å—ï¼ˆä¾‹å¦‚ â€œYes.â€ æˆ– â€œè§ä¸Šâ€ï¼‰\n",
    "* è‹¥å…³é”®è¯­ä¹‰è·¨è¶Šå¤šå¥ï¼Œå¯èƒ½æ‰“æ–­ä¸Šä¸‹æ–‡\n",
    "* ç›¸æ¯” Token åˆ‡åˆ†ï¼Œå¯¹ LLM ä¸Šä¸‹æ–‡é™åˆ¶æ§åˆ¶ä¸å¤Ÿç²¾ç¡®\n",
    "\n",
    "**é€‚ç”¨åœºæ™¯**\n",
    "* åˆæ¬¡æ„å»º RAG æµæ°´çº¿\n",
    "* æ–‡æœ¬æ ‡ç‚¹æ¸…æ™°ã€è¯­å¥è§„æ•´\n",
    "* éœ€è¦ä¸€ä¸ªç®€å•å¯é çš„åŸºçº¿åˆ‡åˆ†å™¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc721c1-c0c7-4a27-9516-2fb9f5e60f57",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sentence_splitter = SentenceSplitter(\n",
    "    chunk_size=100,\n",
    "    chunk_overlap=20\n",
    ")\n",
    "eval_splitter(sentence_splitter, documents, question, ground_truth, \"SentenceSplitter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5d294e-37cd-47c4-b9f3-9844ef4bce02",
   "metadata": {},
   "source": [
    "### Token åˆ‡åˆ†\n",
    "\n",
    "**å·¥ä½œåŸç†**ï¼š  \n",
    "åŸºäº **Token**ï¼ˆLLM ç†è§£çš„æœ€å°å•ä½ï¼‰æ¥åˆ‡åˆ†æ–‡æœ¬ã€‚å½“è¾¾åˆ°è®¾å®šçš„ `chunk_size` æ—¶ï¼Œå°±è¿›è¡Œåˆ†å‰²ã€‚\n",
    "\n",
    "\n",
    "```\n",
    "æ–‡æœ¬ï¼š\n",
    "The quick brown fox jumps over the lazy dog near the park.\n",
    "\n",
    "\n",
    "Tokens:\n",
    "[The][ quick][ brown][ fox][ jumps]  [ over][ the][ lazy][ dog][ near]  [ the][ park][.]\n",
    "\n",
    "\n",
    "å—ï¼š\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚ The quick brown fox jumps â”‚ â”‚ over the lazy dog near â”‚ â”‚ the park .   â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "         å— 1                      å— 2                å— 3\n",
    "```\n",
    "\n",
    "**ä¼˜ç‚¹** âœ…   \n",
    "* ä¸ LLM çš„ä¸Šä¸‹æ–‡çª—å£ç²¾ç¡®å¯¹é½ï¼ˆå¦‚ 512ã€1024ã€8192 Tokenï¼‰\n",
    "* æœ€å‡†ç¡®åœ°é¿å… `context_length_exceeded` é”™è¯¯\n",
    "* æ”¯æŒé‡å ï¼Œç¡®ä¿å—ä¹‹é—´ä¿ç•™ä¸Šä¸‹æ–‡\n",
    "\n",
    "**ç¼ºç‚¹** âŒ  \n",
    "* å¯èƒ½åœ¨è¯æˆ–å¥å­ä¸­é—´åˆ‡æ–­ï¼Œé™ä½å¯è¯»æ€§\n",
    "* éœ€è¦ä¸æ¨¡å‹ä½¿ç”¨åŒä¸€åˆ†è¯å™¨\n",
    "* ç›¸æ¯”å­—ç¬¦åˆ‡åˆ†æ›´åŠ å¤æ‚\n",
    "\n",
    "**é€‚ç”¨åœºæ™¯**\n",
    "* éœ€è¦ç²¾ç¡®æ§åˆ¶ Token ç”¨é‡\n",
    "* ä½¿ç”¨ä¸Šä¸‹æ–‡çª—å£è¾ƒç´§çš„æ¨¡å‹\n",
    "* æ„å»ºé¢å‘ç”Ÿäº§çš„ RAG ç³»ç»Ÿ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8221e6-8b5e-4d8c-a24a-0219b3bbb3af",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "token_splitter = TokenTextSplitter(\n",
    "    chunk_size=100,\n",
    "    chunk_overlap=20\n",
    ")\n",
    "eval_splitter(token_splitter, documents, question, ground_truth, \"Token\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6fa659c-6e25-4c2d-82ef-0b71736901ff",
   "metadata": {},
   "source": [
    "### å¥çª—æ³•ï¼ˆSentence Windowï¼‰\n",
    "\n",
    "**å·¥ä½œåŸç†**ï¼š  \n",
    "å­˜å‚¨æ—¶ä¿æŒè¾ƒå°ã€ç²¾ç»†çš„å—ï¼ˆå¦‚å•å¥ï¼‰ï¼Œä½†åœ¨æ£€ç´¢é˜¶æ®µï¼Œä¼šè¿”å›åŒ¹é…å¥å­**ä»¥åŠå‰å N å¥**ï¼ˆå³â€œçª—å£â€ï¼‰ã€‚\n",
    "\n",
    "\n",
    "```\n",
    "åŸå§‹æ–‡æœ¬ï¼š\n",
    "[ S1 ][ S2 ][ S3 ][ S4 ][ S5 ][ S6 ][ S7 ]\n",
    "\n",
    "å­˜å‚¨çš„èŠ‚ç‚¹ï¼ˆwindow_size=2ï¼‰ï¼š\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚ ... S2 S3 [S4] S5 S6 ...     â”‚ â† S4 å¯¹åº”çš„èŠ‚ç‚¹\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "\n",
    "åŒ¹é… S4 â†’ è¿”å›å®Œæ•´çª—å£\n",
    "```\n",
    "\n",
    "âœ… **ä¼˜ç‚¹**\n",
    "- ğŸ“š å³ä½¿ä½¿ç”¨ç»†ç²’åº¦å—ï¼Œä¹Ÿèƒ½æ£€ç´¢åˆ°ä¸°å¯Œä¸Šä¸‹æ–‡\n",
    "- ğŸ¯ æå‡**å›ç­”çœŸå®æ€§**ä¸ä¾æ®æ€§\n",
    "- ğŸ” å…¼é¡¾é«˜ç²¾åº¦æ£€ç´¢ä¸å®Œæ•´è¯­å¢ƒ\n",
    "\n",
    "âŒ **ç¼ºç‚¹**\n",
    "- ğŸ’¾ å¢åŠ å…ƒæ•°æ®å­˜å‚¨å¼€é”€ï¼ˆéœ€è¦ä¿å­˜çª—å£å†…å®¹ï¼‰\n",
    "- â³ ç”±äºåå¤„ç†ï¼Œé€Ÿåº¦ç•¥æ…¢\n",
    "- ğŸ§  éœ€è¦åœ¨æ£€ç´¢åç»„è£…ä¸Šä¸‹æ–‡\n",
    "\n",
    "ğŸ”§ **é€‚ç”¨åœºæ™¯**\n",
    "- å¸Œæœ›æœ€å¤§åŒ–ç­”æ¡ˆæ­£ç¡®æ€§å’Œä¾æ®\n",
    "- ä½¿ç”¨å¥å­çº§åˆ«ç´¢å¼•\n",
    "- åœ¨æ„**æ£€ç´¢è´¨é‡**èƒœè¿‡é€Ÿåº¦"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4968e8fa-ed0a-48b7-9b79-c4e13165e183",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sentence_window_splitter = SentenceWindowNodeParser.from_defaults(\n",
    "    window_size=3,\n",
    "    window_metadata_key=\"window\",\n",
    "    original_text_metadata_key=\"original_text\"\n",
    ")\n",
    "# To visualize sentence window, we need to use \n",
    "query_engine = index.as_query_engine(\n",
    "    similarity_top_k=5,\n",
    "    streaming=True,\n",
    "    node_postprocessors=[MetadataReplacementPostProcessor(target_metadata_key=\"window\")]\n",
    ")\n",
    "eval_splitter(sentence_window_splitter, documents, question, ground_truth, \"Sentence Window\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a5bac3-d1c5-458a-8b68-75d90f4da85b",
   "metadata": {},
   "source": [
    "### è¯­ä¹‰åˆ‡åˆ†\n",
    "\n",
    "**å·¥ä½œåŸç†**ï¼š  \n",
    "åˆ©ç”¨åµŒå…¥æ¨¡å‹æ£€æµ‹æ–‡æœ¬ä¸­çš„**è¯­ä¹‰è½¬æŠ˜**ã€‚åªæœ‰å½“ç›¸é‚»ç‰‡æ®µçš„è¯­ä¹‰ç›¸ä¼¼åº¦æ˜¾è‘—ä¸‹é™æ—¶æ‰åˆ‡åˆ†ã€‚\n",
    "\n",
    "\n",
    "```\n",
    "åŸæ–‡ï¼š\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚ Kitty plays guitar. She loves music.   â–¶ï¸   She works as a lawyer. â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                                         â†‘\n",
    "                         è¯­ä¹‰è½¬æŠ˜ï¼šçˆ±å¥½ â†’ å·¥ä½œ\n",
    "\n",
    "åˆ‡åˆ†åï¼š\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚ Kitty plays guitar. She loves music.  â”‚ â”‚ She works as a lawyer.   â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "âœ… **ä¼˜ç‚¹**\n",
    "- ğŸ§  å°Šé‡è¯­ä¹‰ä¸ä¸»é¢˜è¾¹ç•Œ\n",
    "- ğŸ¯ å°†ç›¸å…³æƒ³æ³•ä¿ç•™åœ¨åŒä¸€å—ä¸­\n",
    "- ğŸ“ˆ å¾€å¾€èƒ½å¸¦æ¥æœ€ä½³æ£€ç´¢è¡¨ç°\n",
    "\n",
    "âŒ **ç¼ºç‚¹**\n",
    "- ğŸ¢ é€Ÿåº¦è¾ƒæ…¢ï¼ˆéœ€è¦è®¡ç®—åµŒå…¥ï¼‰\n",
    "- ğŸ“‰ éœ€è¦è¶³å¤Ÿé•¿çš„æ–‡æœ¬æ‰èƒ½æ£€æµ‹åˆ°è½¬æŠ˜ï¼ˆçŸ­æ–‡å¯èƒ½æ— æ•ˆï¼‰\n",
    "- ğŸ§° ä¾èµ–é«˜è´¨é‡åµŒå…¥æ¨¡å‹\n",
    "\n",
    "ğŸ”§ **é€‚ç”¨åœºæ™¯**\n",
    "- å¤„ç†å¤æ‚ã€è·¨ä¸»é¢˜çš„æ–‡æ¡£\n",
    "- æ ‡å‡†åˆ†å—æ–¹å¼ä¼šæ‰“ç¢é€»è¾‘å•å…ƒæ—¶\n",
    "- æ›´æ³¨é‡**è´¨é‡**è€Œéé€Ÿåº¦"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2685ab-d202-44e1-9760-b0d261714ef1",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "semantic_splitter = SemanticSplitterNodeParser(\n",
    "    buffer_size=1,\n",
    "    breakpoint_percentile_threshold=95,\n",
    "    embed_model=Settings.embed_model\n",
    ")\n",
    "eval_splitter(semantic_splitter, documents, question, ground_truth, \"Semantic\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00fc64f-1072-47d8-a3fc-0368af2c2e98",
   "metadata": {},
   "source": [
    "### Markdown åˆ‡åˆ†\n",
    "\n",
    "**å·¥ä½œåŸç†**ï¼š  \n",
    "æŒ‰ç…§ Markdown çš„ç»“æ„å…ƒç´ ï¼ˆ`# æ ‡é¢˜`ã€`- åˆ—è¡¨`ã€``` ä»£ç å— ```ï¼‰è§£ææ–‡æ¡£ã€‚ä¿ç•™æ¯ä¸ªæ ‡é¢˜ä¸‹çš„å†…å®¹ï¼Œç»´æŒæ–‡æ¡£å±‚çº§ã€‚ä¾‹å¦‚ï¼š\n",
    "\n",
    "\n",
    "```markdown\n",
    "# Project Overview\n",
    "\n",
    "## Tasks\n",
    "- Finalize Q3 OKRs by Friday\n",
    "- Review team feedback\n",
    "- Schedule retro\n",
    "\n",
    "## Notes\n",
    "Meeting was productive.\n",
    "Next steps: improve docs.\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "âœ… **ä¼˜ç‚¹**\n",
    "- ğŸ—ï¸ ä¿ç•™æ–‡æ¡£ç»“æ„ï¼ˆç« èŠ‚ä¸å­ç« èŠ‚ï¼‰\n",
    "- ğŸ“‘ éå¸¸é€‚åˆæŠ€æœ¯æ–‡æ¡£ã€Wikiã€README ç­‰\n",
    "- ğŸ”— ç»´æŒé€»è¾‘å—å†…éƒ¨çš„å®Œæ•´ä¸Šä¸‹æ–‡\n",
    "\n",
    "âŒ **ç¼ºç‚¹**\n",
    "- ğŸš« ä»…é€‚ç”¨äº Markdown æ–‡ä»¶\n",
    "- ğŸ“„ æ ‡é¢˜ä¸‹å†…å®¹è¿‡å¤šæ—¶å¯èƒ½ç”Ÿæˆè¶…å¤§å—\n",
    "- âŒ å¯¹çº¯æ–‡æœ¬æˆ– PDF æ— æ•ˆï¼Œé™¤éå…ˆè½¬æ¢\n",
    "\n",
    "ğŸ”§ **é€‚ç”¨åœºæ™¯**\n",
    "- å¤„ç†æ–‡æ¡£ç«™ç‚¹ï¼ˆå¦‚ GitHubã€Notion å¯¼å‡ºï¼‰\n",
    "- æ•°æ®æ‹¥æœ‰æ˜ç¡®çš„æ ‡é¢˜ä¸ç« èŠ‚\n",
    "- å¸Œæœ›å®ç°**å±‚çº§æ„ŸçŸ¥çš„åˆ†å—**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f91288-5b12-4764-b5c7-8b69f5c4ce89",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "markdown_splitter = MarkdownNodeParser()\n",
    "eval_splitter(markdown_splitter, documents, question, ground_truth, \"Markdown\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b25b7a2-bc3f-44ea-92f4-560b3fc3bbd7",
   "metadata": {},
   "source": [
    "# åµŒå…¥æ¨¡å‹ï¼šä¸º RAG é€‰æ‹©â€œæœç´¢å¤§è„‘â€\n",
    "\n",
    "---\n",
    "\n",
    "æˆ‘ä»¬åœ¨å¼€å¤´å·²ç»çœ‹åˆ°ï¼Œè°ƒæ•´ `similarity_top_k` èƒ½å¸®åŠ© **TaskFriend** çœ‹åˆ°æ›´å¤šä»»åŠ¡ã€‚æ¥ä¸‹æ¥è¯¥é—®ä¸€ä¸ªæ›´æ·±å±‚çš„é—®é¢˜ï¼š* **TaskFriend** æ˜¯å¦‚ä½•çŸ¥é“å“ªäº›ä»»åŠ¡å’Œä½ çš„æŸ¥è¯¢ç›¸ä¼¼çš„ï¼Ÿ*\n",
    "\n",
    "ç­”æ¡ˆå°±åœ¨äº**åµŒå…¥ï¼ˆEmbeddingsï¼‰**â€”â€”å®ƒä»¬æ˜¯é©±åŠ¨ RAG è¯­ä¹‰æœç´¢çš„â€œéšå½¢æŒ‡çº¹â€ã€‚ä½ å¯ä»¥æŠŠåµŒå…¥ç†è§£ä¸ºæ£€ç´¢çš„â€œå¤§è„‘â€ï¼šå®ƒæŠŠå•è¯ã€å¥å­ç”šè‡³æ•´æ®µæ–‡æœ¬è½¬æ¢æˆé«˜ç»´ç©ºé—´ä¸­çš„å‘é‡ï¼Œç”¨è·ç¦»æ¥è¡¡é‡å«ä¹‰ç›¸è¿‘ç¨‹åº¦ã€‚\n",
    "\n",
    "å°±åƒäººç±»ä¼šè§‰å¾— â€œurgentâ€ æ¯” â€œoptionalâ€ æ›´æ¥è¿‘ â€œcriticalâ€ï¼Œä¸€ä¸ªä¼˜ç§€çš„åµŒå…¥æ¨¡å‹ä¼šåœ¨å‘é‡ç©ºé—´ä¸­æŠŠç›¸ä¼¼æ¦‚å¿µæ”¾åœ¨ä¸€èµ·ã€‚ä½†ä¸åŒæ¨¡å‹ä¹‹é—´å·®å¼‚å·¨å¤§ã€‚\n",
    "\n",
    "æœ¬èŠ‚æˆ‘ä»¬å°†æ­å¼€åµŒå…¥çš„ç¥ç§˜é¢çº±ï¼Œä½¿ç”¨ç»å…¸çš„ AI ç±»æ¯”ï¼ˆ`king - man + woman â‰ˆ queen`ï¼‰å±•ç¤ºå®ƒçš„é­”åŠ›ï¼Œå¹¶å‘ä½ è¯´æ˜ä¸ºä»€ä¹ˆé€‰æ‹©åˆé€‚çš„åµŒå…¥æ¨¡å‹å¯ä»¥æ˜¾è‘—æå‡ **TaskFriend** çš„æ£€ç´¢èƒ½åŠ›â€”â€”æ— è®ºç”¨æˆ·å¦‚ä½•è¡¨è¾¾é—®é¢˜ã€‚\n",
    "\n",
    "\n",
    "## ä»€ä¹ˆæ˜¯åµŒå…¥ï¼Ÿ\n",
    "\n",
    "RAG æµæ°´çº¿çš„æ ¸å¿ƒæ€æƒ³éå¸¸ç®€å•ï¼š**æ ¹æ®â€œå«ä¹‰â€è€Œéâ€œå…³é”®è¯â€æ‰¾åˆ°æœ€ç›¸å…³çš„ä¿¡æ¯ã€‚**\n",
    "\n",
    "å¯æ˜¯ï¼Œå¦‚ä½•è®©æœºå™¨ç†è§£â€œå«ä¹‰â€å‘¢ï¼Ÿ\n",
    "\n",
    "ç­”æ¡ˆå°±æ˜¯**åµŒå…¥**â€”â€”æŠŠæ–‡æœ¬è½¬æ¢æˆé«˜ç»´ç©ºé—´ä¸­çš„å‘é‡ï¼ˆé€šå¸¸æ˜¯ 384 åˆ° 1,024 ç»´ï¼‰ã€‚è¿™äº›å‘é‡ç”±åŸºäºæµ·é‡è¯­æ–™è®­ç»ƒçš„æ·±åº¦å­¦ä¹ æ¨¡å‹ç”Ÿæˆï¼Œå› æ­¤èƒ½å¤Ÿæ•æ‰è¯­ä¹‰å…³ç³»ã€‚\n",
    "\n",
    "ä¾‹å¦‚ï¼š\n",
    "* `\"happy\"` ä¸ `\"joyful\"` çš„å‘é‡éå¸¸ç›¸ä¼¼ã€‚\n",
    "* `\"car\"` ä¼šé è¿‘ `\"vehicle\"`ã€‚\n",
    "* `\"apple\"`ï¼ˆæ°´æœï¼‰ä¼šæ¯” `\"iPhone\"` æ›´é è¿‘ `\"banana\"`â€”â€”å‰ææ˜¯æ¨¡å‹ç†è§£è¯­å¢ƒã€‚\n",
    "\n",
    "å½“ä½ é—® **TaskFriend** â€œWhat tasks are due today?â€ï¼Œç³»ç»Ÿå¹¶ä¸æ˜¯åœ¨çŸ¥è¯†åº“ä¸­æœç´¢å­—é¢ä¸Šçš„ â€œtodayâ€ã€‚å®ƒä¼šæŠŠæŸ¥è¯¢è½¬æ¢æˆä¸€ä¸ªå‘é‡ï¼Œå†åœ¨å‘é‡ç©ºé—´ä¸­æŸ¥æ‰¾ä¸ä¹‹**æœ€æ¥è¿‘**çš„æ–‡æœ¬å—ã€‚\n",
    "\n",
    "ğŸ‘‰ å› æ­¤ï¼ŒåµŒå…¥æ¨¡å‹çš„è´¨é‡ç›´æ¥å†³å®šæ£€ç´¢çš„æ™ºèƒ½ç¨‹åº¦ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7391cbf-df38-48b2-bf61-0f61764d9780",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from dashscope import TextEmbedding\n",
    "import os\n",
    "from functions.embedding_viz import compute_analogy_and_similarity, plot_analogy_2d\n",
    "\n",
    "embedding_model='text-embedding-v3'\n",
    "\n",
    "# Create function to get embedding\n",
    "def get_embedding(text, embedding_model):\n",
    "    response = TextEmbedding.call(\n",
    "        model=embedding_model,\n",
    "        input=text,\n",
    "        api_key=os.getenv(\"DASHSCOPE_API_KEY\")\n",
    "    )\n",
    "    if response.status_code == 200:\n",
    "        return np.array(response.output['embeddings'][0]['embedding'])\n",
    "    else:\n",
    "        raise Exception(f\"Embedding failed: {response.message}\")\n",
    "\n",
    "# ğŸ”§ ONLY DEFINE THIS ONCE!\n",
    "# The formula is A - B + C â‰ˆ D\n",
    "analogy = {\n",
    "    \"A\": \"king\",\n",
    "    \"B\": \"man\",\n",
    "    \"C\": \"woman\",\n",
    "    \"D\": \"queen\"\n",
    "}\n",
    "\n",
    "# Extract words and create list for batch processing\n",
    "words = [analogy[\"A\"], analogy[\"B\"], analogy[\"C\"], analogy[\"D\"]]\n",
    "\n",
    "# Get embeddings for all words\n",
    "print(\"ğŸ“¥ Fetching embeddings...\")\n",
    "embeddings = {word: get_embedding(word, 'text-embedding-v3') for word in words}\n",
    "\n",
    "# Compute analogy: A - B + C, compare to D\n",
    "result_vector, similarity = compute_analogy_and_similarity(\n",
    "    embeddings,\n",
    "    a=analogy[\"A\"],\n",
    "    b=analogy[\"B\"],\n",
    "    c=analogy[\"C\"],\n",
    "    target=analogy[\"D\"]\n",
    ")\n",
    "\n",
    "# Print result\n",
    "print(f\"\\nâœ… Cosine similarity between '({analogy['A']} - {analogy['B']} + {analogy['C']})' and '{analogy['D']}': {similarity:.4f}\")\n",
    "\n",
    "# Plot\n",
    "plot_analogy_2d(\n",
    "    embeddings=embeddings,\n",
    "    a=analogy[\"A\"],\n",
    "    b=analogy[\"B\"],\n",
    "    c=analogy[\"C\"],\n",
    "    d=analogy[\"D\"],\n",
    "    result_vector=result_vector,\n",
    "    title=f\"Vector Analogy: {analogy['A']} - {analogy['B']} + {analogy['C']} â‰ˆ {analogy['D']}\\nEvaluated with text-embedding-v3\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec88267-b0ff-4346-871a-8fb628d138b8",
   "metadata": {},
   "source": [
    "**ç†è§£ç»“æœ**\n",
    "\n",
    "è®©æˆ‘ä»¬åˆ†æä¸€ä¸‹å‘é‡ç±»æ¯”å®éªŒçš„ç»“æœï¼š\n",
    "\n",
    "* **æ˜¾è€Œæ˜“è§çš„éƒ¨åˆ†ï¼š**\n",
    "    * ä½™å¼¦ç›¸ä¼¼åº¦ä¸º `0.7855`â€”â€”å±äº**å¼ºç›¸ä¼¼åº¦**ã€‚\n",
    "    * `\"King\"` ä¸ `\"Man\"` çš„è·ç¦»è¾ƒè¿œï¼Œè¯´æ˜æ¨¡å‹åŒºåˆ†äº†ç”·æ€§çš‡å®¤ä¸æ™®é€šç”·æ€§ã€‚\n",
    "    * `\"Woman\"` ä¸ `\"Queen\"` åŒæ ·ä¿æŒä¸€å®šè·ç¦»ï¼Œè¡¨æ˜æ¨¡å‹æ•æ‰åˆ°äº†æ€§åˆ«è§’è‰²ã€‚\n",
    "    * è®¡ç®—å‡ºçš„ç»“æœå‘é‡ï¼ˆ`king - man + woman`ï¼‰è½åœ¨ `\"Queen\"` é™„è¿‘ï¼Œå±•ç°äº†æ¨¡å‹å¯¹ç±»æ¯”çš„ç†è§£èƒ½åŠ›ã€‚\n",
    "\n",
    "ç®€è€Œè¨€ä¹‹ï¼Œä½™å¼¦ç›¸ä¼¼åº¦è¡¡é‡çš„æ˜¯é«˜ç»´ç©ºé—´ä¸­ä¸¤ä¸ªå‘é‡çš„æ–¹å‘ä¸€è‡´ç¨‹åº¦â€”â€”å³é‡åŒ–ä¸¤æ®µæ–‡æœ¬åœ¨è¯­ä¹‰ä¸Šçš„ç›¸å…³æ€§ï¼Œè€Œä¸å—å‘é‡é•¿åº¦å½±å“ã€‚é«˜åˆ†æ„å‘³ç€ä¸¤ä¸ªå‘é‡å‡ ä¹æŒ‡å‘åŒä¸€æ–¹å‘ï¼Œåœ¨ RAG ä¸­å°±è¡¨ç¤ºæ£€ç´¢åˆ°çš„ä¸Šä¸‹æ–‡åœ¨è¯­ä¹‰ä¸Šä¸æŸ¥è¯¢é«˜åº¦ç›¸å…³ï¼Œå³ä½¿å­—é¢ä¸Šå®Œå…¨ä¸åŒã€‚\n",
    "\n",
    "ä¸ºäº†æ–¹ä¾¿å‚è€ƒï¼Œä¸‹é¢æ˜¯ä½™å¼¦ç›¸ä¼¼åº¦çš„ä¸€èˆ¬å‚è€ƒè¡¨ï¼š\n",
    "\n",
    "\n",
    "| ä½™å¼¦ç›¸ä¼¼åº¦ | è§£è¯» | åœ¨ RAG ä¸­çš„å«ä¹‰ |\n",
    "|-------------------|----------------|------------------------|\n",
    "| **> 0.85**        | **éå¸¸é«˜ / è¡¨ç°ä¼˜å¼‚** | æ–‡æœ¬å‡ ä¹ç­‰ä¹‰ï¼Œæˆ–ä»¥ä¸åŒæªè¾è¡¨è¾¾ç›¸åŒæ¦‚å¿µã€‚é€‚åˆé«˜é£é™©åœºæ™¯ï¼ˆå¦‚åŒ»ç–—é—®ç­”ã€æ³•å¾‹æœç´¢ï¼‰ã€‚èƒ½æŒç»­è¾¾åˆ°æ­¤æ°´å¹³çš„æ¨¡å‹å¯è§†ä¸ºé¡¶å°–ã€‚ |\n",
    "| **0.75 â€“ 0.85**   | **é«˜ / å¼ºç›¸å…³** | è¯­ä¹‰å…³è”æ˜æ˜¾ã€‚é€‚é…å¤§å¤šæ•° RAG åœºæ™¯ã€‚è¿™ä¹Ÿæ˜¯å¸¸è§çš„**ç›¸å…³æ€§é˜ˆå€¼**ï¼ˆä¾‹å¦‚è¿‡æ»¤å‡ºç›¸ä¼¼åº¦ >0.8 çš„æ–‡æœ¬å—ï¼‰ã€‚å¯¹é‡Šä¹‰ã€ä¸»é¢˜çº§åŒ¹é…è¡¨ç°è‰¯å¥½ã€‚ |\n",
    "| **0.60 â€“ 0.75**   | **ä¸­ç­‰ / å¯æ¥å—** | å­˜åœ¨ä¸€å®šè¯­ä¹‰é‡å ï¼Œä½†ä¸ç²¾å‡†ã€‚å¯èƒ½æ£€ç´¢åˆ°è¾¹ç¼˜ç›¸å…³å†…å®¹ã€‚é€‚ç”¨äºå¼€æ”¾é¢†åŸŸæ£€ç´¢ï¼Œä½†å™ªéŸ³å¢åŠ ï¼Œéœ€è¦é‡æ’åºæˆ–æ··åˆæœç´¢æå‡ç²¾åº¦ã€‚ |\n",
    "| **0.50 â€“ 0.60**   | **è¾ƒä½ / å¼±ç›¸å…³** | åªæœ‰æœ‰é™çš„å…±æ€§ã€‚å¯èƒ½å…±äº«å…³é”®è¯æˆ–å¤§è‡´è¯é¢˜ï¼Œä½†æ„å›¾æˆ–ç»†èŠ‚ä¸åŒã€‚è¯¯æŠ¥é£é™©è¾ƒé«˜ï¼Œä¸å»ºè®®ä½œä¸ºå•ä¸€æ£€ç´¢é˜ˆå€¼ã€‚ |\n",
    "| **< 0.50**        | **å¯å¿½ç•¥ / ä¸ç›¸å…³** | å‡ ä¹æ²¡æœ‰è¯­ä¹‰è”ç³»ã€‚ä¸¤ä¸ªå‘é‡ä»£è¡¨å®Œå…¨ä¸åŒæ¦‚å¿µã€‚åœ¨ RAG ä¸­åº”å½“è¿‡æ»¤æ‰æ­¤ç±»åŒ¹é…ã€‚ |\n",
    "\n",
    "`0.7855` çš„ç»“æœä»¤äººæ»¡æ„â€”â€”è¯´æ˜ `text-embedding-v3` æ¨¡å‹å¯¹è¯­ä¹‰ç»“æ„æœ‰ä¸é”™çš„æŒæ¡ã€‚ä½†å®ƒå¹¶ä¸å®Œç¾ã€‚åœ¨å®é™… RAG ç³»ç»Ÿä¸­ï¼ŒåµŒå…¥è´¨é‡çš„å¾®å°å·®å¼‚ä¼šåœ¨æ£€ç´¢é˜¶æ®µè¢«æ”¾å¤§ï¼Œå¯èƒ½å¯¼è‡´å…³é”®ä¸Šä¸‹æ–‡ç¼ºå¤±æˆ–äº§ç”Ÿå¹»è§‰ã€‚å› æ­¤ï¼Œé€‰æ‹©åˆé€‚çš„åµŒå…¥æ¨¡å‹ç»ä¸æ˜¯å¾®è°ƒç»†èŠ‚ï¼Œè€Œæ˜¯åœ¨ä¸ºæ£€ç´¢ç³»ç»ŸæŒ‘é€‰â€œå¤§è„‘â€ã€‚æ›´èªæ˜çš„å¤§è„‘æ„å‘³ç€æ›´å‡†ç¡®ã€æ›´å¯é ã€æ›´å¿ å®çš„å›ç­”ã€‚\n",
    "\n",
    "> **åŠ¨æ‰‹è¯•è¯•ï¼**  \n",
    "> å°†ç±»æ¯”ä»£ç æ›¿æ¢ä¸ºä»¥ä¸‹ç¤ºä¾‹ï¼š\n",
    "> ```python\n",
    "> analogy = {\n",
    ">     \"A\": \"Paris\",\n",
    ">     \"B\": \"France\",\n",
    ">     \"C\": \"Italy\",\n",
    ">     \"D\": \"Rome\"\n",
    "> }\n",
    "> ```\n",
    "\n",
    "åœ¨è¿›å…¥ä¸‹ä¸€èŠ‚ä¹‹å‰ï¼Œæˆ‘ä»¬å°†å¿«é€Ÿæ¯”è¾ƒ `text-embedding-v4` ä¸å½“å‰ä½¿ç”¨çš„ `text-embedding-v3` æ¨¡å‹çš„è¡¨ç°ï¼ˆ[æ›´å¤šä¿¡æ¯](https://modelstudio.console.alibabacloud.com/?tab=api#/api/?type=model&url=2712515)ï¼‰ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ac37d2-f0d3-4f31-84d7-97ab4c5d239d",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define sentences to compare (2 sentences)\n",
    "sentences = [\n",
    "    \"Which tasks must be completed today?\",\n",
    "    \"Which tasks need to be completed today?\",\n",
    "]\n",
    "\n",
    "# Models to compare\n",
    "model = [\"text-embedding-v3\", \"text-embedding-v4\"]\n",
    "\n",
    "# Store results: model -> similarity score\n",
    "results = {}\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "print(\"Comparing sentences:\")\n",
    "print(f\"{sentences}\")\n",
    "print(\"=\" * 50 + \"\\n\")\n",
    "\n",
    "# Evaluate each model\n",
    "for model in model:\n",
    "    try:\n",
    "        print(f\"ğŸ§  Testing {model} on sentence similarity...\")\n",
    "        \n",
    "        # Get embeddings for both sentences\n",
    "        emb1 = get_embedding(sentences[0], embedding_model=model)\n",
    "        emb2 = get_embedding(sentences[1], embedding_model=model)\n",
    "        \n",
    "        # Reshape for sklearn\n",
    "        emb1 = emb1.reshape(1, -1)\n",
    "        emb2 = emb2.reshape(1, -1)\n",
    "        \n",
    "        # Compute cosine similarity\n",
    "        sim = cosine_similarity(emb1, emb2)[0][0]\n",
    "        print(f\"âœ… Similarity between sentences: {sim:.4f}\\n\")\n",
    "        results[model] = sim\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error with {model}: {e}\\n\")\n",
    "        results[model] = None\n",
    "\n",
    "# ğŸ“Š Final Comparison\n",
    "print(\"\\nğŸ“Š SENTENCE SIMILARITY COMPARISON\")\n",
    "print(\"-\" * 50)\n",
    "for model, sim in results.items():\n",
    "    status = f\"{sim:.4f}\" if sim is not None else \"Failed\"\n",
    "    print(f\"{model:>20} : {status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75854b3-39f4-4057-9df9-05abf548fe8f",
   "metadata": {},
   "source": [
    "åœ¨è¯„ä¼°åµŒå…¥æ¨¡å‹æ—¶ï¼Œä½™å¼¦ç›¸ä¼¼åº¦æ˜¯ä¸€ä¸ª**å®ç”¨ä½†ä¸ç»å¯¹**çš„è¯Šæ–­æŒ‡æ ‡ã€‚ä»¥ç¤ºä¾‹ä¸­çš„å‡ ä¹ç›¸åŒçš„å¥å­å¯¹ä¸ºä¾‹ï¼š\n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <th>å¥å­å¯¹</th>\n",
    "    <th>åµŒå…¥æ¨¡å‹</th>\n",
    "    <th>åˆ†æ•°</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td rowspan=\"2\">\n",
    "      <ul>\n",
    "        <li>Which tasks must be completed today?</li>\n",
    "        <li>Which tasks need to be completed today?</li>\n",
    "      </ul>\n",
    "    </td>\n",
    "    <td>text-embedding-v3</td>\n",
    "    <td>0.9935</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>text-embedding-v4</td>\n",
    "    <td>0.9766</td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "ä¸¤å¥è¡¨è¾¾åŒä¸€å«ä¹‰ï¼Œä»…åœ¨è¯­æ°”ä¸Šç•¥æœ‰ä¸åŒï¼ˆâ€œmustâ€ çš„è¦æ±‚æ›´å¼ºäº â€œneed toâ€ï¼‰ã€‚ç„¶è€Œ **text-embedding-v3** çš„ç›¸ä¼¼åº¦ä¸º **0.9935**ï¼Œè€Œ **text-embedding-v4** ç»™å‡ºçš„ç»“æœæ˜¯ **0.9765**ã€‚\n",
    "\n",
    "## ä¸ºä»€ä¹ˆé«˜ä¸”ç›¸è¿‘çš„å¾—åˆ†å¾ˆé‡è¦ï¼Ÿ\n",
    "å½“ä¸¤ä¸ªæ¨¡å‹å¯¹åŒä¹‰å¥ç»™å‡º *éå¸¸é«˜* çš„ç›¸ä¼¼åº¦ï¼ˆä¾‹å¦‚ >0.95ï¼‰æ—¶ï¼Œè¯´æ˜å®ƒä»¬éƒ½èƒ½å¤Ÿè¯†åˆ«æ ¸å¿ƒè¯­ä¹‰ç­‰ä»·â€”â€”è¿™å¯¹æŸ¥è¯¢æ”¹å†™ã€FAQ åŒ¹é…æˆ–å»é‡ç­‰åœºæ™¯è‡³å…³é‡è¦ã€‚ç±»ä¼¼ 0.9935 çš„å¾—åˆ†æ„å‘³ç€æ¨¡å‹å‡ ä¹æŠŠä¸¤å¥è¯è§†ä¸ºå¯ä»¥äº’æ¢ï¼Œè¿™åœ¨ä½ éœ€è¦ä¼˜å…ˆä¿è¯å¬å›ç‡ï¼ˆç¡®ä¿ä¸é”™è¿‡ä»»ä½•ç›¸å…³ç»“æœï¼‰æ—¶éå¸¸ç†æƒ³ã€‚\n",
    "\n",
    "## ä¸ºä»€ä¹ˆé«˜åˆ†ä¹‹é—´çš„ç»†å¾®å·®å¼‚ä¹Ÿå€¼å¾—å…³æ³¨ï¼Ÿ\n",
    "ä» 0.9935 é™åˆ° 0.9765 çœ‹ä¼¼å·®åˆ«ä¸å¤§ï¼Œä½†åœ¨å‘é‡ç©ºé—´ä¸­ï¼Œå³ä¾¿æ˜¯å¾®å°çš„å˜åŒ–ä¹Ÿå¯èƒ½åæ˜ æ¨¡å‹ç¼–ç è¯­è¨€æ–¹å¼çš„å·®å¼‚ã€‚é«˜ç›¸ä¼¼åº¦è¯´æ˜è¯­ä¹‰é«˜åº¦ä¸€è‡´ï¼Œä½†å…·ä½“æ•°å€¼åæ˜ äº†æ¨¡å‹å¯¹â€œé‡Šä¹‰å®¹å¿åº¦â€ä¸â€œè¯­ä¹‰ç²¾åº¦â€çš„å¹³è¡¡ã€‚æœ‰çš„æ¨¡å‹ä¼šæŠŠå‡ ä¹ç›¸åŒçš„è¡¨è¾¾ç´§å¯†èšç±»ï¼ˆåå‘å¬å›ï¼‰ï¼Œè€Œå¦ä¸€äº›æ¨¡å‹ä¼šä¿ç•™æ›´å¤šè·ç¦»æ¥åŒºåˆ†è¯­æ°”ã€æƒ…æ€æˆ–æ„å›¾å·®åˆ«ï¼ˆåå‘ç²¾åº¦ï¼‰ã€‚è¿™å¾ˆå…³é”®ï¼šåœ¨å®¢æœè·¯ç”±ã€åˆè§„å®¡æ ¸ã€åŒ»ç–—è®°å½•ç­‰åœºæ™¯ä¸­ï¼ŒæŠŠ â€œmustâ€ ä¸ â€œshouldâ€ æ··ä¸ºä¸€è°ˆå¯èƒ½é€ æˆä¸¥é‡åæœã€‚å› æ­¤ï¼Œå³ä¾¿æ˜¯ç»†å¾®çš„åˆ†æ•°å·®å¼‚ï¼Œä¹Ÿèƒ½å¸®åŠ©æˆ‘ä»¬åˆ¤æ–­å“ªä¸ªæ¨¡å‹æ›´ç¬¦åˆå¯¹ç»†èŠ‚æŠŠæ§ä¸æ³›åŒ–èƒ½åŠ›çš„éœ€æ±‚ï¼Œæ˜¯æ¨¡å‹é€‰å‹æ—¶çš„é‡è¦ä¿¡å·ã€‚\n",
    "\n",
    "## è¯­ä¹‰å®Œå…¨ä¸åŒçš„å¥å­\n",
    "\n",
    "å½“æ¯”è¾ƒè¯­ä¹‰æ¯«ä¸ç›¸å…³çš„å¥å­â€”â€”ä¾‹å¦‚ â€œWhich tasks must be completed today?â€ ä¸ â€œParis is the capital of Franceâ€â€”â€”ç†æƒ³çš„åµŒå…¥æ¨¡å‹åº”ç»™å‡ºè¾ƒä½çš„ä½™å¼¦ç›¸ä¼¼åº¦ï¼Œåæ˜ å®ƒä»¬å‡ ä¹æ²¡æœ‰å…±åŒå«ä¹‰ã€‚è®©æˆ‘ä»¬æµ‹è¯•ä¸€ä¸‹ï¼š\n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <th>å¥å­å¯¹</th>\n",
    "    <th>åµŒå…¥æ¨¡å‹</th>\n",
    "    <th>åˆ†æ•°</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td rowspan=\"2\">\n",
    "      <ul>\n",
    "        <li>Which tasks must be completed today?</li>\n",
    "        <li>Paris is the capital of France</li>\n",
    "      </ul>\n",
    "    </td>\n",
    "    <td>text-embedding-v3</td>\n",
    "    <td>0.3322</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>text-embedding-v4</td>\n",
    "    <td>0.0583</td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "è¿™ä¸€å·®å¼‚å‡¸æ˜¾äº†æ¨¡å‹è¡Œä¸ºçš„ä¸€ä¸ªé‡è¦ç»´åº¦ï¼šå®ƒä»¬å¦‚ä½•åœ¨å‘é‡ç©ºé—´ä¸­åˆ†ç¦»æ— å…³æ¦‚å¿µã€‚\n",
    "\n",
    "æ¥è¿‘é›¶çš„ç›¸ä¼¼åº¦ï¼ˆä¾‹å¦‚ **0.0583**ï¼‰è¡¨æ˜æ¨¡å‹èƒ½å°†æ— å…³çš„å¥å­è¿œè¿œåˆ†å¼€ï¼Œè¿™å¯¹è¯­ä¹‰æœç´¢ã€æ„å›¾åˆ†ç±»ã€é‡å¤æ£€æµ‹ç­‰éœ€è¦ç²¾ç¡®åŒºåˆ†çš„ä»»åŠ¡éå¸¸æœ‰åˆ©ã€‚ç›¸åï¼Œè¾ƒé«˜çš„åˆ†æ•°ï¼ˆå¦‚ **0.3322**ï¼‰å¹¶ä¸ä¸€å®šæ„å‘³ç€æ¨¡å‹â€œé”™è¯¯â€ï¼Œå¯èƒ½åªæ˜¯è¯´æ˜å®ƒçš„å‘é‡ç©ºé—´æ•´ä½“æ›´åŠ ç´§å‡‘ï¼Œå³ä¾¿æ˜¯æ— å…³çš„å¥å­ä¹Ÿä¿æŒæŸç§åŸºç¡€çš„å¯¹é½å…³ç³»â€”â€”è¿™å¯èƒ½æºäºè¯­è¨€ç»“æ„çš„ç›¸ä¼¼æ€§ã€é¢†åŸŸåå·®ï¼Œæˆ–è®­ç»ƒç›®æ ‡å¼ºè°ƒäº†å…¶ä»–ç‰¹æ€§ã€‚\n",
    "\n",
    "## å¦‚ä½•é€‰æ‹©åµŒå…¥æ¨¡å‹\n",
    "\n",
    "å…³é”®åœ¨äº**åŒæ—¶è¯„ä¼°â€œé«˜ç›¸ä¼¼â€ä¸â€œä½ç›¸ä¼¼â€ä¸¤ç§è¡¨ç°**ï¼š\n",
    "\n",
    "* é¢å¯¹**è¯­ä¹‰ç›¸è¿‘çš„å¥å­å¯¹**æ—¶ï¼Œä½ å¸Œæœ›å¾—åˆ°é«˜åˆ†ï¼ˆä½†ä¸è¦é«˜åˆ°å¤±å»ç»†å¾®å·®åˆ«ï¼‰ã€‚\n",
    "* é¢å¯¹**è¯­ä¹‰æ— å…³çš„å¥å­å¯¹**æ—¶ï¼Œä½ å¸Œæœ›å¾—åˆ°ä½åˆ†ï¼ˆä½†ä¹Ÿåˆ«ä½åˆ°å®Œå…¨å™ªå£°ï¼‰ã€‚\n",
    "\n",
    "ç†æƒ³çš„æ¨¡å‹ä¼šè®©ç›¸å…³è¯­ä¹‰ç´§å¯†èšåˆï¼ŒåŒæ—¶æ‹‰å¼€ä¸ç›¸å…³è¯­ä¹‰çš„è·ç¦»â€”â€”åœ¨ä½ å…³å¿ƒçš„ä»»åŠ¡ä¸Šåˆ›é€ æ¸…æ™°çš„åŒºéš”ã€‚ä¸å…¶å‡è®¾æŸä¸ªæ¨¡å‹â€œæ™®é€‚æœ€ä½³â€ï¼Œä¸å¦‚ä½¿ç”¨è¦†ç›–ä¸åŒè¯­ä¹‰å…³ç³»çš„ä»£è¡¨æ€§æ•°æ®é›†ï¼Œè¿›è¡Œé’ˆå¯¹æ€§çš„æ¯”è¾ƒï¼Œå†ç»“åˆä½ çš„ä¸šåŠ¡è¯‰æ±‚é€‰æ‹©ã€‚\n",
    "\n",
    "\n",
    "**å»¶ä¼¸é˜…è¯»ï¼š**\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "  <img src=\"images/LMP-C01_06-MTEB_leaderboard.jpg\" style=\"max-width: 800px;\" />\n",
    "  <br>\n",
    "  <small><a href=\"https://huggingface.co/spaces/mteb/leaderboard\" target=\"_blank\">Huggingface ä¸Šçš„ Massive Text Embedding Benchmark</a></small>\n",
    "</div>\n",
    "\n",
    "* [Massive Text Embedding Benchmark](https://huggingface.co/spaces/mteb/leaderboard) å¯ä»¥å¸®åŠ©ä½ åŠæ—¶äº†è§£åµŒå…¥æ¨¡å‹çš„æœ€æ–°è¿›å±•ã€‚\n",
    "* äº†è§£æ›´å¤š [Qwen3 ç³»åˆ—åµŒå…¥ä¸é‡æ’åºæ¨¡å‹](https://qwen.ai/blog?id=888d803985bfb14e4b49df6f926ef9ba05349383&from=research.research-list)ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b343f3-f3b7-4d55-b4bd-1cbb2e48183b",
   "metadata": {},
   "source": [
    "# å¬å›ä¹‹æˆ˜ï¼šåœ¨æµ·é‡æ–‡æœ¬å—ä¸­æ‰¾åˆ°æ­£ç¡®ç­”æ¡ˆ\n",
    "\n",
    "---\n",
    "\n",
    "ä¹ä¸€çœ‹ï¼Œæ£€ç´¢ä¼¼ä¹åªæ˜¯ RAG æµæ°´çº¿ä¸­çš„å®‰é™â€œä¸­é—´ä»¶â€â€”â€”ä¸è¿‡æ˜¯ä¸€æ®µç®€å•çš„â€œæœç´¢â€æµç¨‹ã€‚ä½†å®é™…ä¸Šï¼Œæ£€ç´¢æ˜¯æˆè´¥å…³é”®ã€‚ä¸ç®¡æ•°æ®å¤šå¹²å‡€ã€LLM å¤šå¼ºå¤§ï¼Œå¦‚æœç³»ç»Ÿæ‹¿ä¸åˆ°æ­£ç¡®ä¸Šä¸‹æ–‡ï¼Œç­”æ¡ˆå°±ä¸€å®šé”™è¯¯ã€‚\n",
    "\n",
    "åœ¨ç†æƒ³æƒ…å†µä¸‹ï¼Œç”¨æˆ·æ€»æ¸…æ¥šè‡ªå·±æƒ³è¦ä»€ä¹ˆï¼›å¯éšç€ AI è¶Šæ¥è¶Šåƒæˆ‘ä»¬çš„å‰¯é©¾æˆ–ç¬¬äºŒå¤§è„‘ï¼Œé—®é¢˜å°±å˜äº†ã€‚å¾ˆå¿«ï¼Œç”¨æˆ·çš„æé—®ä¼šä»\n",
    "\n",
    "> *\"What urgent tasks are due today?\"*ï¼ˆâ€œä»Šå¤©æœ‰å“ªäº›ç´§æ€¥ä»»åŠ¡åˆ°æœŸï¼Ÿâ€ï¼‰  \n",
    "è½¬å˜ä¸º  \n",
    "> *â€œIâ€™m stuck â€” what should I do next?â€*ï¼ˆâ€œæˆ‘å¡ä½äº†â€”â€”æ¥ä¸‹æ¥è¯¥æ€ä¹ˆåŠï¼Ÿâ€ï¼‰\n",
    "\n",
    "è¿™ä¸ä»…æ˜¯æœç´¢è¯·æ±‚ï¼Œæ›´æ˜¯ä¸€ä¸ªäººåœ¨å¯»æ±‚çœŸå®çš„å»ºè®®ã€‚\n",
    "\n",
    "åœ¨ç°å®åœºæ™¯ä¸­ï¼Œå›ç­”è¿™äº›é—®é¢˜æ‰€éœ€çš„çŸ¥è¯†å¾ˆå°‘é›†ä¸­åœ¨å•ä¸ªå®Œç¾åŒ¹é…çš„æ–‡æœ¬å—é‡Œã€‚å®ƒæ•£è½åœ¨æŒ‡å¯¼æ‰‹å†Œã€æœ€ä½³å®è·µã€æµç¨‹æ¡†æ¶ä¸­ã€‚æ¨¡å‹åªèƒ½çœ‹åˆ°ä½ æä¾›çš„ä¸Šä¸‹æ–‡â€”â€”å¦‚æœè¿™äº›ä¸Šä¸‹æ–‡ä¸å®Œæ•´æˆ–å™ªå£°å¤ªå¤§ï¼Œå°±éš¾å…å‡ºç°å¹»è§‰ã€‚\n",
    "\n",
    "**é‚£æˆ‘ä»¬è¯¥æ€ä¹ˆå¼¥è¡¥è¿™ä¸€å·®è·ï¼Ÿ**\n",
    "\n",
    "è¦åšçš„æ˜¯æŠŠæ£€ç´¢ä»â€œæŸ¥è¯¢â†’ç»“æœâ€çš„å•æ­¥åŠ¨ä½œå‡çº§ä¸ºä¸€å¥—æœ‰ç­–ç•¥çš„æ¨ç†æµç¨‹â€”â€”åœ¨åˆå§‹æœç´¢çš„å‰åéƒ½å¯ä»¥åšä¼˜åŒ–ã€‚æœ¬èŠ‚æˆ‘ä»¬å°†ä»‹ç»ä¸‰ç§é«˜å½±å“åŠ›çš„æŠ€å·§ï¼ŒæŠŠæ£€ç´¢å‡çº§ä¸ºç¨³å¥ã€æ™ºèƒ½çš„ç»„ä»¶ï¼š\n",
    "\n",
    "1. **æŸ¥è¯¢æ”¹å†™**ï¼šå¸®åŠ©ç³»ç»Ÿç†è§£ç”¨æˆ·â€œçœŸæ­£çš„æ„å›¾â€ã€‚  \n",
    "2. **å…ƒæ•°æ®æ ‡ç­¾**ï¼šç”¨ç»“æ„åŒ–æ ‡ç­¾é©¯æœæ··ä¹±çš„å†…å®¹ã€‚  \n",
    "3. **é‡æ’åº**ï¼šæŠŠæœ€ç›¸å…³çš„ä¸Šä¸‹æ–‡æ”¾åœ¨æœ€å‰é¢â€”â€”å› ä¸ºé¦–é€‰é¡¹å¹¶ä¸æ€»æ˜¯æœ€æœ‰ä»·å€¼çš„ã€‚\n",
    "\n",
    "è®©æˆ‘ä»¬çœ‹çœ‹å¦‚ä½•ä¸º RAG åŠ æŒå¬å›èƒ½åŠ›ï¼Œè®© **TaskFriend** æ›´å¯é ã€‚\n",
    "\n",
    "## æŸ¥è¯¢æ”¹å†™ï¼šç”¨çŸ¥è¯†åº“çš„â€œè¯­è¨€â€æé—®\n",
    "\n",
    "æŸ¥è¯¢æ”¹å†™ä¼šæŠŠç”¨æˆ·æå‡ºçš„è‡ªç„¶è¯­è¨€é—®é¢˜è½¬åŒ–ä¸ºæ›´ç²¾å‡†ã€é€‚åˆæ£€ç´¢çš„ç‰ˆæœ¬ã€‚æœ¬èŠ‚æˆ‘ä»¬å°†æ¢ç´¢ä¸‰ç§å¸¸è§çš„æ”¹å†™ç­–ç•¥ï¼š\n",
    "\n",
    "* **LLM æ”¹å†™ï¼š** ç”¨ LLM å°†ç”¨æˆ·é—®é¢˜æ”¹å†™æˆé€‚åˆæ£€ç´¢çš„ç²¾å‡†æè¿°ã€‚\n",
    "* **å¤šæ­¥æŸ¥è¯¢ï¼š** å°†å¤æ‚é—®é¢˜æ‹†è§£æˆå¤šä¸ªå­é—®é¢˜ï¼Œé€æ­¥æ£€ç´¢ï¼Œå†ç»¼åˆç­”æ¡ˆã€‚\n",
    "* **HyDE æ”¹å†™ï¼š** å…ˆç”Ÿæˆä¸€ä¸ªå‡æƒ³ç­”æ¡ˆï¼Œå†æŠŠå®ƒå½“ä½œæœç´¢æŸ¥è¯¢ï¼Œé€‚ç”¨äºæƒ…ç»ªåŒ–æˆ–æ¨¡ç³Šé—®é¢˜ã€‚\n",
    "\n",
    "åœ¨åŠ¨æ‰‹ä¹‹å‰ï¼Œæˆ‘ä»¬å…ˆå†™ä¸€ä¸ªå‡½æ•°æ¥æ¯”è¾ƒä¸åŒç­–ç•¥çš„æ•ˆæœï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e32643-79eb-4fc1-8a9d-ff2c629957bd",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index.core.prompts import PromptTemplate\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "\n",
    "def eval_query_strategy(\n",
    "    strategy_fn,\n",
    "    strategy_name,\n",
    "    index,\n",
    "    test_cases,\n",
    "    ragas_llm,\n",
    "    ragas_embeddings,\n",
    "    node_count\n",
    "):\n",
    "  \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"ğŸ” EVALUATING: {strategy_name}\")\n",
    "    print(f\"{'='*70}\")\n",
    "\n",
    "    # Detect if strategy returns a query engine (e.g., Multi-Step, HyDE)\n",
    "    test_query = test_cases[0][\"question\"]\n",
    "    result = strategy_fn(test_query)\n",
    "\n",
    "    # âœ… Log original query for ALL strategies\n",
    "    print(f\"Original query â†’ '{test_query}'\")\n",
    "\n",
    "    if hasattr(result, \"query\"):  # It's a query engine\n",
    "        print(f\"  â†’ Using transformed query engine: {strategy_name}\")\n",
    "        query_engine = result\n",
    "        final_query = test_query\n",
    "    else:  # It's a rewritten query string\n",
    "        final_query = result\n",
    "        print(f\"Rewritten query â†’ '{final_query}'\")\n",
    "        query_engine = index.as_query_engine(\n",
    "            similarity_top_k=3,\n",
    "            llm=Settings.llm,\n",
    "            streaming=False\n",
    "        )\n",
    "        \n",
    "        \n",
    "    # Run test case\n",
    "    try:\n",
    "        response = query_engine.query(final_query)\n",
    "        answer = str(response).strip()\n",
    "        contexts = [node.get_content().strip() for node in response.source_nodes]\n",
    "        source_nodes = response.source_nodes\n",
    "        print(f\"\\nğŸ’¬ ANSWER:\\n{answer}\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error during query: {e}\")\n",
    "        answer = f\"Error: {e}\"\n",
    "        contexts = []\n",
    "        source_nodes = []\n",
    "\n",
    "    # âœ… NEW: Print retrieved contexts\n",
    "    print(f\"\\nğŸ“Œ RETRIEVED CONTEXTS ({len(contexts)} chunks):\")\n",
    "    print(\"â”€\" * 60)\n",
    "    if contexts:\n",
    "        for i, ctx in enumerate(contexts):\n",
    "            print(f\"ğŸ“„ Chunk {i+1} (Length: {len(ctx)} chars)\")\n",
    "            print(f\"   {ctx.strip()}\")\n",
    "            print(f\"{'â”€'*60}\")\n",
    "    else:\n",
    "        print(\"   No contexts retrieved.\")\n",
    "        print(\"â”€\" * 60)\n",
    "\n",
    "    # Prepare for Ragas\n",
    "    dataset = Dataset.from_dict({\n",
    "        \"question\": [test_query],\n",
    "        \"answer\": [answer],\n",
    "        \"contexts\": [contexts],\n",
    "        \"ground_truth\": [test_cases[0][\"ground_truth\"]]\n",
    "    })\n",
    "\n",
    "    # Evaluate with Ragas\n",
    "    print(\"\\nğŸ“Š EVALUATING WITH RAGAS...\")\n",
    "    try:\n",
    "        results = evaluate(\n",
    "            dataset=dataset,\n",
    "            metrics=[\n",
    "                answer_correctness,\n",
    "                context_recall,\n",
    "                context_precision,\n",
    "            ],\n",
    "            llm=ragas_llm,\n",
    "            embeddings=ragas_embeddings\n",
    "        )\n",
    "        results_df = results.to_pandas()\n",
    "        results_df[\"strategy\"] = strategy_name\n",
    "        results_df[\"node_count\"] = node_count\n",
    "        avg_len = int(sum(len(c) for c in contexts) / len(contexts)) if contexts else 0\n",
    "        results_df[\"avg_context_length\"] = avg_len\n",
    "        results_df[\"context_info\"] = f\"{len(contexts)} chunks, {avg_len} avg chars\"\n",
    "\n",
    "        # Clean display\n",
    "        display_df = results_df[[\n",
    "            \"strategy\", \"node_count\", \"context_info\", \"question\", \"answer\",\n",
    "            \"ground_truth\", \"answer_correctness\", \"context_recall\",\n",
    "            \"context_precision\"\n",
    "        ]].copy()\n",
    "        display_df[\"answer\"] = display_df[\"answer\"].apply(lambda x: x[:100] + \"...\" if len(x) > 100 else x)\n",
    "        display_df[\"ground_truth\"] = display_df[\"ground_truth\"].apply(lambda x: x[:100] + \"...\" if len(x) > 100 else x)\n",
    "\n",
    "        print(f\"\\nğŸ“ˆ RESULTS: {strategy_name}\")\n",
    "        display(Markdown(display_df.to_markdown(index=False)))\n",
    "\n",
    "        return {\n",
    "            \"results_df\": results_df,\n",
    "            \"contexts\": contexts,\n",
    "            \"source_nodes\": source_nodes,\n",
    "            \"answer\": answer,\n",
    "            \"final_query\": final_query\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Evaluation failed: {e}\")\n",
    "        return {\n",
    "            \"results_df\": pd.DataFrame({\"strategy\": [strategy_name], \"error\": [str(e)]}),\n",
    "            \"contexts\": [],\n",
    "            \"source_nodes\": [],\n",
    "            \"answer\": \"\",\n",
    "            \"final_query\": final_query\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e54352-272b-42ff-8500-aaae790ed162",
   "metadata": {},
   "source": [
    "### æ”¹å†™ä½ çš„é—®é¢˜ï¼šLLM é‡å†™\n",
    "\n",
    "è¿™æ˜¯æœ€å®¹æ˜“å®ç°çš„æ–¹æ³•ä¹‹ä¸€â€”â€”æŠŠåŸå§‹æŸ¥è¯¢äº¤ç»™ LLMï¼Œè®©å®ƒé‡å†™å‡ºæ›´é€‚åˆæ£€ç´¢çš„é—®å¥ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64376996-772a-44ec-82ee-8cb166de59a2",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Strategy 0: No rewriting\n",
    "def no_rewrite(query):\n",
    "    return query\n",
    "\n",
    "# Strategy 1: LLM-based rewriting\n",
    "rewrite_prompt = PromptTemplate(\"\"\"\n",
    "You are a compassionate task assistant. When users express overwhelm, paralysis, or lack of progress, \n",
    "your goal is to **rewrite their natural-language question into a precise retrieval query** that will help the system return:\n",
    "- Evidence-based strategies for regaining focus and reducing overwhelm, AND\n",
    "- The user's actual high-priority tasks that are due soon (especially today).\n",
    "\n",
    "### Rules\n",
    "1. Preserve the emotional contextâ€”donâ€™t make it sound robotic.\n",
    "2. Explicitly ask for both \"advice\" and \"tasks due today\" when the user is stuck or overwhelmed.\n",
    "3. Use natural phrasing like â€œWhat should I do whenâ€¦?â€ or â€œHow can Iâ€¦ and what tasks are dueâ€¦?â€\n",
    "4. NEVER generate an answerâ€”only output the rewritten query.\n",
    "5. Output ONLY the rewritten queryâ€”no prefixes, no markdown, no explanations.\n",
    "\n",
    "### Examples\n",
    "Original: \"I'm swamped and don't know where to start\"\n",
    "Rewritten: What practical steps help when overwhelmed, and what high-priority tasks are due today?\n",
    "\n",
    "Original: \"Nothing's getting done\"\n",
    "Rewritten: How can I break through mental paralysis and see my tasks due today with high priority?\n",
    "\n",
    "Original: \"I feel frozenâ€”like I can't move forward\"\n",
    "Rewritten: What techniques help regain momentum when stuck, and what tasks are due today that I should focus on?\n",
    "\n",
    "---\n",
    "Original question: {query_str}\n",
    "Rewritten query:\n",
    "\"\"\")\n",
    "\n",
    "def llm_rewrite(query):\n",
    "    response = Settings.llm.complete(rewrite_prompt.format(query_str=query))\n",
    "    return str(response.text).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c860e2-6a2a-4f2f-aec0-8d544a4a53cb",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "documents = SimpleDirectoryReader(\n",
    "    \"./docs/taskfriend\",\n",
    "    required_exts=[\".md\"],\n",
    "    recursive=True\n",
    ").load_data()\n",
    "\n",
    "print(f\"âœ… Loaded {len(documents)} documents\")\n",
    "\n",
    "splitter = SentenceSplitter(chunk_size=512, chunk_overlap=64)\n",
    "nodes = splitter.get_nodes_from_documents(documents)\n",
    "index = VectorStoreIndex(nodes, embed_model=Settings.embed_model)\n",
    "\n",
    "test_cases = [\n",
    "    {\n",
    "        \"question\": \"I can't get anything done today\",\n",
    "        \"ground_truth\": (\n",
    "            \"When you're stuck and nothing seems to move forward, begin by turning on Focus Mode to hide everything except tasks due todayâ€”this clears mental noise. \"\n",
    "            \"Then, choose an Anchor Task: the single most impactful item that, once done, creates momentum and eases stress. \"\n",
    "            \"Look for something high-priority, clearly defined, doable in under an hour, and emotionally relieving. \"\n",
    "            \"If you're frozen, pause for a 2-Minute Reset: close your eyes, take slow breaths, and release tension in your shoulders and jaw. \"\n",
    "            \"Your tasks due today include: Finalize Q3 OKRs by 3pm, Update Project Phoenix roadmap, and Write thank-you letter to penpal in Korea. \"\n",
    "            \"Of these, the Q3 OKRs likely make the strongest Anchor Task because it unblocks team planning and carries deadline urgency.\"\n",
    "        )\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf8fe5b-7d25-4403-b4a6-2a34a95790a4",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "# Initialize list to collect results\n",
    "QUERY_REWRITING_RESULTS = []\n",
    "\n",
    "# Evaluate each strategy\n",
    "strategies = [\n",
    "    (\"No Rewrite\", no_rewrite),\n",
    "    (\"LLM Rewrite\", llm_rewrite),\n",
    "]\n",
    "\n",
    "for name, fn in strategies:\n",
    "    result = eval_query_strategy(\n",
    "        strategy_fn=fn,\n",
    "        strategy_name=name,\n",
    "        index=index,\n",
    "        test_cases=test_cases,\n",
    "        ragas_llm=ragas_llm,\n",
    "        ragas_embeddings=ragas_embeddings,\n",
    "        node_count=len(nodes)\n",
    "    )\n",
    "    QUERY_REWRITING_RESULTS.append(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6f177f-aa53-4505-8d45-c21a604a48d5",
   "metadata": {},
   "source": [
    "æˆ‘ä»¬æ¥å‰–æä¸€ä¸‹ç»“æœã€‚**LLM é‡å†™**ç­–ç•¥æˆåŠŸåœ°æŠŠç”¨æˆ·å«ç³Šçš„æ±‚åŠ©â€”â€”\n",
    "\n",
    "```\n",
    "â€œI canâ€™t get anything done todayâ€\n",
    "```\n",
    "\n",
    "â€”â€”è½¬æ¢æˆäº†åŒæ—¶åŒ…å«æƒ…ç»ªæ”¯æŒä¸ä»»åŠ¡æ•°æ®çš„ç»“æ„åŒ–è¯·æ±‚ã€‚è¿™è®© RAG ç³»ç»Ÿç”Ÿæˆäº†æ›´ä¸°å¯Œã€æ›´ä¸ªæ€§åŒ–çš„å›ç­”ï¼šæ—¢æä¾›äº†å¾ªè¯çš„åº”å¯¹æŠ€å·§ï¼ˆå¦‚ 2 åˆ†é’Ÿé‡ç½®æ³•ã€Anchor Task æ¡†æ¶ï¼‰ï¼Œåˆåˆ—å‡ºäº†ç”¨æˆ·çš„é«˜ä¼˜å…ˆçº§ä»»åŠ¡ï¼ŒæŒ‡å¼•ä»–ä»¬è¿ˆå‡ºå¯æ‰§è¡Œçš„ä¸‹ä¸€æ­¥ã€‚\n",
    "\n",
    "<table>\n",
    "  <thead>\n",
    "      <th style=\"text-align: left; width: 12%;\">ç­–ç•¥</th>\n",
    "      <th style=\"text-align: left; width: 20%;\">æŸ¥è¯¢</th>\n",
    "      <th style=\"text-align: left; width: 58%;\">å›ç­”</th>\n",
    "      <th style=\"text-align: center; width: 10%;\">answer_correctness<br>å¾—åˆ†</th>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <td>åŸå§‹</td>\n",
    "      <td>\"I can't get anything done today\"<br>ï¼ˆâ€œæˆ‘ä»Šå¤©ä»€ä¹ˆéƒ½åšä¸å®Œâ€ï¼‰</td>\n",
    "      <td>å…ˆå¼€å¯ Focus Modeï¼Œéšè—æ‰€æœ‰éç´§æ€¥ä»»åŠ¡ï¼Œåªä¿ç•™ä»Šå¤©åˆ°æœŸçš„äº‹é¡¹ã€‚ç„¶ååœ¨æ¸…å•ä¸­æ‰¾å‡ºä½ çš„ Anchor Taskï¼šæŒ‘å‡ºé‚£ä¸ªä¸€æ—¦å®Œæˆï¼Œå°±èƒ½è®©ä½™ä¸‹çš„ä¸€å¤©æ›´å¯æ§çš„ä»»åŠ¡ã€‚å…³æ³¨é‚£äº›å½±å“åŠ›é«˜ã€ä¸‹ä¸€æ­¥æ¸…æ™°ã€60 åˆ†é’Ÿå†…å¯å®Œæˆçš„äº‹é¡¹ã€‚å¦‚æœä¾ç„¶å¡ä½ï¼Œç”¨ 2 åˆ†é’Ÿé‡ç½®æ³•ï¼šé—­ä¸Šçœ¼ç›ã€æ·±å‘¼å¸ã€æ”¾æ¾è‚©è†€å¹¶æ¾å¼€ä¸‹é¢Œã€‚è¿™ä¸ªå¿«é€Ÿé‡ç½®å¯ä»¥å¸®åŠ©æ¸…ç†è„‘ä¸­çš„é›¾æ°”ï¼Œæ¢å¤ä¸“æ³¨ã€‚</td>\n",
    "      <td style=\"text-align: center;\">0.734164</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>LLM Rewrite</td>\n",
    "      <td>\"What strategies help when I'm unable to make progress, and what high-priority tasks are due today that I should focus on?\"<br>ï¼ˆâ€œå½“æˆ‘æ— æ³•æ¨è¿›æ—¶ï¼Œæœ‰å“ªäº›ç­–ç•¥èƒ½å¸®æˆ‘æ¢å¤è¿›åº¦ï¼Ÿä»Šå¤©åˆ°æœŸçš„é«˜ä¼˜å…ˆçº§ä»»åŠ¡æœ‰å“ªäº›ï¼Ÿâ€ï¼‰</td>\n",
    "      <td>å½“ä½ æ— æ³•æ¨è¿›æ—¶ï¼Œå…ˆå¼€å¯ â€œFocus Modeâ€ï¼Œéšè—æ‰€æœ‰éç´§æ€¥ä»»åŠ¡ï¼Œåªä¿ç•™æ ‡è®°ä¸º â€œDue Todayâ€ çš„äº‹é¡¹ã€‚è¿™èƒ½ç®€åŒ–è§†é‡ï¼Œå‡å°‘å¿ƒç†è´Ÿæ‹…ã€‚æ¥ç€æ‰¾å‡ºä½ çš„ â€œAnchor Taskâ€â€”â€”å®Œæˆåä¼šè®©æ•´å¤©éƒ½æ›´æœ‰æˆå°±æ„Ÿçš„é‚£ä¸€é¡¹ã€‚é€‰æ‹©å½±å“åŠ›é«˜ã€å®šä¹‰æ¸…æ™°ã€60 åˆ†é’Ÿå†…å¯å®Œæˆã€èƒ½é™ä½æƒ…ç»ªå‹åŠ›çš„ä»»åŠ¡ã€‚å¦‚æœä»ç„¶åƒµä½ï¼Œä½¿ç”¨ 2 åˆ†é’Ÿé‡ç½®æ³•ï¼šé—­ä¸Šçœ¼ç›ã€æ·±å‘¼å¸ã€æ”¾æ¾è‚©è†€å¹¶æ¾å¼€ä¸‹é¢Œï¼Œå¸®åŠ©æ¢å¤å¹³é™ä¸æ¸…æ™°ã€‚<br><br>ä»Šå¤©åˆ°æœŸçš„é«˜ä¼˜å…ˆçº§ä»»åŠ¡åŒ…æ‹¬ï¼š<br>- Finalize Q3 OKRs by 3pmï¼ˆä¸‹åˆ 3 ç‚¹å‰å®Œæˆ Q3 OKRï¼‰<br>- Update Project Phoenix roadmapï¼ˆæ›´æ–° Project Phoenix è·¯çº¿å›¾ï¼‰<br>- Write thank-you letter to penpal in Koreaï¼ˆç»™éŸ©å›½ç¬”å‹å†™æ„Ÿè°¢ä¿¡ï¼‰<br><br>åœ¨è¿™äº›ä»»åŠ¡ä¸­ï¼Œä¼˜å…ˆè€ƒè™‘æœ€é€‚åˆä½œä¸º Anchor Task çš„é‚£ä¸€é¡¹â€”â€”é€šå¸¸æ˜¯èƒ½è§£é”å…¶ä»–å·¥ä½œï¼Œæˆ–å®Œæˆåèƒ½æœ€å¤§ç¨‹åº¦å‡è½»å‹åŠ›çš„ä»»åŠ¡ã€‚</td>\n",
    "      <td style=\"text-align: center;\">0.826623</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "\n",
    "æœ€ç»ˆï¼Œ`answer_correctness` ä» **0.7341** æå‡åˆ° **0.8266**ï¼Œè¯´æ˜åˆç†çš„æŸ¥è¯¢é‡å†™èƒ½æ˜¾è‘—æé«˜å›ç­”è´¨é‡ã€‚\n",
    "\n",
    "ä¸è¿‡è¦æ³¨æ„ï¼Œ`answer_correctness` æŒ‡æ ‡é«˜åº¦ä¾èµ–ä½ çš„ ground truthâ€”â€”æˆ‘ä»¬åœ¨åšçš„è°ƒä¼˜ï¼Œå®è´¨ä¸Šæ˜¯åœ¨è®©æ¨¡å‹å‘ä½ æƒ³è¦çš„è¡Œä¸ºé æ‹¢ã€‚åœ¨çœŸå®åº”ç”¨ä¸­ï¼Œä½ éœ€è¦ä¸ç”¨æˆ·æˆ–ç›®æ ‡å—ä¼—å¯†åˆ‡åä½œï¼Œæ˜ç¡®â€œå¥½ç­”æ¡ˆâ€çš„å®šä¹‰ï¼Œç¡®ä¿è¯„ä¼°æ ‡å‡†ç¬¦åˆçœŸå®éœ€æ±‚ï¼Œè€Œä¸æ˜¯å†…éƒ¨å‡è®¾ã€‚\n",
    "\n",
    "### æ‹†è§£é—®é¢˜ï¼šå¤šæ­¥æŸ¥è¯¢åˆ†è§£\n",
    "\n",
    "å½“ç”¨æˆ·é—® â€œWhat tasks are due today?â€ è¿™ç±»ç®€å•é—®é¢˜æ—¶ï¼Œå•æ¬¡å‘é‡æœç´¢å°±è¶³å¤Ÿã€‚ä½†ç°å®ä¸­çš„é—®é¢˜å¾ˆå°‘è¿™ä¹ˆå•çº¯ã€‚\n",
    "\n",
    "æƒ³è±¡ç”¨æˆ·é—´æ¥åœ°æ±‚åŠ©ï¼š\n",
    "\n",
    "> \"I can't get anything done today.\"ï¼ˆâ€œæˆ‘ä»Šå¤©å®Œå…¨æ²¡çŠ¶æ€â€ï¼‰\n",
    "\n",
    "è¿™å¹¶ä¸æ˜¯ä¸€ä¸ªå•ä¸€é—®é¢˜ï¼Œè€Œæ˜¯ä¸€ä¸ªå¤æ‚çš„å¿ƒç†çŠ¶æ€ã€‚è¦ä¼˜é›…åœ°å›ç­”ï¼Œéœ€è¦ç³»ç»Ÿï¼š\n",
    "\n",
    "* ä»â€œè¢«å›°ä½â€â€œä¸çŸ¥æ‰€æªâ€ç­‰æƒ…ç»ªä¿¡å·ä¸­æå–å®é™…éœ€æ±‚\n",
    "* æ‰¾åˆ°å½±å“ç”Ÿäº§åŠ›çš„çœŸå®é˜»ç¢\n",
    "* æŸ¥é˜…ç›¸å…³æ¡†æ¶ï¼ˆå¦‚ Focus Modeã€Anchor Taskã€2-Minute Resetï¼‰\n",
    "* ç”Ÿæˆæ—¢å®ç”¨åˆå¯æ‰§è¡Œçš„å›ç­”\n",
    "\n",
    "è¿™æ­£æ˜¯**å¤šæ­¥æŸ¥è¯¢åˆ†è§£**çš„ç”¨æ­¦ä¹‹åœ°ã€‚\n",
    "\n",
    "ä¸å…¶æŠŠæ£€ç´¢è§†ä½œä¸€æ¬¡æ€§æœç´¢ï¼Œä¸å¦‚æŠŠå®ƒå½“ä½œç»“æ„åŒ–æ¨ç†æµç¨‹ã€‚è¯¥æ–¹æ³•ä¼šæŠŠå«ä¹‰æ¨¡ç³Šçš„é«˜çº§é—®é¢˜æ‹†è§£æˆä¸€ç³»åˆ—æ›´å°ã€æ›´æ˜“æ£€ç´¢çš„å­é—®é¢˜ï¼Œæ¯ä¸ªå­é—®é¢˜éƒ½é’ˆå¯¹çŸ¥è¯†åº“ä¸­çš„ç‰¹å®šä¿¡æ¯ã€‚\n",
    "\n",
    "ä¾‹å¦‚ï¼Œé¢å¯¹ä¸Šè¿°é—®é¢˜ï¼Œç³»ç»Ÿå¯èƒ½ç”Ÿæˆï¼š\n",
    "\n",
    "> _\"What are some tips to help complete tasks when feeling unproductive?\"_ï¼ˆâ€œæ•ˆç‡ä½ä¸‹æ—¶æœ‰å“ªäº›å®Œæˆä»»åŠ¡çš„å°æŠ€å·§ï¼Ÿâ€ï¼‰\n",
    " > _\"What is an 'Anchor Task' and how can it help with productivity?\"_ï¼ˆâ€œä»€ä¹ˆæ˜¯ â€˜Anchor Taskâ€™ï¼Œå¦‚ä½•å¸®åŠ©æå‡äº§å‡ºï¼Ÿâ€ï¼‰\n",
    " > _\"What is the 2-Minute Reset and how can it help when feeling unproductive?\"_ï¼ˆâ€œä»€ä¹ˆæ˜¯ 2 åˆ†é’Ÿé‡ç½®æ³•ï¼Œå®ƒå¦‚ä½•å¸®åŠ©åœ¨æ•ˆç‡ä½æ—¶æ¢å¤çŠ¶æ€ï¼Ÿâ€ï¼‰\n",
    "\n",
    "æ¯ä¸ªå­é—®é¢˜éƒ½ä¼šç‹¬ç«‹æ‰§è¡Œï¼Œæ£€ç´¢åˆ°èšç„¦çš„ä¸Šä¸‹æ–‡ï¼Œæœ€åç³»ç»Ÿä¼šæŠŠè¿™äº›ç»“æœæ±‡æ€»ï¼Œç”Ÿæˆæœ€ç»ˆç­”æ¡ˆï¼Œè€Œä¸æ˜¯ä¾èµ–å•æ¬¡ `top-k` æœç´¢ã€‚\n",
    "\n",
    "è¿™æ˜¯ä¸€ä¸ªéå¸¸å¥½çš„â€œåˆ†è§£â€ä¾‹å­ï¼Œå› ä¸ºå®ƒé¢å¯¹çœŸå®é—®é¢˜ï¼Œä»ç”¨æˆ·è§’åº¦ä½œç­”ã€‚è¿™å¯¹ LLM æœ‰æ•ˆæ˜¯å› ä¸ºï¼š\n",
    "\n",
    "* **åº”å¯¹å¤æ‚é—®é¢˜ï¼š** çœŸå®éœ€æ±‚å¾ˆå°‘æ˜¯åŸå­åŒ–çš„ã€‚åˆ†è§£æ¨¡ä»¿äº†äººç±»é€æ­¥è§£å†³é—®é¢˜çš„æ–¹å¼ã€‚\n",
    "* **æå‡å¬å›ï¼š** é€šè¿‡ä»å¤šä¸ªè§’åº¦æ¢ç´¢é—®é¢˜ï¼Œå‡å°‘æ¼æ‰å…³é”®ä¿¡æ¯çš„é£é™©ã€‚\n",
    "* **å¢å¼ºç²¾åº¦ï¼š** æ¯ä¸ªå­é—®é¢˜éƒ½é’ˆå¯¹å…·ä½“çš„çŸ¥è¯†ç‚¹ï¼Œæœ€ç»ˆç­”æ¡ˆæ›´å…¨é¢ã€‚\n",
    "\n",
    "**å¤šæ­¥æŸ¥è¯¢åˆ†è§£**åœ¨å¦‚ä¸‹åœºæ™¯ååˆ†å¼ºå¤§ï¼š\n",
    "\n",
    "* ç”¨æˆ·æ„å›¾ä¸æ˜ç¡®æˆ–å¤šå±‚ï¼ˆæƒ…ç»ª + å®é™…éœ€æ±‚ï¼‰\n",
    "* ç­”æ¡ˆéœ€è¦æ•´åˆå¤šæ®µçŸ¥è¯†\n",
    "* ç®€å•çš„å…³é”®è¯æˆ–å‘é‡æ£€ç´¢æ— æ³•æ‰¾åˆ°åˆé€‚æŒ‡å¼•\n",
    "* ç”¨æˆ·é€šè¿‡æƒ…ç»ªåŒ–æˆ–æ¨¡ç³Šè¯­è¨€è¡¨è¾¾éœ€æ±‚\n",
    "\n",
    "å®ƒå¹¶ä¸æ˜¯æœ€å¿«çš„æ–¹æ³•ï¼Œä½†å¯¹äºæ„å»ºèƒ½å¤Ÿç†è§£å¹¶è½¬è¯‘ç”¨æˆ·æ„å›¾çš„ AI åŠ©æ‰‹ï¼Œè¿™æ˜¯æœ€ç¨³å¥çš„ç­–ç•¥ä¹‹ä¸€ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58d7e9b-16d8-41ef-b397-210b8fba3aa4",
   "metadata": {
    "ExecutionIndicator": {
     "show": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Strategy 2: Multi-Step Query Decomposition\n",
    "from llama_index.core.indices.query.query_transform.base import StepDecomposeQueryTransform\n",
    "from llama_index.core.query_engine import MultiStepQueryEngine\n",
    "\n",
    "def multistep_rewrite(query):\n",
    "    step_decompose_transform = StepDecomposeQueryTransform(verbose=True)\n",
    "    base_query_engine = index.as_query_engine(\n",
    "        streaming=True,\n",
    "        similarity_top_k=2\n",
    "    )\n",
    "    \n",
    "    multi_step_engine = MultiStepQueryEngine(\n",
    "        query_engine=base_query_engine,\n",
    "        query_transform=step_decompose_transform,\n",
    "        index_summary=\"Task lists and tips to complete tasks\",\n",
    "        num_steps=3,       # How many iterations to break down the query (default: 3)\n",
    "    )\n",
    "    \n",
    "    return multi_step_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33ed0bb-ef95-4ba2-b998-19d3f122959f",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize list to collect results\n",
    "QUERY_REWRITING_RESULTS = []\n",
    "\n",
    "# Evaluate each strategy\n",
    "strategies = [\n",
    "    (\"Multi-Step Decomposition\", multistep_rewrite),\n",
    "]\n",
    "\n",
    "for name, fn in strategies:\n",
    "    result = eval_query_strategy(\n",
    "        strategy_fn=fn,\n",
    "        strategy_name=name,\n",
    "        index=index,\n",
    "        test_cases=test_cases,\n",
    "        ragas_llm=ragas_llm,\n",
    "        ragas_embeddings=ragas_embeddings,\n",
    "        node_count=len(nodes)\n",
    "    )\n",
    "    QUERY_REWRITING_RESULTS.append(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237b20e3-c277-4fab-ad67-96d2f267de87",
   "metadata": {},
   "source": [
    "æˆ‘ä»¬æ¥è§£æç»“æœã€‚**å¤šæ­¥æŸ¥è¯¢åˆ†è§£**ç­–ç•¥æŠŠåŸå§‹é—®é¢˜æ‹†æˆä¸‰ä¸ªå­æŸ¥è¯¢ï¼š\n",
    "\n",
    "```mermaid\n",
    "graph TD\n",
    "    A[\"åŸå§‹æŸ¥è¯¢ï¼šI can't get anything done today\"] --> B[\"StepDecomposeQueryTransform\"]\n",
    "    B --> C\n",
    "    B --> D\n",
    "    B --> E\n",
    "    \n",
    "    subgraph \"å­æŸ¥è¯¢ 1\"\n",
    "        direction TB\n",
    "        C[\"å­æŸ¥è¯¢ 1ï¼šæœ‰å“ªäº›æŠ€å·§èƒ½åº”å¯¹æ•ˆç‡ä½è½çš„æ—¥å­ï¼Ÿ\"]\n",
    "        C --> F[\"æ£€ç´¢ä¸Šä¸‹æ–‡ 1-3\"]\n",
    "        F --> I[\"é—®ç­”å¯¹ 1ï¼šæŠ€å·§ä¸æ–¹æ³•\"]\n",
    "    end\n",
    "    \n",
    "    subgraph \"å­æŸ¥è¯¢ 2\"\n",
    "        direction TB\n",
    "        D[\"å­æŸ¥è¯¢ 2ï¼šä»€ä¹ˆæ˜¯ Anchor Taskï¼Ÿ\"]\n",
    "        D --> G[\"æ£€ç´¢ä¸Šä¸‹æ–‡ 4-6\"] \n",
    "        G --> J[\"é—®ç­”å¯¹ 2ï¼šAnchor Task è¯¦è§£\"]\n",
    "    end\n",
    "\n",
    "    subgraph \"å­æŸ¥è¯¢ 3\"\n",
    "        direction TB\n",
    "        E[\"å­æŸ¥è¯¢ 3ï¼šä»€ä¹ˆæ˜¯ 2 åˆ†é’Ÿé‡ç½®æ³•ï¼Ÿ\"]\n",
    "        E --> H[\"æ£€ç´¢ä¸Šä¸‹æ–‡ 7-9\"]\n",
    "        H --> K[\"é—®ç­”å¯¹ 3ï¼š2 åˆ†é’Ÿé‡ç½®æ³•è¯¦è§£\"]\n",
    "    end\n",
    "\n",
    "    I --> L[\"ç»¼åˆæœ€ç»ˆå›ç­”\"]\n",
    "    J --> L\n",
    "    K --> L\n",
    "    \n",
    "    L --> M[\"æœ€ç»ˆå“åº”ï¼šå…¨é¢çš„æ•ˆç‡æŒ‡å¯¼\"]\n",
    "    \n",
    "    style A fill:#e1f5fe\n",
    "    style L fill:#f3e5f5\n",
    "    style M fill:#e8f5e8\n",
    "```\n",
    "\n",
    "è¿™ä¸ªç­–ç•¥èƒŒåçš„æ€è·¯æ˜¯ï¼šå¤æ‚ã€æƒ…ç»ªåŒ–çš„ç”¨æˆ·é—®é¢˜ï¼Œå¯ä»¥æ‹†è§£æˆæ›´å…·ä½“ã€æ›´æ˜“æ£€ç´¢çš„å­é—®é¢˜ï¼Œä¸çŸ¥è¯†åº“ä¸­çš„ä¿¡æ¯æ›´å¥½åœ°åŒ¹é…ã€‚ç³»ç»Ÿä¸å†è¯•å›¾ç›´æ¥å›ç­”æ¨¡ç³Šé—®é¢˜ï¼Œè€Œæ˜¯è‡ªåŠ¨ç”Ÿæˆå…·ä½“ã€äº‹å®æ€§çš„é—®é¢˜æ¥æ£€ç´¢ç›¸å…³çŸ¥è¯†ã€‚\n",
    "\n",
    "è¿™ç§æ–¹æ³•å¯¹å¤æ‚æˆ–æ¨¡ç³Šé—®é¢˜å°¤å…¶æœ‰æ•ˆï¼Œå› ä¸ºå®ƒç³»ç»Ÿæ€§åœ°æ¢ç´¢é—®é¢˜çš„ä¸åŒä¾§é¢ï¼ˆæœ¬ä¾‹ä¸­åŒ…æ‹¬ä»»åŠ¡ç®¡ç†æŠ€å·§ã€Anchor Task æ–¹æ³•è®ºä»¥åŠç¼“è§£å‹åŠ›çš„å°æŠ€å·§ï¼‰ï¼Œå†æŠŠå®ƒä»¬æ•´åˆæˆå®Œæ•´çš„ç­”æ¡ˆã€‚ä¸åŒäºç®€å•çš„æŸ¥è¯¢é‡å†™ï¼Œ**å¤šæ­¥æŸ¥è¯¢åˆ†è§£**ä¼šåœ¨ä¿æŒåŸå§‹æ„å›¾çš„å‰æä¸‹æ‰©å±•æ£€ç´¢èŒƒå›´ï¼Œç¡®ä¿ä¸ä¼šé”™è¿‡å…³é”®ä¿¡æ¯ï¼Œæœ€ç»ˆå¸¦æ¥æ›´å®Œæ•´ã€å¯æ‰§è¡Œçš„ç­”æ¡ˆã€‚\n",
    "\n",
    "\n",
    "### æƒ³è±¡ä»¥æ£€ç´¢ï¼šHyDEï¼ˆHypothetical Document Embeddingsï¼‰\n",
    "\n",
    "å‡å¦‚æˆ‘ä»¬èƒ½æ£€ç´¢åˆ°â€œå°šæœªå†™å‡ºæ¥çš„ç­”æ¡ˆâ€å‘¢ï¼Ÿ\n",
    "\n",
    "è¿™å°±æ˜¯ **HyDEï¼ˆå‡è®¾æ–‡æ¡£åµŒå…¥ï¼‰** çš„æ€è·¯â€”â€”å®ƒä»æ ¹æœ¬ä¸Šé¢ è¦†äº† RAG æµç¨‹ã€‚HyDE ä¸æ˜¯ä»æŸ¥è¯¢å‡ºå‘ï¼Œè€Œæ˜¯å…ˆç”Ÿæˆä¸€ä¸ªå‡æƒ³ç­”æ¡ˆã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365621fc-8c61-4dad-bd95-49537c320295",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index.core.indices.query.query_transform.base import HyDEQueryTransform\n",
    "from llama_index.core.query_engine import TransformQueryEngine\n",
    "\n",
    "# Strategy 3: HyDE (Hypothetical Document Embeddings)\n",
    "def hyde_rewrite(query):\n",
    "    # Build base engine\n",
    "    base_engine = index.as_query_engine(\n",
    "        similarity_top_k=3,\n",
    "        llm=Settings.llm,\n",
    "        streaming=False\n",
    "    )\n",
    "\n",
    "    hyde_prompt = PromptTemplate(\n",
    "        \"You are a personal productivity coach. \"\n",
    "        \"Generate a detailed, helpful answer to the user's question.\\n\\n\"\n",
    "        \"Question: {context_str}\\n\\n\"\n",
    "        \"Hypothetical Answer:\"\n",
    "    )\n",
    "\n",
    "    hyde = HyDEQueryTransform(\n",
    "        llm=Settings.llm,\n",
    "        include_original=True,\n",
    "        hyde_prompt=hyde_prompt\n",
    "    )\n",
    "\n",
    "    return TransformQueryEngine(\n",
    "        query_engine=base_engine,\n",
    "        query_transform=hyde\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f868c7b5-cc5b-4ff0-8e1c-012922f06b77",
   "metadata": {},
   "source": [
    "#### HyDE çš„å·¥ä½œæ–¹å¼\n",
    "\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "  <img src=\"images/LMP-C01_06-HyDE.gif\" style=\"max-width: 800px;\" />\n",
    "  <br>\n",
    "  <small>HyDE çš„å·¥ä½œæµç¨‹</small>\n",
    "</div>\n",
    "\n",
    "\n",
    "è¿˜è®°å¾—åµŒå…¥ç« èŠ‚é‡Œæˆ‘ä»¬æåˆ°ï¼Œç›¸ä¼¼æ¦‚å¿µä¼šèšé›†åœ¨ç›¸åŒæ–¹å‘å—ï¼Ÿ**HyDE** å¯¹å›ç­”åšäº†åŒæ ·çš„äº‹æƒ…ï¼š\n",
    "\n",
    "1. ç”¨æˆ·è¡¨è¾¾ï¼šâ€œI can't get anything done todayâ€\n",
    "2. LLM ç”Ÿæˆä¸€ç¯‡è¯¦å°½çš„å‡è®¾å›ç­”\n",
    "3. å°†è¿™æ®µå‡è®¾å›ç­”åµŒå…¥å‘é‡ç©ºé—´ï¼Œå¹¶ç”¨å®ƒå»æ£€ç´¢å‘é‡ç´¢å¼•\n",
    "4. è¿”å›ä¸è¿™ä»½â€œç†æƒ³ç­”æ¡ˆâ€æœ€æ¥è¿‘çš„çœŸå®æ–‡æ¡£\n",
    "5. æœ€ç»ˆç­”æ¡ˆåŸºäºè¿™äº›çœŸå®æ–‡æ¡£ç”Ÿæˆ\n",
    "\n",
    "\n",
    "\n",
    "ç®€è€Œè¨€ä¹‹ï¼Œ**HyDE** é€šè¿‡å…ˆæ„é€ ä¸€ä¸ªâ€œç†æƒ³ç­”æ¡ˆâ€ï¼Œå†ä»¥å®ƒä¸ºé”šç‚¹ï¼Œåœ¨çŸ¥è¯†åº“ä¸­å¯»æ‰¾é‡åˆçš„ä¿¡æ¯ï¼Œä»è€Œè·å¾—æ›´ç²¾å‡†çš„å›ç­”ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e16137-4855-478e-a4d3-c7942154062a",
   "metadata": {
    "ExecutionIndicator": {
     "show": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generate hypothetical document\n",
    "print(\"ğŸ§ª TESTING HYDE: Generating hypothetical document...\")\n",
    "hyde = HyDEQueryTransform(\n",
    "    llm=Settings.llm,\n",
    "    hyde_prompt=PromptTemplate(\n",
    "        \"You are a personal productivity coach. \"\n",
    "        \"Generate a detailed, helpful answer to the user's question.\\n\\n\"\n",
    "        \"Question: {context_str}\\n\\n\"\n",
    "        \"Hypothetical Answer:\"\n",
    "    ),\n",
    "    include_original=True\n",
    ")\n",
    "\n",
    "query = test_cases[0][\"question\"]\n",
    "bundle = hyde(query)\n",
    "\n",
    "print(\"\\nğŸ“ HYPOTHETICAL DOCUMENT GENERATED:\")\n",
    "print(\"-\" * 60)\n",
    "print(bundle.embedding_strs[0])\n",
    "print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63d5d78-b411-43ce-85ab-966b02b96184",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize list to collect results\n",
    "QUERY_REWRITING_RESULTS = []\n",
    "\n",
    "# Define all strategies\n",
    "strategies = [\n",
    "    (\"HyDE\", hyde_rewrite),\n",
    "]\n",
    "\n",
    "# Evaluate each\n",
    "for name, fn in strategies:\n",
    "    result = eval_query_strategy(\n",
    "        strategy_fn=fn,\n",
    "        strategy_name=name,\n",
    "        index=index,\n",
    "        test_cases=test_cases,\n",
    "        ragas_llm=ragas_llm,\n",
    "        ragas_embeddings=ragas_embeddings,\n",
    "        node_count=len(nodes)\n",
    "    )\n",
    "    QUERY_REWRITING_RESULTS.append(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52bc740f-aecb-4692-bbc6-f41d15333813",
   "metadata": {},
   "source": [
    "**HyDE** çš„å¦™å¤„åœ¨äºï¼šå®ƒä¸ä¼šå°è¯•åŒ¹é…æ¨¡ç³ŠæŸ¥è¯¢ä¸­çš„å…³é”®è¯ï¼ˆæ¯”å¦‚ â€œI can't get anything done todayâ€ï¼‰ï¼Œè€Œæ˜¯ç›´æ¥ç”Ÿæˆä¸€æ®µä¸°å¯Œã€è¯¦ç»†çš„å‡è®¾ç­”æ¡ˆï¼Œç„¶åç”¨è¿™æ®µç­”æ¡ˆå»æŸ¥æ‰¾è¯­ä¹‰ä¸Šç›¸è¿‘çš„æ–‡æ¡£ã€‚\n",
    "\n",
    "è¿™æ®µå‡è®¾æ–‡æ¡£å°±åƒç”¨æˆ·æ„å›¾ä¸çœŸå®çŸ¥è¯†ä¹‹é—´çš„â€œæ¡¥æ¢â€ã€‚\n",
    "\n",
    "### å°ç»“\n",
    "\n",
    "æˆ‘ä»¬ä»ç”¨æˆ·çš„æ±‚åŠ©å¼€å§‹ï¼š`â€œI can't get anything done todayâ€`  \n",
    "åœ¨æ­¤åŸºç¡€ä¸Šï¼Œæˆ‘ä»¬æ‰“é€ äº†ä¸€ä¸ªèƒ½å¤Ÿæä¾›**è¾…å¯¼ã€æ¸…æ™°åº¦ä¸ä¿¡å¿ƒ**çš„é«˜çº§ RAG ç³»ç»Ÿã€‚\n",
    "\n",
    "å¯¹ä¸‰ç§æŸ¥è¯¢æ”¹å†™ç­–ç•¥çš„è¯„ä¼°æ­ç¤ºäº†ä¸€ä¸ªé‡è¦æ´å¯Ÿï¼š\n",
    "\n",
    "* **LLM Rewrite** é€šè¿‡æŠŠæ„å›¾è½¬æˆç»“æ„åŒ–æŸ¥è¯¢ï¼Œæå‡äº†æ£€ç´¢è´¨é‡ã€‚\n",
    "* **Multi-Step Decomposition** èƒ½å¤Ÿå±•å¼€æ·±å…¥æ¨ç†ï¼Œä½†å¯èƒ½æ£€ç´¢è¿‡å¤šå†…å®¹ã€‚\n",
    "* **HyDE** å…ˆæ„æƒ³â€œç†æƒ³ç­”æ¡ˆâ€ï¼Œå†æŠŠå®ƒæ‰¾å‡ºæ¥ã€‚\n",
    "\n",
    "æ²¡æœ‰å“ªç§ç­–ç•¥èƒ½åœ¨æ‰€æœ‰ç»´åº¦ä¸Šå®Œèƒœã€‚æ­£ç¡®çš„é€‰æ‹©å–å†³äºä½ å¸Œæœ› LLM è¾¾æˆä»€ä¹ˆç›®æ ‡ã€‚\n",
    "\n",
    "## å…ƒæ•°æ®æ ‡ç­¾ï¼šç”¨ç»“æ„åŒ–ä¿¡æ¯é©¯æœæ··ä¹±\n",
    "\n",
    "æˆ‘ä»¬å·²ç»çœ‹åˆ°æŸ¥è¯¢æ”¹å†™å¦‚ä½•å¸®åŠ©ç³»ç»Ÿç†è§£ç”¨æˆ·æ„å›¾ã€‚ä½†å¦‚æœæˆ‘ä»¬èƒ½æ›´è¿›ä¸€æ­¥â€”â€”ä¸ä»…æ”¹è¿›æŸ¥è¯¢ï¼Œè¿˜ä¼˜åŒ–ç´¢å¼•æœ¬èº«å‘¢ï¼Ÿ\n",
    "\n",
    "åœ¨çœŸå®åº”ç”¨ä¸­ï¼ŒçŸ¥è¯†åº“å¾€å¾€éå¸¸æ··ä¹±ï¼Œæ¯”å¦‚åŒ…å«ï¼š\n",
    "\n",
    "* ä»»åŠ¡æè¿°\n",
    "* æ•™ç»ƒæ‰‹å†Œ\n",
    "* ä¼šè®®è®°å½•\n",
    "* ç”¨æˆ·åé¦ˆ\n",
    "* æµç¨‹æ¡†æ¶\n",
    "\n",
    "æ··åœ¨ä¸€èµ·ã€‚\n",
    "\n",
    "å½“ç”¨æˆ·è¯´ `â€œI can't get anything done todayâ€` æ—¶ï¼Œç†æƒ³çš„ç³»ç»Ÿåº”è¯¥ï¼š\n",
    "\n",
    "* è¯†åˆ«è¿™æ˜¯æ•™ç»ƒç±»è¯·æ±‚\n",
    "* ç­›é€‰å‡ºæŒ‡å¯¼æ€§å†…å®¹\n",
    "* ä¼˜å…ˆå–å›æœ€ç›¸å…³çš„æ¡†æ¶\n",
    "\n",
    "å¯è¦æ€ä¹ˆåšåˆ°ï¼Ÿ\n",
    "\n",
    "ç­”æ¡ˆæ˜¯**å…ƒæ•°æ®æ ‡ç­¾ï¼ˆmetadata taggingï¼‰**â€”â€”é€šè¿‡ä¸ºæ–‡æ¡£æ‰“ä¸Šè¯­ä¹‰æ ‡ç­¾ï¼Œä¸ºæ··ä¹±å†…å®¹æ·»åŠ ç»“æ„ã€‚\n",
    "\n",
    "**ä¸ºä»€ä¹ˆè¦æ‰“æ ‡ç­¾ï¼Ÿ**  \n",
    "æƒ³è±¡åœ¨æ²¡æœ‰åˆ†ç±»çš„å›¾ä¹¦é¦†é‡Œæ‰¾ä¹¦ã€‚ä½ è¦ä¸€æœ¬å…³äºæ­£å¿µçš„ä¹¦ï¼Œå›¾ä¹¦ç®¡ç†å‘˜ç»™ä½ ï¼š\n",
    "\n",
    "* ä¸€éƒ¨æå†™å†…å¿ƒå¹³é™è§’è‰²çš„å°è¯´\n",
    "* ä¸€æœ¬ç¥ç»ç§‘å­¦æ•™ç§‘ä¹¦\n",
    "* ä¸€æœ¬ç‘œä¼½æ‰‹å†Œ\n",
    "\n",
    "å®ƒä»¬éƒ½â€œæœ‰ç‚¹ç›¸å…³â€ï¼Œä½†ä¸ä½ çœŸæ­£éœ€æ±‚å·®è·å·¨å¤§ã€‚\n",
    "\n",
    "æ²¡æœ‰å…ƒæ•°æ®ï¼Œä½ çš„ RAG ç³»ç»Ÿå°±æ˜¯è¿™æ ·çš„å›¾ä¹¦ç®¡ç†å‘˜ã€‚\n",
    "\n",
    "ç»™æ–‡æ¡£åŠ ä¸Šç±»ä¼¼ä»¥ä¸‹æ ‡ç­¾ï¼š\n",
    "\n",
    "* `\"topic\": \"being-stuck\"`\n",
    "* `\"framework\": \"5-minute-rule\"`\n",
    "* `\"type\": \"coaching-guide\"`\n",
    "\n",
    "å°±èƒ½è®© RAG æ›´å‡†ç¡®åœ°åŒ¹é…ç”¨æˆ·éœ€æ±‚ï¼Œåœ¨æ£€ç´¢å‰ç¼©å°æœç´¢èŒƒå›´ã€‚\n",
    "\n",
    "è¿™å¯¹ä»¥ä¸‹æƒ…å†µå°¤å…¶æœ‰ä»·å€¼ï¼š\n",
    "\n",
    "* çŸ¥è¯†åº“åºå¤§ä¸”å†…å®¹å¤šæ ·\n",
    "* ç”¨æˆ·æé—®å«ç³Šä¸æ¸…\n",
    "* éœ€è¦æŠŠæŸ¥è¯¢è·¯ç”±åˆ°ç‰¹å®šç±»å‹çš„å†…å®¹\n",
    "\n",
    "### ç”¨ LLM è‡ªåŠ¨æå–æ ‡ç­¾\n",
    "æ‰‹åŠ¨ç»™æµ·é‡æ–‡æ¡£æ‰“æ ‡ç­¾å¹¶ä¸ç°å®ï¼Œä½† LLM å¯ä»¥å¸®ä½ å®Œæˆã€‚\n",
    "\n",
    "å€ŸåŠ©åŸºäº LLM çš„å…ƒæ•°æ®æå–æŠ€æœ¯ï¼Œä½ å¯ä»¥è‡ªåŠ¨åˆ†ææ–‡æ¡£å¹¶ç”Ÿæˆç»“æ„åŒ–æ ‡ç­¾ã€‚\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb65bb39-84f0-4b58-8e09-6af12974a919",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create LLM engine to extract tags\n",
    "system_message = \"\"\"\n",
    "You are a metadata tagging expert for TaskFriend, an AI productivity coach.\n",
    "Analyze the text and extract structured tags that help route user queries to the right guidance.\n",
    "\n",
    "### Supported Tag Types\n",
    "- topic\n",
    "- content_type\n",
    "- audience\n",
    "- task_stage\n",
    "\n",
    "### Output Rules\n",
    "1. Output only a JSON object: {\"tags\": [{\"key\": \"tag_type\", \"value\": \"tag_value\"}]}\n",
    "2. Each tag can have multiple values, store as JSON array in the object\n",
    "3. Do not include tags and values that are not found\n",
    "4. Keep values concise and normalized\n",
    "5. Output only JSON â€” no explanations\n",
    "\n",
    "---\n",
    "Text to analyze:\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def extract_metadata_tags(text):\n",
    "    \"\"\"Extract structured metadata tags from a document.\"\"\"\n",
    "    try:\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"qwen-plus\",  # Fast and cost-effective\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_message},\n",
    "                {\"role\": \"user\", \"content\": text}\n",
    "            ],\n",
    "            response_format={\"type\": \"json_object\"},  # Ensure clean JSON output\n",
    "            temperature=0.2  # Low temperature for consistency\n",
    "        )\n",
    "        return completion.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        return f'{{\"error\": \"{str(e)}\"}}'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a9b7e5-053c-4d27-b2fc-39dfaaf8fe75",
   "metadata": {},
   "source": [
    "æ¥ä¸‹æ¥æˆ‘ä»¬æ ¹æ® `./doc/taskfriend/` ä¸­çš„æ–‡ä»¶æå–ä¸€äº›æ ‡ç­¾ã€‚ä¸ºæ–¹ä¾¿æ¼”ç¤ºï¼Œæˆ‘ä»¬ç›´æ¥å¤åˆ¶ä¸¤ä»½æ–‡ä»¶é‡Œçš„æ–‡æœ¬ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4633df20-61a8-4241-9800-5d00ba9763d1",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Example 1: \"Identifying Anchor Task\"\n",
    "anchor_task_text = \"\"\"\n",
    "# Identifying your \"Anchor Task\"\n",
    "\n",
    "When everything feels urgentâ€”or nothing doesâ€”an **Anchor Task** is your lifeline.  \n",
    "Itâ€™s the *one task* that, when completed, creates momentum, clarity, or relief for the rest of your day.\n",
    "\n",
    "- ğŸ” What makes a good Anchor Task?\n",
    "    - **High impact**: Completing it unlocks progress on other items.\n",
    "    - **Clear next step**: No ambiguityâ€” you know exactly what â€œdoneâ€ looks like.\n",
    "    - **Doable in <60 minutes**: Small enough to finish, big enough to matter.\n",
    "    - **Emotionally resonant**: It reduces anxiety, guilt, or uncertainty.\n",
    "\n",
    "- ğŸ§­ How to find yours\n",
    "    1. **Scan your list** for tasks that:\n",
    "       - Are blocking others (â€œwaiting on meâ€)\n",
    "       - Cause recurring stress when ignored\n",
    "       - Align with your top goal this week\n",
    "    2. **Ask**:  \n",
    "       _â€œIf I only do one thing today, what would make me feel most at peace?â€_\n",
    "    3. **Avoid**:\n",
    "       - â€œAdmin black holesâ€ (e.g., â€œclean inboxâ€)\n",
    "       - Vague intentions (e.g., â€œwork on projectâ€)\n",
    "\n",
    "- ğŸ’¡ Examples\n",
    "    - âœ… *Good*: â€œDraft email to client approving Phase 2â€  \n",
    "      (Unblocks team, <30 mins, reduces deadline anxiety)\n",
    "    - âŒ *Not Anchor*: â€œOrganize all project filesâ€  \n",
    "      (Too big, low urgency, no clear finish)\n",
    "\n",
    "> ğŸŒŸ **Pro Tip**: Your Anchor Task isnâ€™t always the *most urgent*â€”itâ€™s the one that **anchors your sense of control**.\n",
    "\"\"\"\n",
    "\n",
    "print(\"ğŸ“Œ 'Identifying Anchor Task' - Extracted Tags:\")\n",
    "print(extract_metadata_tags(anchor_task_text))\n",
    "\n",
    "\n",
    "# Example 2: \"Managing Overwhelm\"\n",
    "overwhelm_text = \"\"\"\n",
    "# How to Overcome Mental Freeze\n",
    "When your task list feels chaotic or overwhelming, and you don't know where to start:\n",
    "\n",
    "1. Activate \"Focus Mode\"\n",
    "Hide all non-urgent tasks instantly. Only tasks marked â€œDue Todayâ€ remain visible.\n",
    "\n",
    "2. Identify your \"Anchor Task\"\n",
    "Choose ONE task that, if completed, makes the day successful.\n",
    "\n",
    "3. Use the 2-Minute Reset\n",
    "If paralyzed, close your eyes and breathe for 2 minutes. Relax your shoulders and unclench your jaws.\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\nğŸ“Œ 'Managing Overwhelm' - Extracted Tags:\")\n",
    "print(extract_metadata_tags(overwhelm_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce117489-ae08-4e1f-ad84-c736b539499a",
   "metadata": {},
   "source": [
    "è™½ç„¶æµç¨‹ç®€å•ï¼Œå´èƒ½äº§å‡ºå¯¹åº”ç”¨éå¸¸æœ‰ä»·å€¼çš„**æ ‡ç­¾**ã€‚ä¾‹å¦‚ï¼Œå½“ç”¨æˆ·éš¾ä»¥æ‹†è§£ä»»åŠ¡æ—¶ï¼Œæˆ‘ä»¬å¯ä»¥é‡å†™æŸ¥è¯¢ï¼Œè®©å®ƒå¯»æ‰¾å¸¦æœ‰ `\"topic\": \"task-breakdown\"` æ ‡ç­¾çš„æ–‡æœ¬å—ï¼Œå¸®åŠ©åº”ç”¨æ‹¿åˆ°æ›´ç›¸å…³çš„å†…å®¹å¹¶ç”Ÿæˆæ›´ä¼˜ç­”æ¡ˆã€‚\n",
    "\n",
    "è¿™ç§æŠ€æœ¯éå¸¸é€‚åˆä»»ä½•é«˜åº¦ç»“æ„åŒ–æ–‡æ¡£æˆ–æ•°æ®åº“é©±åŠ¨çš„ RAG ç³»ç»Ÿã€‚\n",
    "\n",
    "## é‡æ’åºï¼šæŠŠæœ€ç›¸å…³çš„å†…å®¹æ’åœ¨æœ€å‰\n",
    "\n",
    "ä½ å·²ç»ä¼˜åŒ–äº†åˆ†å—ã€é€‰å¥½äº†åµŒå…¥æ¨¡å‹ã€æ”¹å†™äº†æŸ¥è¯¢ã€æ·»åŠ äº†å…ƒæ•°æ®ï¼Œç”šè‡³æŠŠå¤æ‚é—®é¢˜æ‹†æˆäº†å¤šä¸ªæ­¥éª¤ã€‚\n",
    "\n",
    "ä½†ç°å®æ˜¯ï¼š*å¹¶éæ‰€æœ‰æ£€ç´¢åˆ°çš„æ–‡æœ¬å—éƒ½ä¸€æ ·æœ‰ä»·å€¼ã€‚*\n",
    "\n",
    "å‘é‡ç›¸ä¼¼åº¦æœç´¢èƒ½æ‰¾åˆ°ç›¸å…³å†…å®¹ï¼Œä½†å®ƒæœªå¿…æŠŠæœ€é‡è¦çš„å†…å®¹æ”¾åœ¨æœ€å‰é¢ã€‚\n",
    "\n",
    "**ä¸ºä»€ä¹ˆéœ€è¦é‡æ’åºï¼Ÿ**  \n",
    "é‡æ’åºæ˜¯åˆ©ç”¨æ›´å¼ºçš„å…³è”æ¨¡å‹ï¼ˆé€šå¸¸æ˜¯äº¤å‰ç¼–ç å™¨ï¼‰å¯¹æ£€ç´¢åˆ°çš„æ–‡æœ¬å—é‡æ–°è¯„åˆ†å¹¶æ’åºçš„è¿‡ç¨‹ã€‚\n",
    "\n",
    "ä¸é€Ÿåº¦å¿«ä½†è¿‘ä¼¼çš„å‘é‡æœç´¢ä¸åŒï¼Œé‡æ’åºæ¨¡å‹ä¼šï¼š\n",
    "\n",
    "* åŒæ—¶é˜…è¯»æŸ¥è¯¢å’Œæ–‡æœ¬å—\n",
    "* ç†è§£æ›´ç»†è‡´çš„å…³è”\n",
    "* æŠŠæœ€ç›¸å…³çš„ä¸Šä¸‹æ–‡æå‡åˆ°é¡¶éƒ¨\n",
    "\n",
    "åŒºåˆ«åœ¨äºï¼š\n",
    "\n",
    "* â€œè¿™äº›æ–‡æ¡£å¤§æ¦‚ç›¸å…³â€ â†’ å‘é‡æœç´¢\n",
    "* â€œè¿™ç¯‡æ–‡æ¡£ç›´æ¥å›ç­”äº†ä½ çš„é—®é¢˜â€ â†’ é‡æ’åº\n",
    "\n",
    "å¯¹ **TaskFriend** æ¥è¯´ï¼Œè¿™ç‚¹è‡³å…³é‡è¦ã€‚å½“ç”¨æˆ·è¯´ï¼š\n",
    "\n",
    "> `â€œIâ€™m stuck â€” what should I do next?â€` \n",
    "\n",
    "ä»–ä»¬ä¸è¦æ³›æ³›çš„å»ºè®®ï¼Œè€Œæ˜¯æƒ³è¦æ­£ç¡®çš„å»ºè®®â€”â€”ä¾‹å¦‚ 5 åˆ†é’Ÿè§„åˆ™â€”â€”è¢«æ”¾åœ¨æœ€å‰é¢ã€‚\n",
    "\n",
    "é‡æ’åºå¯ä»¥ä¿è¯è¿™ç‚¹ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441de28a-f77a-4e7e-a724-0c6059e71b4d",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_cases = [\n",
    "    {\n",
    "        \"question\": \"Which tasks are due today?\",\n",
    "        \"ground_truth\": (\"\"\"\n",
    "        The tasks due today are:\n",
    "        1. Finalize Q3 OKRs is due today, \n",
    "        2. Onboard new team member is due today, \n",
    "        3. Update project roadmap is due today, \n",
    "        4. Write thank-you letter is due today\n",
    "        \"\"\"          \n",
    "        )\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234c9846-a678-4862-9755-a32f7e102767",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index.core.indices.utils import default_parse_choice_select_answer_fn\n",
    "\n",
    "def safe_parse_choice_select_answer_fn(answer: str, num_choices: int):\n",
    "    \"\"\"\n",
    "    Safely parse LLM reranker output.\n",
    "    Handles cases where LLM adds explanations, uses inconsistent formatting, etc.\n",
    "    \"\"\"\n",
    "    # Debug: see what the LLM actually returned\n",
    "    print(f\"ğŸ” LLM Reranker Raw Output:\\n{answer}\\n{'â”€'*50}\")\n",
    "    \n",
    "    # Strategy 1: Extract only the part before \"Explanation\" (if present)\n",
    "    if \"Explanation\" in answer:\n",
    "        answer = answer.split(\"Explanation\")[0]\n",
    "    \n",
    "    # Strategy 2: Remove any non-digit, non-comma characters (keep only numbers and commas)\n",
    "    import re\n",
    "    cleaned = re.sub(r'[^\\d,]', ' ', answer)  # Keep digits and commas\n",
    "    cleaned = ','.join(cleaned.split())  # Normalize spacing\n",
    "    \n",
    "    # Fallback: if still no valid format, try original parser\n",
    "    try:\n",
    "        return default_parse_choice_select_answer_fn(cleaned or answer, num_choices)\n",
    "    except (IndexError, ValueError, KeyError) as e:\n",
    "        print(f\"âš ï¸ Parse failed: {e}. Falling back to top {num_choices} nodes.\")\n",
    "        # Return top N indices as fallback (0, 1, 2, ...)\n",
    "        return list(range(min(num_choices, num_choices))), [1.0] * min(num_choices, num_choices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b1ebb1-8a85-49c3-99e2-4be6cb1436e4",
   "metadata": {
    "ExecutionIndicator": {
     "show": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index.core.postprocessor import LLMRerank\n",
    "\n",
    "# Reset index to read all documents in the `./docs/taskfriend` directory\n",
    "documents = SimpleDirectoryReader(\n",
    "    \"./docs/taskfriend\",\n",
    "    required_exts=[\".pdf\"],\n",
    "    recursive=False\n",
    ").load_data()\n",
    "print(f\"âœ… Loaded {len(documents)} documents\")\n",
    "\n",
    "splitter = TokenTextSplitter(chunk_size=256, chunk_overlap=16)\n",
    "\n",
    "print(\"ğŸ§± Parsing documents into chunks...\")\n",
    "nodes = splitter.get_nodes_from_documents(documents)\n",
    "print(f\"   â†’ Created {len(nodes)} chunks\")\n",
    "    \n",
    "index = VectorStoreIndex(nodes, embed_model=Settings.embed_model)\n",
    "\n",
    "rerank_query_engine = index.as_query_engine(\n",
    "    similarity_top_k=3,\n",
    "    streaming=False,\n",
    "    llm=Settings.llm,\n",
    "    node_postprocessors=[\n",
    "        LLMRerank(\n",
    "            choice_batch_size=5,\n",
    "            top_n=5\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Run with reranking\n",
    "print(\"\\nğŸš€ BASELINE: Vector Search Only\")\n",
    "baseline_engine = index.as_query_engine(similarity_top_k=5, llm=Settings.llm)\n",
    "baseline_results = eval_output(query_engine=baseline_engine, question=question, ground_truth=ground_truth)\n",
    "display(baseline_results)\n",
    "\n",
    "# Run with reranking\n",
    "print(\"\\nğŸš€ ENHANCED: Reranking + Vector Search\")\n",
    "rerank_results = eval_output(query_engine=rerank_query_engine, question=question, ground_truth=ground_truth)\n",
    "display(rerank_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2363cc6-699c-4f16-96a9-e3c22aa4b764",
   "metadata": {},
   "source": [
    "ç»“æœéå¸¸æƒŠè‰³â€”â€”æˆ‘ä»¬çœ‹åˆ°é»˜è®¤æ’åºå™¨æŠŠå¤§é‡æ— å…³å—æ’åœ¨äº†å‰é¢ï¼Œå¯¼è‡´ç­”æ¡ˆä¸é¢„æœŸç›¸å·®ç”šè¿œã€‚è€Œå¼•å…¥ `LLMRerank` åå¤„ç†å™¨åï¼Œæœ€å…³é”®çš„ 3 æ¡ä¿¡æ¯è¢«æ”¾åˆ°äº†é¡¶éƒ¨ï¼Œç”Ÿæˆçš„å›ç­”æ›´åŠ å‡†ç¡®ã€è´´åˆé—®é¢˜ã€‚\n",
    "\n",
    "# ä¼˜åŒ–åçš„ RAG æµæ°´çº¿\n",
    "\n",
    "---\n",
    "\n",
    "åœ¨æœ¬ç« ä¸­ï¼Œä½ æŠŠ **TaskFriend** ä»åŸºç¡€ RAG ç³»ç»Ÿå‡çº§ä¸ºä¸€ä¸ªæ‡‚ä¸Šä¸‹æ–‡ã€ä¼šæ€è€ƒçš„åŠ©æ‰‹ï¼Œä¼˜åŒ–äº†æµæ°´çº¿ä¸­çš„æ¯ä¸€ä¸ªç¯èŠ‚ï¼š\n",
    "\n",
    "```mermaid\n",
    "graph TD\n",
    "    A[ç”¨æˆ·æŸ¥è¯¢] --> B{æŸ¥è¯¢æ”¹å†™}\n",
    "    B -->|é‡å†™åçš„æŸ¥è¯¢| C[å…ƒæ•°æ®è¿‡æ»¤]\n",
    "    C -->|è¿‡æ»¤åçš„æ–‡æœ¬å—| D[å‘é‡ç›¸ä¼¼åº¦æœç´¢]\n",
    "    D -->|Top-K æ–‡æœ¬å—| E[é‡æ’åº]\n",
    "    E -->|é‡æ’åçš„ä¸Šä¸‹æ–‡| F[LLM ç”Ÿæˆ]\n",
    "    F --> G[æœ€ç»ˆå›ç­”]\n",
    "\n",
    "    subgraph \"TaskFriend çŸ¥è¯†åº“\"\n",
    "        direction TB\n",
    "        H[åŸå§‹æ–‡æ¡£] --> I[åˆ†å—]\n",
    "        I --> J[å…ƒæ•°æ®æ ‡ç­¾]\n",
    "        J --> K[åµŒå…¥æ¨¡å‹]\n",
    "        K --> L[(å‘é‡æ•°æ®åº“)]\n",
    "    end\n",
    "\n",
    "    J -->|topic: being-stuck<br>framework: 5-minute-rule| C\n",
    "    L --> D\n",
    "    E -.->|ä½¿ç”¨äº¤å‰ç¼–ç å™¨<br>è¿›è¡Œç›¸å…³æ€§æ‰“åˆ†| L\n",
    "\n",
    "    style A fill:#4CAF50,stroke:#388E3C,color:white\n",
    "    style G fill:#4CAF50,stroke:#388E3C,color:white\n",
    "    style B fill:#2196F3,stroke:#1976D2,color:white\n",
    "    style C fill:#FF9800,stroke:#F57C00,color:white\n",
    "    style E fill:#9C27B0,stroke:#7B1FA2,color:white\n",
    "    style L fill:#607D8B,stroke:#455A64,color:white\n",
    "\n",
    "    classDef process fill:#2196F3,stroke:#1976D2,stroke-width:2px,color:white;\n",
    "    classDef enhancement fill:#FF9800,stroke:#F57C00,stroke-width:2px,color:white;\n",
    "    classDef final fill:#4CAF50,stroke:#388E3C,stroke-width:2px,color:white;\n",
    "    classDef db fill:#607D8B,stroke:#455A64,stroke-width:2px,color:white;\n",
    "\n",
    "    class B,C,E process\n",
    "    class J enhancement\n",
    "    class A,G final\n",
    "    class L db\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e027f6-1b13-4e10-bf37-1ca56f5192c6",
   "metadata": {
    "tags": []
   },
   "source": [
    "# æ¥ä¸‹æ¥å‘¢ï¼Ÿ\n",
    "\n",
    "---\n",
    "\n",
    "## è‡ªæµ‹æ—¶é—´ï¼\n",
    "\n",
    "<details>\n",
    "<summary style=\"cursor: pointer; padding: 12px; border: 1px solid #dee2e6; border-radius: 6px;\">\n",
    "<b>1. ä¸‹åˆ—å“ªé¡¹æœ€èƒ½æè¿° RAG ç³»ç»Ÿä¸­ `similarity_top_k` å‚æ•°çš„ä½œç”¨ï¼Ÿ</b>  \n",
    "\n",
    "<ul>\n",
    "    <li>A) é™åˆ¶ LLM ç”Ÿæˆç­”æ¡ˆçš„æ¬¡æ•°  </li>\n",
    "    <li>B) æ§åˆ¶ä»å‘é‡åº“æ£€ç´¢çš„æ–‡æœ¬å—æ•°é‡  </li>\n",
    "    <li>C) å†³å®šæŸ¥è¯¢è¢«é‡å†™çš„æ¬¡æ•°  </li>\n",
    "    <li>D) è®¾å®šæ–‡æœ¬å—çš„æœ€å¤§å­—ç¬¦æ•°</li>\n",
    "</ul>\n",
    "\n",
    "**æŸ¥çœ‹ç­”æ¡ˆ â†’**\n",
    "</summary>\n",
    "\n",
    "<div style=\"margin-top: 10px; padding: 15px; border: 1px solid #dee2e6; border-radius: 0 0 6px 6px;\">\n",
    "\n",
    "âœ… **æ­£ç¡®ç­”æ¡ˆï¼š** B) æ§åˆ¶ä»å‘é‡åº“æ£€ç´¢çš„æ–‡æœ¬å—æ•°é‡  \n",
    "ğŸ“ **è§£é‡Š**ï¼š\n",
    "* `similarity_top_k` å‚æ•°å†³å®šäº†å‘é‡åº“è¿”å›çš„ Top-K æ–‡æœ¬å—æ•°é‡ï¼Œä¾æ®çš„æ˜¯æŸ¥è¯¢ä¸åµŒå…¥å‘é‡çš„ç›¸ä¼¼åº¦ã€‚\n",
    "* è¿™æ˜¯ä¸€ä¸ªå…³é”®è°ƒèŠ‚å‚æ•°ï¼Œç›´æ¥å½±å“ï¼š\n",
    "    * å¬å›ç‡ï¼ˆæ˜¯å¦æ£€å›æ‰€æœ‰ç›¸å…³ä¿¡æ¯ï¼Ÿï¼‰\n",
    "    * ç²¾ç¡®ç‡ï¼ˆæ£€å›çš„å†…å®¹æ˜¯å¦çœŸæ­£ç›¸å…³ï¼Ÿï¼‰\n",
    "\n",
    "</div>\n",
    "</details>\n",
    "\n",
    "## æ ¸å¿ƒè¦ç‚¹\n",
    "\n",
    "* **ä¸ºä»€ä¹ˆè¦ä¼˜åŒ– RAGï¼Ÿ**\n",
    "    * **åŸºç¡€ RAG éš¾ä»¥åº”å¯¹å¤æ‚é—®é¢˜**â€”â€”å°¤å…¶æ˜¯æƒ…ç»ªåŒ–ã€æ¨¡ç³Šæˆ–å¤šé‡æ„å›¾çš„æé—®ã€‚\n",
    "    * **æ£€ç´¢è´¨é‡å†³å®šç”Ÿæˆè´¨é‡**â€”â€”â€œåƒåœ¾ä¸Šä¸‹æ–‡â€åªä¼šå¸¦æ¥â€œåƒåœ¾ç­”æ¡ˆâ€ã€‚\n",
    "    * **ä¼˜åŒ–ä¸æ˜¯å¯é€‰é¡¹**â€”â€”å®ƒæ˜¯ä»â€œå‹‰å¼ºå¯ç”¨â€è¿ˆå‘â€œå¯ä¸Šçº¿â€çš„å¿…ç»ä¹‹è·¯ã€‚\n",
    "    * **ç›®æ ‡ä¸ä»…æ˜¯ç›¸å…³æ€§ï¼Œè¿˜è¦æœ‰ä¾æ®ã€æœ‰åŒç†å¿ƒã€‚**\n",
    "\n",
    "<br>\n",
    "\n",
    "* **æ–‡æ¡£é¢„å¤„ç†**\n",
    "    * **æ–‡æ¡£çš„åˆ‡åˆ†ä¸æ ¼å¼ä¼šç›´æ¥å½±å“æ£€ç´¢è¡¨ç°ã€‚**\n",
    "    * **Markdown ä¼˜ç‚¹ï¼š**\n",
    "      - ä¿ç•™ç»“æ„ï¼ˆæ ‡é¢˜ã€åˆ—è¡¨ï¼‰\n",
    "      - æ˜“äºé˜…è¯»\n",
    "    * **Markdown ç¼ºç‚¹ï¼š**\n",
    "      - è¿‡åº¦åˆ‡åˆ†ä¼šç ´åä¸Šä¸‹æ–‡\n",
    "      - å…ƒæ•°æ®æ”¯æŒè¾ƒå¼±\n",
    "    * **æœ€ä½³å®è·µï¼š**\n",
    "      - ä½¿ç”¨è¯­ä¹‰æ„ŸçŸ¥çš„åˆ†å—ï¼ˆå¦‚æŒ‰ç« èŠ‚ï¼‰\n",
    "      - æ·»åŠ å…ƒæ•°æ®ï¼ˆä¾‹å¦‚ `source: coaching_guide`ï¼‰\n",
    "      - é¿å…è¿‡åº¦æ‹†åˆ†\n",
    "\n",
    "<br>\n",
    "\n",
    "* **ç»¼åˆ**\n",
    "    * **æ²¡æœ‰ä¸‡èƒ½æŠ€å·§**â€”â€”å°†ä»¥ä¸‹æ–¹æ³•ç»„åˆä½¿ç”¨ï¼š\n",
    "      - æŸ¥è¯¢æ”¹å†™ â†’ æ¾„æ¸…æ„å›¾\n",
    "      - å¤šæ­¥åˆ†è§£ â†’ æ”¯æŒæ¨ç†\n",
    "      - HyDE â†’ å…¼é¡¾åŒç†å¿ƒ\n",
    "      - é‡æ’åº â†’ æå‡ç²¾åº¦\n",
    "    * **RAG çš„æœªæ¥ä¸åœ¨æ£€ç´¢æœ¬èº«ï¼Œè€Œåœ¨ç†è§£èƒ½åŠ›ã€‚**\n",
    "    * **ä½ çš„ç›®æ ‡ï¼šæ„å»ºä¸ä»…èƒ½å›ç­”ï¼Œæ›´èƒ½å¸®åŠ©çš„ç³»ç»Ÿã€‚**\n",
    "    \n",
    "<br>\n",
    "\n",
    "* **æŸ¥è¯¢æ”¹å†™**\n",
    "    * **è‡ªç„¶è¯­è¨€å¾ˆæ··ä¹±**â€”â€”ç”¨æˆ·ä¼šè¯´ â€œIâ€™m stuckâ€ï¼Œè€Œä¸æ˜¯ â€œè¯·æ£€ç´¢ä»»åŠ¡é˜»å¡æŒ‡å¯¼â€ã€‚\n",
    "    * **æŸ¥è¯¢æ”¹å†™å¯ä»¥å€ŸåŠ© LLMï¼Œå°†æ„å›¾è½¬æ¢æˆå‹å¥½çš„æ£€ç´¢è¯­å¥ã€‚**\n",
    "    * **å®ƒé€šè¿‡æŠŠå…³é”®çŸ­è¯­æ˜ å°„åˆ°ç»“æ„åŒ–è¿‡æ»¤æ¡ä»¶æå‡æ£€ç´¢å‡†ç¡®æ€§**ï¼ˆå¦‚ â€œdue todayâ€ â†’ `Due == 'Today'`ï¼‰ã€‚\n",
    "    * **é€‚ç”¨åœºæ™¯ï¼š**\n",
    "      - å«ç³Šä¸æ¸…çš„æé—®\n",
    "      - æƒ…ç»ªåŒ–çš„è¡¨è¾¾\n",
    "      - éšå«éœ€æ±‚\n",
    "    * **åŠ¡å¿…ä¿ç•™åŸæœ‰è¯­å¢ƒ**â€”â€”ä¸è¦åœ¨ç¿»è¯‘ä¸­ä¸¢å¤±ç´§è¿«æ„Ÿæˆ–æƒ…ç»ªã€‚\n",
    "\n",
    "<br>\n",
    "\n",
    "* **å¤šæ­¥åˆ†è§£**\n",
    "    * **å¤æ‚é—®é¢˜éœ€è¦å¤æ‚æ¨ç†**â€”â€”æŠŠå®ƒä»¬æ‹†æˆå­é—®é¢˜ã€‚\n",
    "    * **ç¤ºä¾‹**ï¼š  \n",
    "      â€œIâ€™m stuck on OKRsâ€ â†’  \n",
    "      1. å®Œæˆ OKR çš„æ­¥éª¤æœ‰å“ªäº›ï¼Ÿ  \n",
    "      2. å¯ä»¥å¯»æ±‚å“ªäº›å¸®åŠ©ï¼Ÿ  \n",
    "      3. å¡ä½æ—¶å¦‚ä½•å¼€å±€ï¼Ÿ\n",
    "    * **ä½¿ç”¨ QueryEngineTool ç­‰å·¥å…·**ï¼ŒæŠŠå­é—®é¢˜è·¯ç”±åˆ°ä¸åŒçŸ¥è¯†åº“ã€‚\n",
    "    * **æƒè¡¡ç‚¹**ï¼šæ›´å¤šæ­¥éª¤æ„å‘³ç€æ›´å¤š API è°ƒç”¨ï¼Œä½†æ¢æ¥æ›´æ·±çš„æ¨ç†ã€‚\n",
    "\n",
    "<br>\n",
    "\n",
    "* **HyDE**\n",
    "    * **HyDEï¼ˆHypothetical Document Embeddingsï¼‰åå‘æ€è€ƒï¼šå…ˆç”Ÿæˆâ€œå‡è®¾ç­”æ¡ˆâ€ï¼Œå†ç”¨å®ƒæ£€ç´¢ã€‚**\n",
    "    * **ä¹‹æ‰€ä»¥å¥æ•ˆï¼Œæ˜¯å› ä¸ºå‡è®¾ç­”æ¡ˆä¸æŒ‡å¯¼æ‰‹å†Œçš„å†™ä½œé£æ ¼ã€å†…å®¹ç±»å‹ç›¸ä¼¼ã€‚**\n",
    "    * **éå¸¸é€‚åˆï¼š**\n",
    "      - æ•™ç»ƒ/å»ºè®®å‹ç³»ç»Ÿ\n",
    "      - ç¼ºä¹ç›´æ¥å…³é”®è¯åŒ¹é…çš„æŸ¥è¯¢\n",
    "      - æƒ…ç»ªåŒ–æˆ–å¼€æ”¾å¼æé—®\n",
    "    * **é£é™©**ï¼šå¦‚æœå‡è®¾ç­”æ¡ˆè·‘åï¼Œå¯èƒ½æ£€ç´¢åˆ°æ— å…³å†…å®¹ã€‚\n",
    "\n",
    "<br>\n",
    "\n",
    "* **é‡æ’åº**\n",
    "    * **å‘é‡æœç´¢åªèƒ½æ‰¾åˆ°â€œç›¸å…³â€å†…å®¹ï¼Œå´æœªå¿…æ’å‡ºâ€œæœ€æœ‰ç”¨â€çš„å†…å®¹ã€‚**\n",
    "    * **é‡æ’åºåˆ©ç”¨äº¤å‰ç¼–ç å™¨ï¼ˆå¦‚ CohereRerankï¼‰é‡æ–°è°ƒåº**ï¼Œæ·±åº¦ç†è§£â€œæŸ¥è¯¢-æ–‡æœ¬â€çš„å¯¹åº”å…³ç³»ã€‚\n",
    "    * **ç¡®ä¿å…³é”®å†…å®¹ï¼ˆå¦‚ 5 åˆ†é’Ÿè§„åˆ™ï¼‰å§‹ç»ˆä½äºä¸Šä¸‹æ–‡çª—å£é¡¶éƒ¨ã€‚**\n",
    "    * **æœ€ä½³å®è·µ**ï¼šå¤šæ£€ç´¢ä¸€äº›ï¼ˆä¾‹å¦‚ Top-10ï¼‰ï¼Œå†é‡æ’ä¸º Top-3ã€‚\n",
    "    * **æ•ˆæœ**ï¼šæ›´å¼ºçš„ä¾æ®æ€§ã€æ›´å°‘å¹»è§‰ã€æ›´ä¼˜å›ç­”ã€‚"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM Engineer (Professional)",
   "language": "python",
   "name": "llm_pro"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
