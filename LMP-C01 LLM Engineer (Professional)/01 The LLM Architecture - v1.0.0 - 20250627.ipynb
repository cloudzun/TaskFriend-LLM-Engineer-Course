{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b63e6c92-a10c-404b-916d-a493d2265214",
   "metadata": {},
   "source": [
    "# LLM æ¶æ„\n",
    "\n",
    "---\n",
    "\n",
    "å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä»£è¡¨äº†ç°ä»£äººå·¥æ™ºèƒ½ç³»ç»Ÿçš„ä¸€æ¬¡é£è·ƒï¼Œç»¼åˆè¿ç”¨è‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆNLPï¼‰ã€Transformerã€åˆ†å¸ƒå¼è®¡ç®—ç­‰å¤šé¡¹æŠ€æœ¯ã€‚å°½ç®¡è¿™äº›ç»„ä»¶éƒ½æ˜¯ç°ä»£ LLM çš„å…³é”®æ„æˆï¼Œä½† Transformer æ— ç–‘æ˜¯æ¨åŠ¨ LLM å´›èµ·çš„æœ€é‡è¦æŠ€æœ¯çªç ´ã€‚æ­¤é˜¶æ®µå¹¶ä¸è¦æ±‚æ·±å…¥æŒæ¡ Transformer çš„å…¨éƒ¨ç»†èŠ‚ï¼Œä½†ç†è§£ç°ä»£ LLM çš„æ ¸å¿ƒæµç¨‹è‡³å…³é‡è¦ï¼š\n",
    "\n",
    "* **åˆ†è¯ï¼ˆTokenizationï¼‰ï¼š** å°†æ–‡æœ¬è½¬æ¢ä¸ºæœºå™¨å¯ç†è§£çš„æ•°å­—\n",
    "* **å¤„ç†ï¼ˆProcessingï¼‰ï¼š** è®©æ¨¡å‹åˆ¤æ–­æ–‡æœ¬ä¸­çš„\"é‡è¦æ€§\"\n",
    "* **ç”Ÿæˆï¼ˆGenerationï¼‰ï¼š** é€šè¿‡è§£ç ç­–ç•¥ç”Ÿæˆæ–‡æœ¬\n",
    "\n",
    "## æœ¬è¯¾ç¨‹çš„ç»“æ„ï¼Ÿ\n",
    "\n",
    "**ã€Š[LMP-C01] LLM Engineer (Professional)**ã€‹è¯¾ç¨‹é‡‡ç”¨ç‹¬ç‰¹è®¾è®¡ï¼Œä¸ºæ‚¨æ„å»ºä¸€ä¸ª*è™šæ„æƒ…å¢ƒ*ï¼Œå¹¶ä»¥æ‚¨ä¸ºä¸»è§’ã€‚è¯¾ç¨‹ä¸­çš„ç¤ºä¾‹ã€å®éªŒä¸æŒ‘æˆ˜éƒ½ç¯ç»•æ­¤æƒ…å¢ƒå±•å¼€ã€‚æ‚¨å°†ä»¥ä¸»è§’èº«ä»½å®Œæˆè¿™äº›æŒ‘æˆ˜ï¼Œä»è€ŒæŒæ¡æˆä¸ºä¸€å**LLM Enginner**æ‰€éœ€çš„å…¨éƒ¨èƒ½åŠ›ã€‚\n",
    "\n",
    "## æ•…äº‹èƒŒæ™¯\n",
    "\n",
    "æ‚¨åˆ›ç«‹äº†è‡ªå·±çš„åˆåˆ›å…¬å¸ï¼Œæ­£åœ¨æ‰“é€ ä¸€æ¬¾åä¸º **TaskFriend** çš„æ–°åº”ç”¨â€”â€”ä¸€ä½å¸®åŠ©ç”¨æˆ·ç®¡ç†æ—¥å¸¸ä»»åŠ¡ã€å®‰æ’ä¼˜å…ˆçº§å¹¶ä¼˜åŒ–æ—¶é—´çš„ AI åŠ©æ‰‹ã€‚éšç€ç”Ÿæˆå¼ AI æŠ€æœ¯çš„ä¸æ–­å‘å±•ï¼Œæ‚¨ä¸æ–­æ€è€ƒå¦‚ä½•å°† AI æ›´å¥½åœ°èå…¥äº§å“ã€‚è¿‘æœŸçš„ä¸€é¡¹ç”¨æˆ·è°ƒç ”å¸¦æ¥ä¸å°‘å¯å‘ï¼Œå…¶ä¸­ä¸€æ¡åé¦ˆå°¤å…¶å¼•äººæ³¨æ„ï¼š*`\"When I log tasks or new ideas, I often find myself stuck in a loop on deciding how to proceed or what to do next. What does the TaskFriend team do when they find themselves in a situation like this?\"`* è¿™æ¿€å‘äº†æ‚¨ä¸€è¿ä¸²çš„æƒ³æ³•ï¼Œæœ€ç»ˆå¾—å‡ºä¸€ä¸ªç»“è®ºã€‚\n",
    "\n",
    "æ‚¨çš„ç›®æ ‡ï¼šè®© AI èƒ½å¤Ÿç†è§£è¯¸å¦‚ `\"How do I organize my week?\"` æˆ– `\"Whatâ€™s the best way to study for exams?\"` è¿™æ ·çš„è‡ªç„¶è¯­è¨€é—®é¢˜ã€‚\n",
    "\n",
    "åœ¨æœ¬ç« ä¸­ï¼Œæˆ‘ä»¬å°†å›´ç»•ä»¥ä¸‹å¤æ‚é—®é¢˜çš„å¤„ç†æ€è·¯å¼€å±•å­¦ä¹ ï¼š\n",
    "\n",
    "`\"I need to finish a report due tomorrow but also want to go to the gym to keep fit. I'd like to do both. What should I do?\"`\n",
    "\n",
    "## å­¦ä¹ ç›®æ ‡\n",
    "\n",
    "* ç†è§£ LLM å¦‚ä½•å¤„ç†ä¸æ•ˆç‡ç›¸å…³çš„å’¨è¯¢\n",
    "* æ„å»ºä»»åŠ¡ä¼˜å…ˆçº§æœºå™¨äºº\n",
    "* è¯†åˆ«å¹¶è§„é¿ä¼¦ç†é£é™©ï¼ˆå¦‚æ’ç¨‹å¯¼è‡´çš„è¿‡åŠ³é£é™©ï¼‰"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d954569d-12a9-4e06-8e4b-87fd35f86031",
   "metadata": {},
   "source": [
    "## åˆå§‹åŒ–ç¯å¢ƒ\n",
    "\n",
    "### é…ç½® API Key\n",
    "\n",
    "åœ¨ä»»ä½•ç¬”è®°æœ¬å¼€å§‹å·¥ä½œå‰ï¼Œæˆ‘ä»¬éƒ½éœ€è¦åŠ è½½ [Model Studio çš„ API Key](https://modelstudio.console.alibabacloud.com/?tab=globalset#/efm/api_key)ï¼Œä»¥ä¾¿è°ƒç”¨æœ¬è¯¾ç¨‹ä¸­å°†æŒç»­ä½¿ç”¨çš„ Qwen ç³»åˆ—æ¨¡å‹æ¥å£ã€‚\n",
    "\n",
    "> å¦‚ä¸æ¸…æ¥šå¦‚ä½•è·å– **Model Studio** API Keyï¼Œè¯·å‚é˜… `00 Setting Up the Environment` æ–‡ä»¶ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422185e1-3ba9-4fcc-9e93-3d61b7719ce5",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load Model Studio API key\n",
    "import os\n",
    "from config.load_key import load_key\n",
    "load_key(\n",
    "    confirmation=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a1b57e-7ed6-4e2a-babb-710760acb176",
   "metadata": {},
   "source": [
    "### é…ç½® LLM å®¢æˆ·ç«¯\n",
    "\n",
    "æˆ‘ä»¬å°†é€šè¿‡ DashScope æä¾›çš„ã€å…¼å®¹ OpenAI åè®®çš„æ¥å£æ¥ä¸ Qwen æ¨¡å‹ï¼ˆä»¥åŠè¯¾ç¨‹ä¸­ä¼šä½¿ç”¨çš„å…¶ä»–æ¨¡å‹ï¼‰è¿›è¡Œäº¤äº’ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c81b92b-c711-405d-a941-969522e058cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "import logging\n",
    "\n",
    "logging.getLogger().setLevel(logging.ERROR)\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=os.getenv(\"DASHSCOPE_API_KEY\"),\n",
    "    base_url=\"https://dashscope-intl.aliyuncs.com/compatible-mode/v1\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dbddb8b-1451-4f80-8ada-3fa753177073",
   "metadata": {},
   "source": [
    "## ä½“éªŒ TaskFriend èŠå¤©æœºå™¨äºº\n",
    "\n",
    "### LLM çš„å“åº”æ–¹å¼\n",
    "\n",
    "LLM å¯ä»¥é€šè¿‡ä¸¤ç§æ¨¡å¼ç»™å‡ºå›ç­”ï¼šæµå¼ï¼ˆstreamingï¼‰ä¸éæµå¼ï¼ˆnon-streamingï¼‰ã€‚\n",
    "\n",
    "æˆ‘ä»¬å…ˆä»éæµå¼æ¨¡å¼å…¥æ‰‹ã€‚åœ¨è¿™ç§æ¨¡å¼ä¸‹ï¼Œæ¨¡å‹éœ€è¦æ¥æ”¶å®Œæ•´çš„è¾“å…¥åæ‰ä¼šç”Ÿæˆå“åº”ï¼Œé€‚ç”¨äºå¯¹å®æ—¶äº¤äº’è¦æ±‚ä¸é«˜çš„åœºæ™¯ã€‚ä¾‹å¦‚æ‚¨åœ¨æœç´¢å¼•æ“è¾“å…¥æŸ¥è¯¢æ—¶ï¼Œæœç´¢å¼•æ“é€šå¸¸ä¼šä»¥éæµå¼æ–¹å¼å¤„ç†è¯·æ±‚å¹¶è¿”å›ç»“æœã€‚å¯¹äºå¤§å¤šæ•°ç”¨æˆ·è€Œè¨€ï¼Œè¿™æ ·çš„å»¶è¿Ÿå¯ä»¥æ¥å—ï¼Œå› æ­¤å®æ—¶æ€§å¹¶éé¦–è¦è€ƒè™‘ã€‚\n",
    "\n",
    "ç°åœ¨ï¼Œæˆ‘ä»¬æ¥æµ‹è¯•ä¸€ä¸‹èŠå¤©æœºå™¨äººåœ¨éæµå¼æ¨¡å¼ä¸‹å¯¹ç®€å•é—®é¢˜çš„å“åº”è¡¨ç°ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4471f02-b84c-414a-8c32-842ff625b4fe",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# User query\n",
    "query = \"Tell me about yourself\"\n",
    "\n",
    "# System prompt\n",
    "system_prompt = \"You are TaskFriend, a helpful AI assistant that helps users manage daily tasks, prioritize work, and optimize time.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5646367-88d7-4584-b018-762a408e349f",
   "metadata": {
    "ExecutionIndicator": {
     "show": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Non-streaming mode response\n",
    "def get_qwen_response(query, system_prompt, temperature, top_p):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"qwen-plus\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": query}\n",
    "        ],\n",
    "        temperature=temperature,\n",
    "        top_p=top_p,\n",
    "        stream=False\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "response = get_qwen_response(query, system_prompt, temperature=0.7, top_p=0.8)\n",
    "print(f\"Query: '{query}'\")\n",
    "print(f\"=\" * 50 + \"\\n\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51db5ac-2976-4f9b-b040-964645d4ba4f",
   "metadata": {},
   "source": [
    "æ‚¨æ˜¯å¦æ³¨æ„åˆ°ï¼Œä»è¿è¡Œä»£ç åˆ°æ”¶åˆ°å›ç­”ä¹‹é—´å­˜åœ¨çŸ­æš‚å»¶è¿Ÿï¼Ÿè¿™æ­£æ˜¯éæµå¼æ¨¡å¼çš„å…¸å‹è¡¨ç°ï¼šåœ¨å®Œæ•´ç”Ÿæˆç­”æ¡ˆä¹‹å‰ï¼Œæ¨¡å‹ä¸ä¼šè¿”å›ä»»ä½•è¾“å‡ºã€‚å¯¹äºç®€çŸ­é—®ç­”è€Œè¨€ï¼Œè¿™æ ·çš„å»¶æ—¶å°šå¯æ¥å—ï¼Œä½†è‹¥è¯·æ±‚å†…å®¹è¾ƒé•¿ï¼Œä¾‹å¦‚è®© LLM ç¼–å†™å®Œæ•´æ–¹æ¡ˆï¼Œç­‰å¾…æ—¶é—´å°±ä¼šæ˜¾è‘—å¢åŠ ï¼Œä»è€Œå½±å“ç»ˆç«¯ç”¨æˆ·ä½“éªŒã€‚\n",
    "\n",
    "LLM çš„ä¸€é¡¹é‡è¦ä¼˜åŠ¿åœ¨äºæµå¼æ¨¡å¼ï¼Œå®ƒå…è®¸æ¨¡å‹åœ¨æ¥æ”¶è¾“å…¥çš„åŒæ—¶åˆ†æ®µè¾“å‡ºç»“æœã€‚è¿™æ ·æ—¢èƒ½æå‡å“åº”é€Ÿåº¦ï¼Œä¹Ÿè¥é€ å‡ºæ›´â€œäººæ€§åŒ–â€çš„ä½“éªŒï¼Œä»¿ä½›æ­£åœ¨ä¸å®æ—¶å¯¹è¯çš„ä¼™ä¼´äº’åŠ¨ã€‚\n",
    "\n",
    "è‹¥è¦åœ¨ Qwen ä¸­å¯ç”¨æµå¼æ¨¡å¼ï¼Œæˆ‘ä»¬éœ€è¦åœ¨å‡½æ•°ä¸­åŠ å…¥ `stream=True`ï¼Œå¹¶æŒ‰ç…§æ•°æ®å—å¤„ç†è¿”å›å†…å®¹ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225f5e72-aac2-4322-a0ee-513c475aba39",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Streaming mode response\n",
    "def get_qwen_stream_response(query, system_prompt, temperature, top_p):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"qwen-plus\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": query}\n",
    "        ],\n",
    "        temperature=temperature,\n",
    "        top_p=top_p,\n",
    "        stream=True\n",
    "    )\n",
    "    \n",
    "    for chunk in response:\n",
    "        content = chunk.choices[0].delta.content\n",
    "        if content:  # Skip empty chunks\n",
    "            yield content\n",
    "\n",
    "response = get_qwen_stream_response(query, system_prompt, temperature=0.7, top_p=0.8)\n",
    "print(f\"Query: '{query}'\")\n",
    "print(f\"=\" * 50 + \"\\n\")\n",
    "for chunk in response:\n",
    "    print(chunk, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b386c6f-115d-4840-a529-70cb3c9c2c3d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# åˆ†è¯ï¼šè®©æ–‡æœ¬å˜æˆæ•°å­—\n",
    "\n",
    "---\n",
    "\n",
    "æœºå™¨çœŸçš„èƒ½å¬æ‡‚äººç±»åœ¨è¯´ä»€ä¹ˆå—ï¼Ÿä¸æˆ‘ä»¬ä¸åŒï¼Œæœºå™¨å¹¶ä¸èƒ½ç›´æ¥ç†è§£è‡ªç„¶è¯­è¨€ã€‚å€˜è‹¥è®©å…¶è‡ªè¡Œå‘å±•è¯­è¨€ä½“ç³»ï¼Œç»“æœå¾ˆå¯èƒ½ä¸äººç±»é¢„æœŸå¤§ç›¸å¾„åº­ã€‚ä¸€ä¸ªè‘—åæ¡ˆä¾‹æ˜¯ Facebook äººå·¥æ™ºèƒ½ç ”ç©¶é™¢ï¼ˆFAIRï¼‰åœ¨ 2017 å¹´è¿›è¡Œçš„å®éªŒï¼Œä»–ä»¬è®­ç»ƒäº†ä¸€å¥— AI ç³»ç»Ÿï¼Œå¹¶è§‚å¯Ÿå…¶ç”Ÿæˆçš„â€œè¯­è¨€â€â€¦â€¦\n",
    "\n",
    "æ€»çš„æ¥è¯´ï¼Œæœºå™¨å¹¶ä¸æ“…é•¿å¤©ç”Ÿç†è§£è¯­è¨€ï¼Œä½†å®ƒä»¬æå–„äºå¤„ç†æ•°å­—ã€‚å› æ­¤ï¼ŒLLM å¤„ç†ä»»ä½•æŸ¥è¯¢çš„ç¬¬ä¸€æ­¥ï¼Œä¾¿æ˜¯é€šè¿‡ **åˆ†è¯ï¼ˆtokenizationï¼‰** å°†æ–‡æœ¬æ‹†è§£å¹¶è½¬åŒ–ä¸ºæ•°å­—ã€‚åˆ†è¯ä¼šæŠŠå¥å­æ‹†åˆ†æˆä¸€ä¸ªä¸ª **è¯å…ƒï¼ˆtokenï¼‰**ï¼Œè¿™äº›è¯å…ƒå°±æ˜¯ LLM æ¥æ”¶çš„åŸå§‹è¾“å…¥ã€‚\n",
    "\n",
    "## ä»€ä¹ˆæ˜¯è¯å…ƒï¼Ÿ\n",
    "\n",
    "**è¯å…ƒ** æ˜¯ LLM èƒ½å¤Ÿç†è§£çš„æœ€å°æ„ä¹‰å•ä½ï¼Œå¯ä»¥æ˜¯ï¼š\n",
    "\n",
    "* ä¸€ä¸ª**å®Œæ•´å•è¯**ï¼ˆå¦‚ \"deadline\"ï¼‰\n",
    "* ä¸€ä¸ª**å­è¯**ï¼ˆå¦‚ \"un\" + \"happiness\"ï¼‰\n",
    "* ä¸€ä¸ª**ç¬¦å·**ï¼ˆå¦‚ \"ã€‚\"ã€\"ï¼Ÿ\"ï¼‰\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd2019c-8d12-4997-b0a7-4e82103bfb85",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# User query\n",
    "query = \"I have a report due tomorrow, but I want to go to the gym to avoid burnout.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d9c83c-54d2-43e3-a51c-df9340128c5d",
   "metadata": {
    "ExecutionIndicator": {
     "show": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "from transformers import AutoTokenizer\n",
    "from functions.safe_token_str import safe_token_str\n",
    "from functions.token_table import create_token_table\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Initialize tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"Qwen/Qwen-7B\", \n",
    "    trust_remote_code=True,\n",
    "    use_fast=True\n",
    ")\n",
    "\n",
    "# Tokenize input string\n",
    "tokens = tokenizer.tokenize(\n",
    "    query,\n",
    "    allowed_special=set(),  # Treat all text as normal text\n",
    "    disallowed_special=()    # Don't raise errors for special tokens\n",
    ")\n",
    "\n",
    "# Convert tokens to strings (handle bytes if necessary)\n",
    "tokens = [t.decode('utf-8') if isinstance(t, bytes) else t for t in tokens]\n",
    "\n",
    "# Get token IDs\n",
    "token_ids = tokenizer.encode(\n",
    "    query,\n",
    "    allowed_special=set(),\n",
    "    disallowed_special=()\n",
    ")\n",
    "\n",
    "# Verify token-ID alignment\n",
    "if len(tokens) != len(token_ids):\n",
    "    min_len = min(len(tokens), len(token_ids))\n",
    "    tokens = tokens[:min_len]\n",
    "    token_ids = token_ids[:min_len]\n",
    "\n",
    "# Display tokenization results in a styled table\n",
    "print(f\"Query: '{query}'\")\n",
    "print(f\"=\" * 50 + \"\\n\")\n",
    "print(\"Tokenization Results:\")\n",
    "create_token_table(tokens, token_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a798ec0-15d3-44ff-817f-178eb841f8a1",
   "metadata": {},
   "source": [
    "### é‡å¤è¯å…ƒ ID çš„æ„ä¹‰\n",
    "\n",
    "æ¯ä¸ªè¯å…ƒéƒ½æœ‰å”¯ä¸€çš„ IDâ€”â€”ä¹Ÿå°±æ˜¯è¯´ï¼ŒåŒä¸€ä¸ªè¯å…ƒåœ¨ä»»ä½•ä½ç½®éƒ½ä¼šå¯¹åº”åŒä¸€ä¸ª IDã€‚åœ¨ä¸Šä¸€ç¤ºä¾‹ä¸­ï¼Œæˆ‘ä»¬çœ‹åˆ°å¤šä¸ªè¯å…ƒå…±äº«**ç›¸åŒçš„è¯å…ƒ ID**ã€‚è¿™æ°æ°æ˜¯ LLM ä¸­**æœ€åŸºç¡€å´ç»å¸¸è¢«å¿½è§†çš„æ¦‚å¿µä¹‹ä¸€**ã€‚æˆ‘ä»¬ä¸€èµ·æ¥çœ‹çœ‹ï¼Œä¸ºä½•ç›¸åŒçš„è¯å…ƒä¼šæ‹¥æœ‰ç›¸åŒçš„ IDï¼Œä»¥åŠè¿™ç§é‡å¤å¯¹äºè¯­ä¹‰ç†è§£æœ‰ä½•é‡è¦ä½œç”¨ã€‚\n",
    "\n",
    "```mermaid\n",
    "graph LR\n",
    "A[Token ' to'] --> B{Vocabulary}\n",
    "B --> C[ID 311]\n",
    "D[Another ' to'] --> B\n",
    "E[' report'] --> B\n",
    "B --> F[ID 1895]\n",
    "\n",
    "```\n",
    "\n",
    "è¿™æ˜¯åˆ†è¯çš„ä¸€ä¸ª**åŸºæœ¬è§„å¾‹**ï¼š\n",
    "\n",
    "* æ¯æ¬¡å‡ºç°å®Œå…¨ç›¸åŒçš„è¯å…ƒï¼Œéƒ½ä¼šæ˜ å°„åˆ°å®Œå…¨ç›¸åŒçš„ ID\n",
    "* å› æ­¤å¸¦ç©ºæ ¼çš„ `' to'` æ€»æ˜¯æ˜ å°„åˆ°åŒä¸€ä¸ª ID\n",
    "* ä½†ä¸å¸¦ç©ºæ ¼çš„ `'to'` åˆ™ä¸æ˜¯åŒä¸€ä¸ªè¯å…ƒï¼ˆID ä¸åŒï¼‰\n",
    "\n",
    "### é‡å¤ ID å¦‚ä½•æ„å»ºè¯­ä¹‰ç†è§£\n",
    "\n",
    "1. **æ¨¡å¼è¯†åˆ«å¼•æ“**\n",
    "    \n",
    "    å½“åŒä¸€è¯å…ƒ ID å¤šæ¬¡å‡ºç°æ—¶ï¼Œæ¨¡å‹ä¼šæ•æ‰åˆ°æœ‰æ„ä¹‰çš„æ¨¡å¼ï¼š\n",
    "    \n",
    "    `# ç”¨æˆ·æŸ¥è¯¢: \"I need to finish... want to go to the gym...\"`\n",
    "    \n",
    "    `token_ids = [..., 311, ..., 311, ..., 311, ...]  # éƒ½æ˜¯ ' to' è¯å…ƒ`\n",
    "    \n",
    "    **æ¨¡å‹å­¦åˆ°çš„å†…å®¹ï¼š**\n",
    "\n",
    "    * å½“ ID 311ï¼ˆ' to'ï¼‰åœ¨ä¸€å¥è¯ä¸­å‡ºç° 3 æ¬¡ â†’ æå¯èƒ½æ˜¯ä»»åŠ¡åˆ—è¡¨\n",
    "    * æ¨¡å¼ï¼š [ACTION] to [TASK] â†’ [ACTION] to [TASK] â†’ [ACTION] to [TASK]\n",
    "    * TaskFriend ä¾¿èƒ½æ®æ­¤è¯†åˆ« \"need to finish\"ã€\"want to go\"ã€\"like to do\" ç­‰ä»»åŠ¡åºåˆ—\n",
    "    \n",
    "2. **æ³¨æ„åŠ›æœºåˆ¶çš„â€œç‡ƒæ–™â€**\n",
    "    \n",
    "    é‡å¤çš„è¯å…ƒ ID ä¸º Transformer çš„æ³¨æ„åŠ›æœºåˆ¶æä¾›åŠ¨åŠ›ï¼š\n",
    "    \n",
    "    ```mermaid\n",
    "    graph LR\n",
    "    A[' to' ID 311] --> B[Attention]\n",
    "    C[' to' ID 311] --> B\n",
    "    D[' to' ID 311] --> B\n",
    "    B --> E[Pattern: Task Sequence]\n",
    "    \n",
    "    ```\n",
    "    \n",
    "    æ³¨æ„åŠ›æœºåˆ¶ä¼šå­¦ä¹ åˆ°ï¼š\n",
    "    \n",
    "    > â€œå½“æˆ‘è¿ç»­çœ‹åˆ°å¤šä¸ª ID 311 çš„è¯å…ƒæ—¶ï¼Œè¦é‡ç‚¹å…³æ³¨åé¢çš„å†…å®¹â€”â€”å®ƒä»¬å¾ˆå¯èƒ½æ˜¯ä»»åŠ¡åˆ—è¡¨ã€‚â€\n",
    "    \n",
    "    æ­£æ˜¯å€ŸåŠ©è¿™ç§æ³¨æ„åŠ›æœºåˆ¶ï¼ŒTaskFriend èƒ½ç†è§£ \"need to finish\"ã€\"want to go\" å’Œ \"like to do\" å½¢æˆçš„ä»»åŠ¡åºåˆ—æ¨¡å¼ï¼Œå¹¶æ®æ­¤è§¦å‘ä¼˜å…ˆçº§åˆ¤æ–­é€»è¾‘ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc526723-ab97-4b83-a809-9dec9907e45a",
   "metadata": {
    "ExecutionIndicator": {
     "show": false
    },
    "execution": {
     "iopub.execute_input": "2025-07-27T13:36:13.223472Z",
     "iopub.status.busy": "2025-07-27T13:36:13.223238Z",
     "iopub.status.idle": "2025-07-27T13:36:13.245211Z",
     "shell.execute_reply": "2025-07-27T13:36:13.244480Z",
     "shell.execute_reply.started": "2025-07-27T13:36:13.223454Z"
    },
    "tags": []
   },
   "source": [
    "## å­è¯åˆ†è¯åŠæ›´å¤š\n",
    "\n",
    "æ—©æœŸçš„è‡ªç„¶è¯­è¨€å¤„ç†ç³»ç»Ÿé‡‡ç”¨åŸºäºå•è¯çš„åˆ†è¯æ–¹å¼ï¼Œä½†è¿™ç§æ–¹æ³•åœ¨ä»¥ä¸‹åœºæ™¯ä¸‹è¡¨ç°ä¸ä½³ï¼š\n",
    "\n",
    "* ç½•è§è¯ï¼ˆå¦‚ \"floccinaucinihilipilification\"ï¼‰\n",
    "* å¤åˆè¯ï¼ˆå¦‚ \"unhappiness\"ã€\"burnout\"ï¼‰\n",
    "* æ‹¼å†™é”™è¯¯ï¼ˆå¦‚ \"teh\"ï¼Œåº”å½“å¯¹åº” \"the\"ï¼‰\n",
    "\n",
    "æ‚¨å¯èƒ½ä¹Ÿæ³¨æ„åˆ°ï¼Œåœ¨å‰ä¸€ä¸ªç¤ºä¾‹ä¸­ï¼Œåˆ†è¯ç»“æœä¼šä¿ç•™å•è¯å‰é¢çš„ç©ºæ ¼ï¼ˆæˆ–ç§°â€œç©ºç™½å­—ç¬¦â€ï¼‰ã€‚æ—¢ç„¶æˆ‘ä»¬å¯ä»¥æ ¹æ®ç©ºæ ¼å‡†ç¡®æ‹†åˆ†å¥å­ï¼Œä¸ºä½•è¿˜éœ€è¦è¿™ä¹ˆåšå‘¢ï¼Ÿ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7465f228-43e4-4570-8125-47fc8ccbefb9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# User query\n",
    "query = \"I have a report due tomorrow, but I want to go to the gym to avoid burnout.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f563750-c992-44e4-9762-cde4e4549720",
   "metadata": {
    "ExecutionIndicator": {
     "show": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Whitespace vs Qwen Tokenization Strategy\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Whitespace Tokenizer\n",
    "ws_tokens = query.split()\n",
    "\n",
    "# Dynamically find problem tokens (compare tokens to Qwen's tokenizer)\n",
    "problem_tokens = []\n",
    "for ws_token in ws_tokens:\n",
    "    # Check how Qwen tokenizes this single whitespace token\n",
    "    qwen_subtokens = tokenizer.tokenize(\n",
    "        ws_token,\n",
    "        allowed_special=set(),\n",
    "        disallowed_special=()\n",
    "    )\n",
    "    # If Qwen splits it into multiple tokens, it's a problem\n",
    "    if len(qwen_subtokens) > 1:\n",
    "        problem_tokens.append(ws_token)\n",
    "\n",
    "print(\"\\nğŸ”¤ Whitespace Tokenization (naive approach):\")\n",
    "print(f\"    Tokens: {ws_tokens}\")\n",
    "print(f\"    Token count: {len(ws_tokens)}\")\n",
    "print(f\"    Problem tokens: {problem_tokens}\")\n",
    "\n",
    "# 2. Qwen Tokenizer\n",
    "qwen_tokens = tokenizer.tokenize(\n",
    "    query,\n",
    "    allowed_special=set(),\n",
    "    disallowed_special=()\n",
    ")\n",
    "qwen_tokens = [safe_token_str(t) for t in qwen_tokens]\n",
    "\n",
    "# Show subword structure, i.e. 'burnout' â†’ 'burn' + 'out' \n",
    "actual_subwords = []\n",
    "for token in qwen_tokens:\n",
    "    # For tokens with leading space, show the actual word components\n",
    "    if token.startswith(' ') and len(token) > 1:\n",
    "        # Tokenize the word WITHOUT leading space to see true subwords\n",
    "        word = token.strip()\n",
    "        subwords = tokenizer.tokenize(\n",
    "            word,\n",
    "            allowed_special=set(),\n",
    "            disallowed_special=()\n",
    "        )\n",
    "        subwords = [safe_token_str(t) for t in subwords]\n",
    "        if len(subwords) > 1:\n",
    "            actual_subwords.append(f\"{token} â†’ {subwords}\")\n",
    "        else:\n",
    "            actual_subwords.append(token)\n",
    "    else:\n",
    "        actual_subwords.append(token)\n",
    "\n",
    "print(\"\\nğŸ¤– Qwen Tokenization (byte-level BPE):\")\n",
    "print(f\"    Tokens: {qwen_tokens}\")\n",
    "print(f\"    Token count: {len(qwen_tokens)}\")\n",
    "print(f\"    True subword structure: {actual_subwords}\")\n",
    "\n",
    "# 3. The Critical Difference\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"Why Tokenization Methods Matter\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"1. Whitespace fails on {len(problem_tokens)}/{len(ws_tokens)} tokens ({len(problem_tokens)/len(ws_tokens)*100:.0f}% failure rate!):\")\n",
    "for token in problem_tokens:\n",
    "    qwen_subtokens = [safe_token_str(t) for t in tokenizer.tokenize(token, allowed_special=set(), disallowed_special=())]\n",
    "    print(f\"   - '{token}' â†’ {len(qwen_subtokens)} tokens: {qwen_subtokens}\")\n",
    "\n",
    "print(f\"\\n2. Real-world consequence:\")\n",
    "print(f\"   Whitespace: {len(problem_tokens)}/{len(ws_tokens)} tokens problematic ({len(problem_tokens)/len(ws_tokens)*100:.0f}% failure rate!)\")\n",
    "print(f\"   Qwen: 0/{len(qwen_tokens)} tokens problematic (100% coverage)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71dac40b-bff9-4b7e-ba47-c6939788ab15",
   "metadata": {},
   "source": [
    "æˆ‘ä»¬å¯ä»¥æ¸…æ¥šçœ‹åˆ°ï¼ŒåŸºäºç©ºæ ¼çš„åˆ†è¯ç­–ç•¥ä¸ Qwen çš„ BPE åˆ†è¯ç­–ç•¥ä¹‹é—´å­˜åœ¨æ˜¾è‘—å·®å¼‚ã€‚\n",
    "\n",
    "```mermaid\n",
    "graph LR\n",
    "A[Whitespace Tokenizer] --> B[Subword Tokenization]\n",
    "B --> C[Qwen's Byte-Level BPE]\n",
    "C --> D[Vectorization]\n",
    "\n",
    "```\n",
    "\n",
    "### å…³é”®å·®å¼‚ï¼šä¿ç•™ç©ºæ ¼ vs. ç†è§£å­è¯\n",
    "\n",
    "ç©ºæ ¼åˆ†è¯åªæ˜¯ç®€å•åœ°æŒ‰ç…§ç©ºæ ¼æ‹†åˆ†æ–‡æœ¬ï¼ˆä¾‹å¦‚æŠŠ \"burnout\" å½“ä½œä¸€ä¸ªæ•´ä½“ï¼‰ï¼Œè€Œ Qwen çš„æ–¹æ³•åˆ™åŒæ—¶åœ¨ä¸¤ä¸ªå±‚é¢è¿ä½œï¼š\n",
    "\n",
    "* **è¡¨å±‚ï¼š** ä¿ç•™ç©ºæ ¼ä¿¡æ¯ï¼Œä»¥ä¾¿ç²¾å‡†è¿˜åŸåŸæ–‡\n",
    "* **è¯­ä¹‰å±‚ï¼š** é€šè¿‡å­è¯ç»“æ„ç†è§£å•è¯å†…éƒ¨çš„è¯­ä¹‰å…³ç³»\n",
    "\n",
    "#### å¯è§†åŒ–åŒå±‚åˆ†è¯\n",
    "\n",
    "```mermaid\n",
    "graph TB\n",
    "    subgraph Whitespace Tokenizer\n",
    "        direction TB\n",
    "        W1[\"'burnout'\"] --> W2[\"å•ä¸€è¯å…ƒ<br/>(æ— å†…éƒ¨ç»“æ„)\"]\n",
    "    end\n",
    "    \n",
    "    subgraph Qwen's Byte-Level BPE\n",
    "        direction TB\n",
    "        Q1[\"' burned'\"] --> Q2[\"è¡¨å±‚è¯å…ƒ<br/>(å«ç©ºæ ¼)\"]\n",
    "        Q1 --> Q3[\"è¯­ä¹‰ç»“æ„<br/>burn + out\"]\n",
    "        Q2 --> Q4[\"ç²¾å‡†è¿˜åŸæ–‡æœ¬\"]\n",
    "        Q3 --> Q5[\"æ¨¡å¼è¯†åˆ«\"]\n",
    "    end\n",
    "    \n",
    "    W2 -.->|æ— æ³•å¤„ç†æœªçŸ¥è¯| Q5\n",
    "    Q5 --> R[\"TaskFriend å¾—ä»¥ç†è§£ï¼š<br/>- 'burned' ä¸ 'burnout' çš„å…³è”<br/>- 'time' + 'block' = æå‡æ•ˆç‡\"]\n",
    "\n",
    "```\n",
    "\n",
    "Qwen çš„åˆ†è¯å™¨ä¸ä»…ä»…æ˜¯æ‹†åˆ†æ–‡æœ¬ï¼Œå®ƒæ„å»ºäº†ä¸€ä¸ªåŒå±‚è¡¨ç¤ºï¼šä¿ç•™ç©ºæ ¼ç¡®ä¿å¯ä»¥å®Œç¾å¤åŸæ–‡æœ¬ï¼ŒåŒæ—¶é€šè¿‡å­è¯ç†è§£è¿æ¥è¯­ä¹‰ã€‚è¿™ä½¿å¾— Qwen åœ¨ç²¾å‡†å¤„ç†ç”¨æˆ·è¯­è¨€çš„åŒæ—¶ï¼Œå³ä¾¿ç”¨æˆ·ä»æœªç”¨è¿‡æŸä¸ªè¯ï¼Œä¹Ÿèƒ½é€šè¿‡ç›¸å…³å­è¯æ¨æ–­å…¶å«ä¹‰ï¼Œä¾‹å¦‚ä» *\"burn\"* ä¸ *\"out\"* ç†è§£ *\"burnout\"*ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d3619b-9e7e-4917-937c-92bff8f8e7db",
   "metadata": {
    "tags": []
   },
   "source": [
    "# å‘é‡åŒ–ä¸æ³¨æ„åŠ›ï¼šè¯å…ƒå¦‚ä½•è·å¾—å«ä¹‰\n",
    "\n",
    "---\n",
    "\n",
    "æƒ³è±¡æ‚¨æ­£å‘æœ‹å‹å€¾è¯‰ç¹å¿™çš„æ—¥ç¨‹ï¼š\n",
    "\n",
    "> \"I need to finish a report due tomorrow but also want to go to the gym. What should I do?\"\n",
    "\n",
    "æœ‹å‹ä¸ä»…èƒ½å¬åˆ°è¿™äº›è¯è¯­ï¼Œæ›´èƒ½ç†è§£ \"report due tomorrow\" æ‰€ä»£è¡¨çš„**ç´§è¿«æ€§**ï¼Œä»¥åŠå»å¥èº«æˆ¿å¯¹èº«å¿ƒå¥åº·çš„é‡è¦æ€§ã€‚ä»–ä»¬ä¼šæƒè¡¡ä¸¤è€…ï¼Œä¸ºæ‚¨æå‡ºå¯è¡Œå»ºè®®ã€‚\n",
    "\n",
    "é‚£ä¹ˆï¼Œå¦‚ä½•è®© **TaskFriend** ä¹Ÿåšåˆ°è¿™ä¸€ç‚¹ï¼Ÿæˆ‘ä»¬å¸Œæœ›å®ƒå­¦ä¼šè¯†åˆ«å…³é”®çŸ­è¯­ï¼š\n",
    "\n",
    "* \"report due tomorrow\"\n",
    "* \"want to go to the gym\"\n",
    "\n",
    "ç­”æ¡ˆå°±æ˜¯å‘é‡åŒ–ä¸æ³¨æ„åŠ›æœºåˆ¶â€”â€”å®ƒä»¬è´Ÿè´£è¯†åˆ«æ ¸å¿ƒè¯å…ƒï¼Œå¹¶å°†å…¶è½¬æ¢ä¸ºå¯Œå«è¯­ä¹‰çš„è¡¨ç¤ºã€‚\n",
    "\n",
    "## å‘é‡ç©ºé—´ï¼šæ„ä¹‰çš„æ‰¿è½½ä½“\n",
    "\n",
    "å¯ä»¥æŠŠå®ƒæƒ³è±¡æˆä¸€ç‰‡æµ©ç€šçš„å®‡å®™ç©ºé—´ï¼Œæ¯ä¸ªè¯éƒ½æœ‰å±äºè‡ªå·±çš„åæ ‡ã€‚åœ¨è¿™ç‰‡ç©ºé—´é‡Œï¼š\n",
    "\n",
    "* å·¥ä½œç›¸å…³è¯è¯­èšé›†åœ¨ä¸€ç‰‡åŒºåŸŸï¼ˆreportã€deadlineã€meetingï¼‰\n",
    "* å¥åº·ç›¸å…³è¯è¯­å½¢æˆè‡ªå·±çš„æ˜Ÿç¾¤ï¼ˆgymã€burnoutã€wellnessï¼‰\n",
    "* ä¸æ—¶é—´ç´§è¿«ç›¸å…³çš„è¯è¯­å›´ç»•ç€â€œç´§æ€¥â€è½¨é“è¿è¡Œï¼ˆtomorrowã€ASAPã€deadlineï¼‰\n",
    "\n",
    "å½“ **TaskFriend** çœ‹åˆ° \"report due tomorrow\" æ—¶ï¼Œå®ƒå¹¶ä¸æ˜¯åœ¨å¤„ç†ä¸‰ä¸ªäº’ä¸å…³è”çš„è¯ï¼Œè€Œæ˜¯è¯†åˆ«å‡ºè¿™äº›å‘é‡ç»„åˆä½äºâ€œç´§æ€¥å·¥ä½œâ€åŒºåŸŸã€‚å½“å®ƒçœ‹åˆ° \"gym to keep fit\" æ—¶ï¼Œä¹Ÿä¼šæ„è¯†åˆ°è¿™ç»„å‘é‡ä½äºç”¨æˆ·â€œä¸ªäººåå¥½â€çš„è¯­ä¹‰åŒºåŸŸã€‚\n",
    "\n",
    "> **è¯´æ˜ï¼š** æœ¬èŠ‚æ¼”ç¤ºç¤ºä¾‹é€‰ç”¨ distilBERTï¼Œä»¥å…¼é¡¾æ¨¡å‹ä½“é‡ä¸è¿è¡Œé€Ÿåº¦ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d930b9b-3bcf-4d5b-9905-dc8608d01d8b",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# User query\n",
    "query = \"I have a report due for tomorrow's meeting, but I want to go to the gym to stay fit.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22c7f87-3592-4ece-8c12-b90b11272908",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define cluster terms\n",
    "# These do not affect the results of the model in any way, but serve to help better visualize the vector representations\n",
    "WORK = ['report', 'task', 'assignment', 'project', 'analysis', 'deadline', 'due', 'submit']\n",
    "WELLBEING = ['gym', 'exercise', 'workout', 'burnout', 'stress', 'energy', 'balance', 'happy', 'fit']\n",
    "URGENCY = ['tomorrow', 'today', 'now', 'need', 'must', 'should', 'due', 'immediate', 'urgent', 'soon']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6084e3c7-e439-469a-8ad2-9a0290bc5a7a",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "from transformers import AutoModel\n",
    "from functions.vector_visualization import visualize_task_elements  # Import visualization function\n",
    "\n",
    "print(\"Identifying Key Tokens & Vectorizing Them\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Load the model\n",
    "print(\"\\nLoading language model (distilBERT)...\", end=\"\", flush=True)\n",
    "start_time = time.time()\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "model = AutoModel.from_pretrained(\"distilbert-base-uncased\", output_attentions=True)\n",
    "model.eval()\n",
    "\n",
    "load_time = time.time() - start_time\n",
    "print(f\" Done âœ“ ({load_time:.1f} seconds)\")\n",
    "\n",
    "# Get embeddings AND attention weights\n",
    "print(f\"\\nAnalyzing query: '{query}'\")\n",
    "print(\"Processing with attention analysis...\", end=\"\", flush=True)\n",
    "start_time = time.time()\n",
    "\n",
    "with torch.no_grad():\n",
    "    inputs = tokenizer(query, return_tensors=\"pt\")\n",
    "    outputs = model(**inputs)\n",
    "    embeddings = outputs.last_hidden_state[0].numpy()\n",
    "    attentions = outputs.attentions\n",
    "\n",
    "load_time = time.time() - start_time\n",
    "print(f\" Done âœ“ ({load_time:.1f} seconds)\")\n",
    "\n",
    "# Extract tokens\n",
    "tokens = tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0])\n",
    "\n",
    "# 1. FILTER: Remove special tokens and subwords\n",
    "meaningful_indices = [i for i, token in enumerate(tokens) \n",
    "                     if token not in ['[CLS]', '[SEP]'] and \n",
    "                     not token.startswith('##') and \n",
    "                     len(token) > 1]\n",
    "meaningful_tokens = [tokens[i] for i in meaningful_indices]\n",
    "meaningful_vectors = embeddings[meaningful_indices]\n",
    "\n",
    "# 2. LET THE MODEL DECIDE: Use attention to identify key tokens\n",
    "print(\"\\nIdentifying important task elements...\", end=\"\", flush=True)\n",
    "start_time = time.time()\n",
    "\n",
    "# Calculate attention importance scores\n",
    "attention_scores = np.zeros(len(meaningful_tokens))\n",
    "for layer_attention in attentions:\n",
    "    avg_heads = layer_attention[0].mean(dim=0).numpy()\n",
    "    \n",
    "    for idx, orig_pos in enumerate(meaningful_indices):\n",
    "        attention_to_token = avg_heads[:, orig_pos]\n",
    "        meaningful_attention = [attention_to_token[i] for i in meaningful_indices if i != orig_pos]\n",
    "        \n",
    "        if meaningful_attention:\n",
    "            attention_scores[idx] += np.mean(meaningful_attention)\n",
    "\n",
    "# Normalize scores\n",
    "attention_scores = attention_scores / np.max(attention_scores) if np.max(attention_scores) > 0 else attention_scores\n",
    "\n",
    "# Get top 15 most important tokens according to attention\n",
    "top_indices = np.argsort(attention_scores)[::-1][:15]\n",
    "key_tokens = [meaningful_tokens[i] for i in top_indices]\n",
    "key_vectors = meaningful_vectors[top_indices]\n",
    "key_scores = attention_scores[top_indices]\n",
    "\n",
    "load_time = time.time() - start_time\n",
    "print(f\" Done âœ“ ({load_time:.1f} seconds)\")\n",
    "\n",
    "# Print the model's selected key tokens and their importance\n",
    "for i, (token, score) in enumerate(zip(key_tokens, key_scores)):\n",
    "    print(f\"  {i+1}. '{token}' (importance: {score:.3f})\")\n",
    "\n",
    "# Visualize vector map\n",
    "print(\"\\nğŸ“Š Visualizing vector map...\")\n",
    "visualize_task_elements(\n",
    "    key_tokens, \n",
    "    key_vectors, \n",
    "    key_scores,\n",
    "    work_terms=WORK,\n",
    "    wellbeing_terms=WELLBEING,\n",
    "    urgency_terms=URGENCY\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea3e4dc-69ca-464a-91e7-b378db433587",
   "metadata": {},
   "source": [
    "# æ–‡æœ¬ç”Ÿæˆï¼šæ‰“é€ ç†æƒ³å›ç­”\n",
    "\n",
    "---\n",
    "\n",
    "å½“æˆ‘ä»¬å·²ç»æŠŠæ‚¨çš„æè¿°è½¬åŒ–ä¸ºæœ‰æ„ä¹‰çš„å‘é‡åï¼Œæ¥ä¸‹æ¥å°±è½®åˆ°â€œé­”æ³•â€ç™»åœºâ€”â€”ç”Ÿæˆå›å¤ï¼è®¸å¤šäººè¯¯ä»¥ä¸º Qwen è¿™ç±» LLM èƒ½ç›´æ¥ç”Ÿæˆæ–‡å­—ï¼Œä½†äº‹å®å¹¶éå¦‚æ­¤ã€‚\n",
    "\n",
    "æ¨¡å‹åœ¨å¤„ç†è¾“å…¥åï¼Œä¼šä¸ºæ¯ä¸ªå¯èƒ½çš„ä¸‹ä¸€ä¸ªè¯å…ƒè®¡ç®—æ¦‚ç‡ã€‚è¿™ä¸€æ­¥é€šè¿‡ç”Ÿæˆ **logits**ï¼ˆåŸå§‹é¢„æµ‹åˆ†æ•°ï¼‰å®Œæˆï¼Œç„¶åå€ŸåŠ© softmax å‡½æ•°è½¬åŒ–ä¸ºæ¦‚ç‡åˆ†å¸ƒã€‚\n",
    "\n",
    "```mermaid\n",
    "graph LR\n",
    "    A[I thought] --> B((Tokenizer))\n",
    "    B --> C[Input token ids<br>40, 3381]\n",
    "    C --> D((Large<br>Language<br>Model))\n",
    "    \n",
    "    D --> E[it: 0.96]\n",
    "    D --> F[you: 0.89]\n",
    "    D --> G[that: 0.72]\n",
    "    D --> H[to: 0.53]\n",
    "\n",
    "    subgraph Input\n",
    "        A\n",
    "        B\n",
    "        C\n",
    "    end\n",
    "\n",
    "    subgraph Generation\n",
    "        D\n",
    "        E\n",
    "        F\n",
    "        G\n",
    "        H\n",
    "    end\n",
    "\n",
    "```\n",
    "\n",
    "æˆ‘ä»¬ç”¨ä¸€ä¸ªå…·ä½“ä¾‹å­æ¥åˆ†æè¿™ä¸€å…³é”®æ­¥éª¤ã€‚å½“æ‚¨è¾“å…¥ \"I thought\" æ—¶ï¼Œæ¨¡å‹å¯èƒ½ä¼šç»™å‡ºå¦‚ä¸‹æ¦‚ç‡ï¼š\n",
    "\n",
    "|Token|Logit|Probability|\n",
    "|---|---|---|\n",
    "|' it'|0.96|0.42|\n",
    "|' you'|0.89|0.28|\n",
    "|' that'|0.72|0.18|\n",
    "|' to'|0.53|0.09|\n",
    "\n",
    "çœŸæ­£æœ‰è¶£çš„éƒ¨åˆ†åœ¨äºï¼šæ¨¡å‹å¦‚ä½•æ ¹æ®è¿™äº›æ¦‚ç‡é€‰å–ä¸‹ä¸€ä¸ªè¯å…ƒï¼Œå†³å®šäº†å›ç­”çš„é£æ ¼ä¸è´¨é‡ã€‚è¿™ä¸»è¦å—ä¸¤ä¸ªå…³é”®å‚æ•°æ§åˆ¶ï¼š`temperature` ä¸ `top_p`ã€‚\n",
    "\n",
    "## Temperatureï¼šè°ƒæ§éšæœºæ€§\n",
    "\n",
    "`temperature` ç”¨äºè°ƒèŠ‚æ¨¡å‹é¢„æµ‹çš„â€œè‡ªä¿¡åº¦â€ï¼š\n",
    "\n",
    "* **ä½æ¸©åº¦ï¼ˆ0.1-0.5ï¼‰ï¼š** è¾“å‡ºæ›´ä¿å®ˆã€ç¡®å®šæ€§é«˜\n",
    "* **ä¸­æ¸©åº¦ï¼ˆ0.6-1.0ï¼‰ï¼š** åœ¨åˆ›é€ åŠ›ä¸è¿è´¯æ€§ä¹‹é—´å–å¾—å¹³è¡¡\n",
    "* **é«˜æ¸©åº¦ï¼ˆ1.0+ï¼‰ï¼š** æ›´å…·åˆ›é€ æ€§ï¼Œä½†å¯èƒ½ç¼ºä¹è¿è´¯\n",
    "\n",
    "### Temperature ç¤ºä¾‹\n",
    "\n",
    "æˆ‘ä»¬æ¥çœ‹çœ‹ä¸åŒ `temperature` å€¼ä¼šå¦‚ä½•å½±å“åŒä¸€æç¤ºè¯­ `\"I thought\"` çš„ç»­å†™ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b2e39d-88cf-4932-90b0-330c2cb9f825",
   "metadata": {
    "ExecutionIndicator": {
     "show": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# User query\n",
    "query = \"I thought\"\n",
    "\n",
    "# System prompt\n",
    "system_prompt = \"Complete the sentence\"\n",
    "\n",
    "# Temperature, range: [0, 2)\n",
    "# Model Studio default is 0.7\n",
    "# Experiment default is [0, 1.0, 1.9]\n",
    "temp_values=[0, 1.0, 1.9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dade2ac-ee8e-48e3-8342-90872aaaf908",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def print_qwen_comparison_temp(query, system_prompt, temp_values, top_p, iterations):\n",
    "    print(f\"Comparing temperature effects (top_p={top_p})\")\n",
    "    print(f\"{'='*50}\\n\")\n",
    "    print(f\"Prompt: '{query}'\\n\")\n",
    "    \n",
    "    for temp in temp_values:\n",
    "        print(f\"\\nğŸŒ¡ï¸ TEMPERATURE = {temp}\")\n",
    "        print(f\"{'-'*50}\")\n",
    "        \n",
    "        for i in range(iterations):\n",
    "            time.sleep(1.5)\n",
    "            print(f\"Output #{i+1}: \", end=\"\")\n",
    "            response = get_qwen_stream_response(\n",
    "                query, \n",
    "                system_prompt, \n",
    "                temperature=temp,\n",
    "                top_p=top_p\n",
    "            )\n",
    "            \n",
    "            output_content = ''\n",
    "            for chunk in response:\n",
    "                output_content += chunk\n",
    "                print(chunk, end='', flush=True)  # Stream output in real-time\n",
    "            print(\"\\n\" + \"=\"*50)\n",
    "\n",
    "# Example usage with extreme values\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # Test values\n",
    "    print_qwen_comparison_temp(\n",
    "        query=query,\n",
    "        system_prompt=system_prompt,\n",
    "        temp_values=temp_values,\n",
    "        top_p=0.8,  # Fixed for fair comparison\n",
    "        iterations=5\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a2a2c7-35f7-4b71-a14b-c973d1b25079",
   "metadata": {},
   "source": [
    "**é¢„æœŸè¾“å‡ºç‰¹å¾ï¼š**\n",
    "\n",
    "* **Temperature 0.0ï¼š**\n",
    "    * è¾“å‡ºå®Œå…¨ç¡®å®šï¼Œæªè¾å‡ ä¹ä¸€è‡´\n",
    "    * ä»…åœ¨ä¸ªåˆ«è¯è¯­ä¸Šæœ‰è½»å¾®å˜åŠ¨\n",
    "    * ä¸¥æ ¼éµå¾ªæœ€å¯èƒ½çš„ç»­å†™è·¯å¾„\n",
    "    * è¡¨è¿°é‡å¤ã€æ¨¡å¼åŒ–ï¼Œç¼ºä¹åˆ›æ„\n",
    "* **Temperature 1.0ï¼š**\n",
    "    * æ•´ä½“ä¿æŒä¸€è‡´ï¼Œä½†ç»“æ„ä¼šå‡ºç°ç»†å¾®å·®å¼‚\n",
    "    * å¶å°”å¼•å…¥æ–°çš„ä¿¡æ¯æˆ–è§’åº¦\n",
    "    * åœ¨ç´§æ‰£æç¤ºè¯­çš„åŒæ—¶å±•ç°é€‚åº¦åˆ›é€ åŠ›\n",
    "    * åœ¨å¯é¢„æµ‹æ€§ä¸å¤šæ ·æ€§ä¹‹é—´å–å¾—å¹³è¡¡\n",
    "* **Temperature 1.9ï¼š**\n",
    "    * ä¸åŒè¾“å‡ºä¹‹é—´å·®å¼‚å·¨å¤§\n",
    "    * ç»å¸¸å‡ºç°å¯Œæœ‰åˆ›æ„çš„è·³è·ƒå¼å†…å®¹\n",
    "    * å¯èƒ½é‡å¤æˆ–å®Œå…¨è·‘é¢˜\n",
    "    * éšæœºæ€§æé«˜ï¼Œæ—¢å¯èƒ½å¸¦æ¥æ–°é¢–è§‚ç‚¹ï¼Œä¹Ÿå¯èƒ½ç‰ºç‰²è¿è´¯æ€§\n",
    "    * å……åˆ†å±•ç¤ºé«˜æ¸©åº¦å¸¦æ¥çš„åˆ›é€ æ½œåŠ›ï¼Œä½†ä¸€è‡´æ€§ä¸‹é™\n",
    "\n",
    "## Top_pï¼ˆæ ¸é‡‡æ ·ï¼‰ï¼šç²¾é€‰æœ€ä¼˜å€™é€‰\n",
    "\n",
    "`temperature` è°ƒæ•´æ•´ä½“éšæœºæ€§ï¼Œè€Œ `top_p` å†³å®šä»å“ªäº›é«˜æ¦‚ç‡è¯å…ƒä¸­è¿›è¡ŒæŒ‘é€‰ï¼š\n",
    "\n",
    "* **ä½ top_pï¼ˆ0.1-0.5ï¼‰ï¼š** ä»…è€ƒè™‘æœ€å¯èƒ½çš„å°‘é‡è¯å…ƒï¼ˆé«˜åº¦èšç„¦ï¼‰\n",
    "* **ä¸­ç­‰ top_pï¼ˆ0.6-0.9ï¼‰ï¼š** åœ¨è´¨é‡ä¸å¤šæ ·æ€§ä¹‹é—´å–å¾—å¹³è¡¡\n",
    "* **é«˜ top_pï¼ˆ0.95+ï¼‰ï¼š** çº³å…¥æ›´å¤šä½æ¦‚ç‡è¯å…ƒï¼ˆæ›´å…·åˆ›é€ æ€§ï¼‰\n",
    "\n",
    "### Top_p ç¤ºä¾‹\n",
    "\n",
    "åœ¨å›ºå®š `temperature = 0.7` çš„å‰æä¸‹ï¼Œæˆ‘ä»¬è§‚å¯Ÿä¸åŒ `top_p` å¯¹å›ç­”çš„å½±å“ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50f6b6c-d50a-482d-a5b5-f055e3f486d0",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# User query\n",
    "query = \"Describe a bustling city street at rush hour.\"\n",
    "\n",
    "# System prompt\n",
    "system_prompt = \"You are a concise story teller. Provide a 2-sentence answer.\"\n",
    "\n",
    "# Nucleus sampling (top_p), range: [0, 1]\n",
    "# Model Studio default is 0.8\n",
    "# Experiment default is [0.3, 0.7, 0.95]\n",
    "top_p_values = [0.1, 0.6, 0.95]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e938999d-5dac-4a1d-8bb3-28e5b3042487",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def print_qwen_comparison(query, system_prompt, temperature, top_p_values, iterations):\n",
    "    print(f\"COMPARING TOP_P EFFECTS (temperature={temperature})\")\n",
    "    print(f\"Prompt: '{query}'\")\n",
    "    print(f\"{'='*50}\\n\")\n",
    "    \n",
    "    for p in top_p_values:  # Using 'p' to avoid name conflict\n",
    "        print(f\"\\nğŸ¯ TOP_P = {p}\")\n",
    "        print(f\"{'-'*50}\")\n",
    "        \n",
    "        for i in range(iterations):\n",
    "            time.sleep(1.5)\n",
    "            print(f\"Output #{i+1}: \", end=\"\")\n",
    "            response = get_qwen_stream_response(\n",
    "                query, \n",
    "                system_prompt, \n",
    "                temperature=temperature,  # Using the fixed temperature\n",
    "                top_p=p  # Using the current top_p value\n",
    "            )\n",
    "            \n",
    "            output_content = ''\n",
    "            for chunk in response:\n",
    "                output_content += chunk\n",
    "                print(chunk, end='', flush=True)\n",
    "            print(\"\\n\" + \"=\"*50)\n",
    "\n",
    "# Define top_p values FIRST\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    print_qwen_comparison(\n",
    "        query=query,\n",
    "        system_prompt=system_prompt,\n",
    "        temperature=0.7,  # Fixed temperature\n",
    "        top_p_values=top_p_values,  # Pass the list of values\n",
    "        iterations=3\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a857b04-cd40-486f-9428-223d607d46d3",
   "metadata": {},
   "source": [
    "**é¢„æœŸè¾“å‡ºç‰¹å¾ï¼š**\n",
    "\n",
    "* **top_p 0.1ï¼š**\n",
    "    * è¾“å‡ºé«˜åº¦ä¸€è‡´ï¼Œå‡ ä¹æ²¡æœ‰å·®å¼‚\n",
    "    * ç”¨è¯ä¿å®ˆ\n",
    "    * å¥å¼æä¸ºç›¸è¿‘ï¼Œä»…åœ¨æœ«å°¾ç•¥æœ‰å˜åŒ–\n",
    "    * ä¸¥æ ¼å›´ç»•æœ€å¯èƒ½çš„è¯åºå±•å¼€\n",
    "* **top_p 0.6ï¼š**\n",
    "    * è¾“å‡ºä¹‹é—´å­˜åœ¨ä¸€å®šå·®å¼‚ï¼Œä½†ä¿æŒè¿è´¯\n",
    "    * ä½¿ç”¨æ›´ä¸°å¯Œçš„è¯æ±‡ä¸å¥å¼\n",
    "    * æè¿°æ—¢å…·åˆ›é€ æ€§åˆç´§æ‰£ä¸»é¢˜\n",
    "    * åœ¨èšç„¦æ€§ä¸å¤šæ ·æ€§ä¹‹é—´å–å¾—è‰¯å¥½å¹³è¡¡\n",
    "* **top_p 0.95ï¼š**\n",
    "    * å†…å®¹å’Œç»“æ„å·®å¼‚æ˜¾è‘—\n",
    "    * å¼•å…¥ä½æ¦‚ç‡ä½†æœ‰è¶£çš„ç»†èŠ‚\n",
    "    * æ›´å¤šéšå–»ä¸ä¸åŒçš„æå†™æ–¹å¼\n",
    "    * åœ¨ä¿æŒç›¸å…³æ€§çš„åŒæ—¶ï¼Œæ¢ç´¢æ›´å¹¿æ³›çš„è¡¨è¾¾å¯èƒ½"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5acfe2-4202-46f3-8ea2-56cf7b93db39",
   "metadata": {},
   "source": [
    "# åç»­å®‰æ’\n",
    "\n",
    "---\n",
    "\n",
    "<details>\n",
    "<summary style=\"cursor: pointer; padding: 12px; border: 1px solid #dee2e6; border-radius: 6px;\"><b>1. ä¸ºä»€ä¹ˆ Qwen çš„åˆ†è¯å™¨ä¼šæŠŠ \"burnout\" æ‹†æˆ \"burn\" å’Œ \"out\"ï¼Œè€Œç©ºæ ¼åˆ†è¯å™¨å´å°†å…¶è§†ä¸ºä¸€ä¸ªæ•´ä½“ï¼Ÿ</b>\n",
    "\n",
    "<ul>\n",
    "<li>A) ä¸ºäº†å‡å°‘æ¯å¥è¯çš„è¯å…ƒæ•°é‡ </li>\n",
    "<li>B) ä¸ºäº†å®ç°å­è¯çº§ç†è§£ï¼Œå¹¶é«˜æ•ˆå¤„ç†ç½•è§è¯ä¸å¤åˆè¯ </li>\n",
    "<li>C) ä¸ºäº†è·³è¿‡æ ‡ç‚¹ç¬¦å·ã€æé«˜ç”Ÿæˆé€Ÿåº¦ </li>\n",
    "<li>D) ä¸ºäº†å¼ºåˆ¶è¾“å…¥å…¨éƒ¨å°å†™</li>\n",
    "</ul>\n",
    "\n",
    "**æŸ¥çœ‹ç­”æ¡ˆ â†’**\n",
    "\n",
    "</summary>\n",
    "\n",
    "<div style=\"margin-top: 10px; padding: 15px; border: 1px solid #dee2e6; border-radius: 0 0 6px 6px;\">\n",
    "\n",
    "âœ… **æ­£ç¡®ç­”æ¡ˆï¼š** B) ä¸ºäº†å®ç°å­è¯çº§ç†è§£ï¼Œå¹¶é«˜æ•ˆå¤„ç†ç½•è§è¯ä¸å¤åˆè¯  \n",
    "ğŸ“ **è§£æï¼š**  \n",
    "<ul>\n",
    "<li>å­è¯åˆ†è¯ï¼ˆå¦‚å­—èŠ‚çº§ BPEï¼‰èƒ½å¤Ÿè®©æ¨¡å‹ç†è§£å•è¯çš„å†…éƒ¨ç»“æ„ã€‚</li>\n",
    "<li>å³ä½¿è®­ç»ƒè¯­æ–™ä¸­æ²¡æœ‰å‡ºç°è¿‡ \"burnout\"ï¼Œæ¨¡å‹ä»èƒ½ä» \"burn\" ä¸ \"out\" æ¨æ–­å…¶å«ä¹‰ã€‚</li>\n",
    "<li>ç©ºæ ¼åˆ†è¯æ— æ³•å¤„ç†å¤åˆè¯ã€æ‹¼å†™é”™è¯¯ä¸ç½•è§è¯ï¼Œå› æ­¤å­è¯ç­–ç•¥å¯¹ç¨³å¥çš„è¯­è¨€ç†è§£è‡³å…³é‡è¦ã€‚</li>\n",
    "</ul>\n",
    "</div>\n",
    "</details>\n",
    "<br>\n",
    "<details>\n",
    "<summary style=\"cursor: pointer; padding: 12px; border: 1px solid #dee2e6; border-radius: 6px; margin-top: 15px;\"><b>2. æ³¨æ„åŠ›æœºåˆ¶å¦‚ä½•å¸®åŠ© LLM è¯†åˆ« \"need to finish\" æˆ– \"want to go\" ä¹‹ç±»çš„ä»»åŠ¡åºåˆ—ï¼Ÿ</b>\n",
    "\n",
    "<ul>\n",
    "<li>A) é€šè¿‡ä½™å¼¦ç›¸ä¼¼åº¦å°†å•è¯è½¬æ¢ä¸ºå‘é‡ </li>\n",
    "<li>B) ä¸ºç´§æ€¥ä»»åŠ¡åˆ†é…æ›´é«˜çš„è¯å…ƒ ID </li>\n",
    "<li>C) è¯†åˆ«é‡å¤æ¨¡å¼ï¼ˆå¦‚å¤šä¸ª 'to' è¯å…ƒï¼‰ï¼Œå¹¶å°†å…¶ä¸åç»­åŠ¨ä½œå…³è” </li>\n",
    "<li>D) æé«˜æ¸©åº¦å‚æ•°ï¼Œä»¥è·å¾—æ›´å…·åˆ›é€ æ€§çš„æ’ç¨‹å»ºè®®</li>\n",
    "</ul>\n",
    "\n",
    "æŸ¥çœ‹ç­”æ¡ˆ â†’\n",
    "\n",
    "</summary>\n",
    "\n",
    "<div style=\"margin-top: 10px; padding: 15px; border: 1px solid #dee2e6; border-radius: 0 0 6px 6px;\">\n",
    "\n",
    "âœ… **æ­£ç¡®ç­”æ¡ˆï¼š** C) è¯†åˆ«é‡å¤æ¨¡å¼ï¼ˆå¦‚å¤šä¸ª 'to' è¯å…ƒï¼‰ï¼Œå¹¶å°†å…¶ä¸åç»­åŠ¨ä½œå…³è”  \n",
    "ğŸ“ **è§£æï¼š**  \n",
    "<ul>\n",
    "<li>æ³¨æ„åŠ›æœºåˆ¶ä¼šå­¦ä¹ åˆ°ï¼šé«˜é¢‘è¯å…ƒ IDï¼ˆå¦‚ä»£è¡¨ ' to' çš„ 311ï¼‰å¾€å¾€ä¸å³å°†å‡ºç°çš„ä»»åŠ¡è¯è¯­ç›¸å…³ã€‚</li>\n",
    "<li>å½“æ¨¡å‹å‘ç° [ACTION] + 'to' + [TASK] çš„é‡å¤æ¨¡å¼æ—¶ï¼Œä¾¿ä¼šæ¨æ–­å‡ºè¿™æ˜¯ä¸€ç³»åˆ—æ„å›¾ã€‚</li>\n",
    "<li>æ­£æ˜¯è¿™ç§æ¨¡å¼è¯†åˆ«èƒ½åŠ›ï¼Œè®© TaskFriend èƒ½åœ¨æ²¡æœ‰æ˜ç¡®å…³é”®è¯çš„æƒ…å†µä¸‹è¯†åˆ«ç”¨æˆ·ç›®æ ‡å¹¶è§¦å‘ä¼˜å…ˆçº§é€»è¾‘ã€‚</li>\n",
    "</ul>    \n",
    "</div>\n",
    "</details>\n",
    "\n",
    "## æ ¸å¿ƒè¦ç‚¹\n",
    "\n",
    "* **åˆ†è¯**\n",
    "    * **è¯å…ƒæ˜¯ LLM çš„æœ€å°æ„ä¹‰å•ä½**ï¼Œå¯ä»¥æ˜¯å•è¯ã€å­è¯æˆ–ç¬¦å·ã€‚\n",
    "    * **å­è¯åˆ†è¯ï¼ˆå¦‚å­—èŠ‚çº§ BPEï¼‰** ä¼˜äºç©ºæ ¼åˆ†è¯ï¼Œèƒ½å¤„ç†ç½•è§è¯ã€å¤åˆè¯ä¸æ‹¼å†™é”™è¯¯ï¼ˆä¾‹å¦‚ \"burnout\" â†’ \"burn\" + \"out\"ï¼‰ã€‚\n",
    "    * **è¯å…ƒä¸­ä¿ç•™ç©ºæ ¼**ï¼ˆå¦‚ \" gym\" ä¸ \"gym\"ï¼‰æ—¢èƒ½è¿˜åŸæ–‡æœ¬ï¼Œåˆåˆ©äºè¯­ä¹‰åˆ†æã€‚\n",
    "    * **ç›¸åŒè¯å…ƒå¯¹åº”ç›¸åŒ ID**ï¼Œè¿™ç§é‡å¤æ¨¡å¼å¸®åŠ©æ¨¡å‹è¯†åˆ«ä»»åŠ¡åºåˆ—ï¼ˆä¾‹å¦‚å¤šæ¬¡å‡ºç°çš„ \" to\"ï¼‰ã€‚\n",
    "    * **åˆ†è¯æ˜¯åç»­å¤„ç†çš„åœ°åŸº**â€”â€”è¾“å…¥è‹¥ä¸å¯é ï¼Œåç»­æµç¨‹ä¹Ÿä¼šå—å½±å“ã€‚\n",
    "\n",
    "<br>\n",
    "\n",
    "* **å‘é‡åŒ–ä¸æ³¨æ„åŠ›ï¼šè¯å…ƒå¦‚ä½•è·å¾—å«ä¹‰**\n",
    "    * **å‘é‡åŒ–** å°†è¯å…ƒæ˜ å°„åˆ°é«˜ç»´ç©ºé—´ï¼Œç›¸ä¼¼è¯­ä¹‰åœ¨å‡ ä½•ä¸Šæ›´æ¥è¿‘ï¼ˆä¾‹å¦‚â€œgymâ€æ¥è¿‘â€œfitnessâ€ï¼‰ã€‚\n",
    "    * **æ³¨æ„åŠ›æœºåˆ¶** åŠ¨æ€è¯„ä¼°è¯å…ƒçš„é‡è¦æ€§ï¼Œå¸®åŠ©æ¨¡å‹èšç„¦äº \"report due tomorrow\" ç­‰å…³é”®ä¿¡æ¯ã€‚\n",
    "    * **æ³¨æ„åŠ›å¾—åˆ†** æ­ç¤ºæ¨¡å‹è®¤ä¸ºé‡è¦çš„éƒ¨åˆ†ï¼Œæ˜¯ä¼˜åŒ–æç¤ºè¯ä¸è°ƒè¯•çš„æœ‰åŠ›å·¥å…·ã€‚\n",
    "    * **å‘é‡ç©ºé—´ä¸­çš„è¯­ä¹‰èšç±»**ï¼ˆå·¥ä½œã€å¥åº·ã€ç´§è¿«ï¼‰å¸®åŠ©æ¨¡å‹æƒè¡¡å–èˆã€åˆ¶å®šä¼˜å…ˆçº§ã€‚\n",
    "    * **è¯­ä¹‰ä¾èµ–äºä¸Šä¸‹æ–‡**â€”â€”åŒä¸€ä¸ªè¯ï¼ˆå¦‚ \"run\"ï¼‰åœ¨ä¸åŒè¯­å¢ƒä¸‹ä¼šæ¿€æ´»ä¸åŒçš„è¯­ä¹‰åŒºåŸŸã€‚\n",
    "\n",
    "<br>\n",
    "\n",
    "* **ç”Ÿæˆï¼šæ‰“é€ ç†æƒ³å›ç­”**\n",
    "    * **LLM ä¸ä¼šâ€œæ€è€ƒâ€ï¼Œå®ƒåœ¨é¢„æµ‹**ï¼šä¾æ®è®­ç»ƒæ•°æ®çš„æ¦‚ç‡åˆ†å¸ƒé¢„æµ‹ä¸‹ä¸€ä¸ªè¯å…ƒã€‚\n",
    "    * **Logits â†’ softmax â†’ æ¦‚ç‡** æ„æˆç”Ÿæˆæµç¨‹ï¼Œæ¨¡å‹éœ€ä»ä¸­é‡‡æ ·ã€‚\n",
    "    * **Temperature** æ§åˆ¶éšæœºæ€§ï¼š\n",
    "      * ä½æ¸©åº¦ï¼ˆ0.1â€“0.5ï¼‰ï¼šç¡®å®šã€èšç„¦\n",
    "      * é«˜æ¸©åº¦ï¼ˆ1.0+ï¼‰ï¼šå¯Œæœ‰åˆ›æ„ä½†æ˜“å¤±çœŸ\n",
    "    * **Top_pï¼ˆæ ¸é‡‡æ ·ï¼‰** å°†é€‰æ‹©èŒƒå›´é™åˆ¶åœ¨æœ€å¯èƒ½çš„è¯å…ƒå†…ï¼š\n",
    "      * ä½ top_p = èŒƒå›´çª„ã€è¾“å‡ºç¨³\n",
    "      * é«˜ top_p = èŒƒå›´å¹¿ã€è¡¨è¾¾å¤šæ ·\n",
    "    * **åˆç†å¹³è¡¡ temperature ä¸ top_p**ï¼Œæ‰èƒ½ç”Ÿæˆæ—¢è¿è´¯åˆè´´åˆè¯­å¢ƒçš„å›å¤ã€‚"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM Engineer (Professional)",
   "language": "python",
   "name": "llm_pro"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
